<!DOCTYPE html>

<html lang="fr" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="shortcut icon" type="image/x-icon" href="../../_static/cbpsmn_logo.png" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>TP INSA 2019-2020 : le GPU par la pratique &#8212; Documentation PSMN-CBP </title>
    <script src="../../_static/documentation_options.js?v=d1a510d7"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/translations.js?v=bf059b8c"></script>
    <link href="../../_static/Bootstrap/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/style.css">
    <script src="https://www.google.com/recaptcha/api.js" async defer></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" /> 
  </head><body>  

    <div class="document">
      <div class="orange-border"></div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            <div class="container contenu">
              <header class="list-inline-item" >
    <div class="d-flex justify-content-between">
        <div class="wid-header pt-3">
            <a href="../../index.html">
                <img class="img-fluid" src="../../_static/header/cbpsmn_logo.png" alt="logo CBP-PSMN">
            </a>
        </div>
        <div class="wid-header">
            <div class="d-flex justify-content-end container-language">
                <div class="px-2">
                    <img class="img-fluid cursor" src="../../_static/header/fr.png" alt="français">
                </div>
                <div>
                    <img class="img-fluid cursor" src="../../_static/header/en.png" alt="anglais">
                </div>
            </div>
            <a href="https://www.ens-lyon.fr/">
                <img class="img-fluid" src="../../_static/header/Logo_ENS_Lyon.png" alt="logo CBP-PSMN">
            </a>
        </div>
    </div>
    
        <nav class="navbar navbar-expand-lg">
            <div class="container-fluid">
                
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="navbar-nav me-auto mb-2 mb-lg-0" id="menu">

                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" aria-current="page">Accueil</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../Accueil/Actualites.html">Actualités PSMN</a></li>
                                    <li><a class="dropdown-item" href="../../Accueil/Bureau.html">Bureau des Correspondants</a></li>
                                    <li><a class="dropdown-item" href="../../Accueil/Evenements.html">Evènements CBP</a></li>
                                    <li><a class="dropdown-item" href="../../Accueil/Liens.html">Liens</a></li>
                                    <li><a class="dropdown-item" href="../../Accueil/Services.html">Services</a></li>
                                    <li class="nav-item dropend">
                                        <a class="dropdown-toggle dropdown-item" href="#">Partenaires</a>
                                        <div class="dropdown-menu">
                                            <ul>
                                                <li><a class="dropdown-item" href="../../Accueil/Laboratoires/ENS.html">Les laboratoires ENS Lyon</a></li> 
                                                <li><a class="dropdown-item" href="../../Accueil/Laboratoires/Udl.html">Les laboratoires Udl</a></li>
                                                <li><a class="dropdown-item" href="../../Accueil/Laboratoires/AURA.html">Les laboratoires région AURA</a></li>
                                                <li><a class="dropdown-item" href="../../Accueil/Laboratoires/CdC.html">Les Centres de Calculs</a></li>
                                                <li><a class="dropdown-item" href="../../Accueil/Laboratoires/PP.html">Les partenaires privés</a></li>
                                            </ul>
                                        </div>
                                    </li>
                                </ul>   
                            </div>
                        </li>
                    
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Informations</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../Informations/News.html">Fil des news</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/Arrets.html">Les arrêts prévus</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/Absences.html">Les absences des opérateurs</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/StatsUtil.html">Statistiques d'utilisation</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/Calendrier.html">Calendrier des évolutions</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/Adaptation.html">Adaptation aux nouveaux besoins</a></li>
                                    <li><a class="dropdown-item" href="../../Informations/Calculer.html">Pour calculer</a></li>
                                    <li><a class="dropdown-item" href="#">F.A.Q.</a></li>
                                    <li class="nav-item dropend">
                                        <a class="dropdown-toggle dropdown-item" href="#">Réalisations et solutions</a>
                                        <div class="dropdown-menu">
                                            <ul> 
                                                <li><a class="dropdown-item" href="../../Informations/Realisations/Logiciels.html">Logiciels</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Realisations/Outils.html">Outils système</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Realisations/Materiel.html">Matériel</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Realisations/Reseaux.html">Réseaux</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Realisations/Plateaux.html">Plateaux techniques</a></li> 
                                            </ul>
                                        </div>
                                    </li>
                                    <li class="nav-item dropend">
                                        <a class="dropdown-toggle dropdown-item" href="#">Classification par activités</a>
                                        <div class="dropdown-menu">
                                            <ul> 
                                                <li><a class="dropdown-item" href="../../Informations/Classification/Etudes.html">Etudes</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Classification/Integration.html">Intégration</a></li> 
                                                <li><a class="dropdown-item" href="../../Informations/Classification/Qualification.html">Qualification</a></li> 
                                            </ul>
                                        </div>
                                    </li>
                                </ul>       
                            </div>
                        </li> 
                    
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Plateformes</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../DataCenter.html">Data Center</a></li>
                                    <li><a class="dropdown-item" href="https://www.ens-lyon.fr/PSMN/Documentation/">Documentations</a></li>
                                    <li><a class="dropdown-item" href="../ClustersServeurs.html">Les clusters et les serveurs</a></li>
                                    <li><a class="dropdown-item" href="../EquipInfo.html">Equipements informatique</a></li>
                                    <li><a class="dropdown-item" href="../ProjetsInfra.html">Projets d'infrastructure</a></li>
                                    <li class="nav-item dropend">
                                        <a class="dropdown-toggle dropdown-item" href="#">Supports</a>
                                        <div class="dropdown-menu">
                                            <ul>   
                                                <li><a class="dropdown-item" href="../Supports/RCS.html">Recherche en calcul scientifique</a></li> 
                                                <li><a class="dropdown-item" href="../Supports/RIS.html">Recherche en informatique scientifique</a></li>
                                                <li><a class="dropdown-item" href="../Supports/HN.html">En humanités numériques</a></li>
                                                <li><a class="dropdown-item" href="../Supports/AFJ.html">Administratif, financier et juridique</a></li>
                                            </ul>                                        
                                        </div>
                                    </li>  
                                </ul>   
                            </div>
                        </li>
                    
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Formation</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../Formation/Formation.html">Formation</a></li>
                                    <li><a class="dropdown-item" href="../../Formation/Stage.html">Propositions de stage</a></li>
                                </ul>   
                            </div>
                        </li>
                        
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Science</a>
                            <div class="dropdown-menu">
                                <ul> 
                                    <li><a class="dropdown-item" href="../../Science/Publications2024.html">Publications</a></li>
                                    <li><a class="dropdown-item" href="../../Science/Theses.html">Thèses</a></li>
                                    <li><a class="dropdown-item" href="../../Science/CreationsMulti.html">Créations multimédia</a></li>
                                    <li><a class="dropdown-item" href="../../Science/Chercheurs.html">Chercheurs associés</a></li>
                                    <li><a class="dropdown-item" href="../../Science/Projets.html">Projets scientifiques + Projets utilisateurs</a></li>
                                </ul>   
                            </div>
                        </li>
                      
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Animation</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../Animation/EvenementsScient.html">Évènements scientifiques</a></li>
                                    <li><a class="dropdown-item" href="../../Animation/Services.html">Services proposés aux organisateurs</a></li>
                                    <li><a class="dropdown-item" href="../../Animation/PAS.html">Projets d'animation scientifique</a></li>
                                    <li><a class="dropdown-item" href="../../Animation/Appels.html">Appel à projets</a></li>
                                    <li><a class="dropdown-item" href="../../Animation/Media.html">Médias</a></li>
                                    <li class="nav-item dropend">
                                        <a class="dropdown-toggle dropdown-item" href="#">Ateliers HM / PN-SHS</a>
                                        <div class="dropdown-menu">
                                            <ul>
                                                <li><a class="dropdown-item" href="../../Animation/Ateliers/AHN.html">Humanités Numériques (AHN)</a></li> 
                                                <li><a class="dropdown-item" href="../../Animation/Ateliers/ABC.html">Biologie Computationnelle (ABC)</a></li>
                                                <li><a class="dropdown-item" href="../../Animation/Ateliers/ACT.html">Chimie Théorique</a></li>
                                                <li><a class="dropdown-item" href="https://groupes.renater.fr/wiki/apn-shs/index">Pratiques Numériques en SHS (ED483)</a></li>
                                                <li><a class="dropdown-item" href="../../Animation/Ateliers/Guides.html">Guides et Tutoriels</a></li>
                                            </ul>
                                        </div>
                                    </li>
                                </ul>   
                            </div>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Réseaux</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/CECAM.html">CECAM-FR-RA</a></li> 
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/FLMSN.html">FLMSN</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/IXXI.html">IXXI</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/PBIL.html">Pôle Bioinformatique Lyonnais</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/CIRA.html">CIRA: Calcul intensif en Rhône-Alpes</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/GDR.html">GDR Calcul</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/LC.html">LyonCalcul</a></li>
                                    <li><a class="dropdown-item" href="../../R%C3%A9seaux/Sierra.html">Sierra</a></li>
                                </ul>
                            </div>
                        </li>
                        
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#">Contacts</a>
                            <div class="dropdown-menu">
                                <ul>
                                    <li><a class="dropdown-item" href="../../Contacts/Acces.html ">Accès aux sites</a></li>
                                    <li><a class="dropdown-item" href="../../Contacts/Equipe.html">Équipe / Staff</a></li>                                        
                                    <li><a class="dropdown-item" href="../../Contacts/Calendrier.html">Calendrier & réservations de la salle TP</a></li>
                                    <li><a class="dropdown-item" href="../../Contacts/Formulaires.html">Formulaires</a></li>
                                </ul>   
                            </div>
                        </li>  
                    </ul>
                </div>
                <div class="container w-25">

<search id="searchbox" role="search">
    <form class="d-flex" style="height: 35px;" action="../../search.html" method="get">
      <input class="form-control me-2 input-search" type="text" name="q" placeholder="Rechercher" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input class="btn btn-search" type="submit" value="Go" />
    </form>
</search>

                </div>

            </div>
        </nav>
</header>
              <div class="pt-4 border-top border-secondary" id="contenu">
                
  <section id="tp-insa-2019-2020-le-gpu-par-la-pratique">
<span id="insagpu"></span><h1>TP INSA 2019-2020 : le GPU par la pratique<a class="headerlink" href="#tp-insa-2019-2020-le-gpu-par-la-pratique" title="Lien vers cette rubrique">¶</a></h1>
<p>Cette session pratique accompagne le <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/PresentationGPU_190606_EQ.pdf">cours</a> du 9 décembre au matin réalisé par Emmanuel Quémener.</p>
<section id="cqqcoqp-comment-qui-quand-combien-ou-quoi-pourquoi">
<h2>CQQCOQP : Comment ? Qui ? Quand ? Combien ? Où ? Quoi ? Pourquoi ?<a class="headerlink" href="#cqqcoqp-comment-qui-quand-combien-ou-quoi-pourquoi" title="Lien vers cette rubrique">¶</a></h2>
<ul class="simple">
<li><p><strong>Pourquoi ?</strong> Faire un tour d’horizon des GPUs et appréhender des méthodes d’investigation</p></li>
<li><p><strong>Quoi ?</strong> Tester les GPU sur des exemples simples pendant deux séances de 4 heures</p></li>
<li><p><strong>Quand ?</strong> Les lundi 9 décembre 2019, 6 janvier 2020, 13 janvier 2020, 20 janvier 2020</p></li>
<li><p><strong>Combien ?</strong> Mesurer la performance que les GPUs offrent en comparaison des autres machines</p></li>
<li><p><strong>Où ?</strong> Sur des stations de travail, des noeuds de cluster, des portables (bien configurés), dans des terminaux</p></li>
<li><p><strong>Qui ?</strong> Pour les édudiants, enseignants, chercheurs, personnels techniques curieux</p></li>
<li><p><strong>Comment ?</strong> En appliquant quelques commandes simples, généralement dans des terminaux.</p></li>
</ul>
</section>
<section id="but-de-la-session">
<h2>But de la session<a class="headerlink" href="#but-de-la-session" title="Lien vers cette rubrique">¶</a></h2>
<p>C’est de prendre en main les GPU dans les machines, de comparer les performances avec des CPU classiques par l’intermédiaire de quelques exemples simples et des codes de production.</p>
</section>
<section id="deroulement-de-la-session">
<h2>Déroulement de la session<a class="headerlink" href="#deroulement-de-la-session" title="Lien vers cette rubrique">¶</a></h2>
<ul class="simple">
<li><p>Investiguer le matériel GPU</p></li>
<li><p>Exploration avec le « ​coeur »​ du GPU : xGEMM</p></li>
<li><p>Exploration des GPU avec un Pi Monte Carlo</p></li>
<li><p>Exploration par un corps N-Corps à « grain fin » : <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code></p></li>
<li><p>Exploration de « codes métier » : <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>, <a class="reference external" href="https://bitbucket.org/dpotter/pkdgrav3">PKDGRAV3</a> et <a class="reference external" href="http://www.gromacs.org/">Gromacs</a></p></li>
</ul>
</section>
<section id="demarrage-de-la-session">
<h2>Démarrage de la session<a class="headerlink" href="#demarrage-de-la-session" title="Lien vers cette rubrique">¶</a></h2>
<section id="prerequis-en-materiel-logiciel-et-humain">
<h3>Prérequis en matériel, logiciel et humain<a class="headerlink" href="#prerequis-en-materiel-logiciel-et-humain" title="Lien vers cette rubrique">¶</a></h3>
<p>De manière à proposer un environnement pleinement fonctionnel, le Centre Blaise Pascal fournit le matériel, les logiciels et un OS correctement intégré. Les personnes qui veulent réaliser cette session sur leur laptop doivent disposer d’un « vrai » système d’exploitation de type Unix, équipé de tout l’environnement adéquat.</p>
<section id="prerequis-pour-le-materiel">
<h4>Prérequis pour le matériel<a class="headerlink" href="#prerequis-pour-le-materiel" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Si vous utilisez le CBP, juste le login est nécessaire</p></li>
<li><p>Si vous n’utilisez PAS le CBP, une machine relativement récente avec un GPU intégré, de préférence Nvidia</p></li>
</ul>
</section>
<section id="prerequis-pour-le-logiciel">
<h4>Prérequis pour le logiciel<a class="headerlink" href="#prerequis-pour-le-logiciel" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Une session graphique sur une station de travail, plusieurs terminaux et votre navigateur favori</p></li>
<li><p>Si vous n’utilisez pas le CBP, un OS GNU/Linux correctement configuré pour le GPU embarqué avec tous les composants Nvidia, OpenCL, PyOpenCL, PyCUDA.</p></li>
</ul>
<p>Les personnes voulant exploiter de gros GPU ou GPGPU peuvent se connecter sur les machines suivantes :</p>
<ul class="simple">
<li><p><strong>gtx1080alpha</strong>, <strong>gtx1080beta</strong>, <strong>gtx1080gamma</strong>, <strong>gtx1080delta</strong> : stations virtuelles disposant de Nvidia GTX 1080</p></li>
<li><p><strong>k80alpha</strong>, <strong>k80beta</strong>, <strong>k80gamma</strong> : stations virtuelles disposant d’1, 1 et 2 GPU de Nvidia Tesla K80</p></li>
<li><p><strong>p100alpha</strong>, <strong>p100beta</strong> : stations virtuelles disposant d’une Nvidia Tesla P100</p></li>
<li><p><strong>p100gamma</strong> : station virtuelle disposant de 2 Nvidia Tesla P100</p></li>
<li><p><strong>k40m</strong> : station virtuelle disposant d’une Nvidia Tesla K40m</p></li>
</ul>
<p>Jetez un coup d’oeil sur <a class="reference external" href="http://styx.cbp.ens-lyon.fr/ganglia/?r=hour&amp;cs=&amp;ce=&amp;m=load_one&amp;s=by+name&amp;c=Workstations">Monitoring des stations de travail</a> avant de lancer vos tâches ! De grosses requêtes concurrentielles peuvent entraîner des DoS !</p>
</section>
<section id="prerequis-pour-l-humain">
<h4>Prérequis pour l’humain<a class="headerlink" href="#prerequis-pour-l-humain" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Une allergie à la commande en ligne peut dramatiquement réduire la portée de cette session pratique</p></li>
<li><p>Une pratique des scripts shell sera un avantage, sinon vous avez cette session pour parfaire vos connaissances.</p></li>
</ul>
</section>
</section>
</section>
<section id="investiguer-le-materiel-gpu">
<h2>Investiguer le matériel GPU<a class="headerlink" href="#investiguer-le-materiel-gpu" title="Lien vers cette rubrique">¶</a></h2>
<section id="qu-y-a-t-il-dans-ma-machine">
<h3>Qu’y a-t-il dans ma machine ?<a class="headerlink" href="#qu-y-a-t-il-dans-ma-machine" title="Lien vers cette rubrique">¶</a></h3>
<p>Le matériel en Informatique Scientifique est défini par <a class="reference external" href="https://upload.wikimedia.org/wikipedia/commons/e/e5/Von_Neumann_Architecture.svg">l’architecture de Von Neumann</a>:</p>
<ul class="simple">
<li><p>CPU (Unité Centrale de Traitement) avec CU (Unité de Contrôle) et ALU (Unité Arithmétique &amp; Logique)</p></li>
<li><p>MU (Unité de Mémoire)</p></li>
<li><p>Input and Output Devices : Périphériques d’Entrée et Sortie</p></li>
</ul>
<p>Les GPU sont généralement considérés comme des périphériques d’Entrée/Sortie. Comme la plupart des périphériques installés dans les machines, ils exploitent un bus d’interconnexion <a class="reference external" href="https://en.wikipedia.org/wiki/Conventional_PCI">PCI</a> ou <a class="reference external" href="https://en.wikipedia.org/wiki/PCI_Express">PCI Express</a>.</p>
<p>Pour récupérer la liste des périphériques PCI, utilisez la commande <code class="docutils literal notranslate"><span class="pre">lspci</span> <span class="pre">-nn</span></code>. A l’intérieur d’une longue liste apparaissent quelques périphériques <strong>VGA</strong> ou <strong>3D</strong>. Ce sont les périphériques GPU ou GPGPU.</p>
<p>Voici une sortie de la commande <code class="docutils literal notranslate"><span class="pre">lspci</span> <span class="pre">-nn</span> <span class="pre">|</span> <span class="pre">egrep</span> <span class="pre">'(VGA|3D)'</span></code> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>3b:00.0<span class="w"> </span>VGA<span class="w"> </span>compatible<span class="w"> </span>controller<span class="w"> </span><span class="o">[</span><span class="m">0300</span><span class="o">]</span>:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation<span class="w"> </span>GP102<span class="w"> </span><span class="o">[</span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti<span class="o">]</span><span class="w"> </span><span class="o">[</span>10de:1b06<span class="o">]</span><span class="w"> </span><span class="o">(</span>rev<span class="w"> </span>a1<span class="o">)</span>
a1:00.0<span class="w"> </span>VGA<span class="w"> </span>compatible<span class="w"> </span>controller<span class="w"> </span><span class="o">[</span><span class="m">0300</span><span class="o">]</span>:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation<span class="w"> </span>GK107GL<span class="w"> </span><span class="o">[</span>Quadro<span class="w"> </span>K420<span class="o">]</span><span class="w"> </span><span class="o">[</span>10de:0ff3<span class="o">]</span><span class="w"> </span><span class="o">(</span>rev<span class="w"> </span>a1<span class="o">)</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #1: récuperez la liste des périphériques (GP)GPU</strong></p>
<ul class="simple">
<li><p>Combien de périphériques VGA sont listés ?</p></li>
<li><p>Combien de périphériques 3D sont listés ?</p></li>
<li><p>Récupérez le modèle du circuit de GPU, dans son nom étendu.</p></li>
<li><dl class="simple">
<dt>Récupérez sur le web les informations suivantes pour chaque GPU :</dt><dd><ul>
<li><p>le nombre d’unités de calcul (les « cuda cores » ou les « stream processors »)</p></li>
<li><p>la fréquence de base des coeurs de calcul</p></li>
<li><p>la fréquence de la mémoire</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<p>La totalité des stations de travail contiennent des cartes Nvidia.</p>
<p>Dans les systèmes <strong>Posix</strong> (<strong>Unix</strong> dans le langage courant), tout est fichier. Les informations sur les circuits Nvidia et leur découverte par le système d’exploitation peuvent être récupérées avec un <code class="docutils literal notranslate"><span class="pre">grep</span></code> dans la commande <code class="docutils literal notranslate"><span class="pre">dmesg</span></code>.</p>
<p>Si le démarrage de la machine n’est pas trop ancien, vous disposez des informations comparables aux suivantes :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="w">   </span><span class="m">19</span>.545688<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>The<span class="w"> </span>NVIDIA<span class="w"> </span>GPU<span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w"> </span><span class="o">(</span>PCI<span class="w"> </span>ID:<span class="w"> </span>10de:1b06<span class="o">)</span>
<span class="w">            </span>NVRM:<span class="w"> </span>NVIDIA<span class="w"> </span>Linux<span class="w"> </span>driver<span class="w"> </span>release.<span class="w">  </span>Please<span class="w"> </span>see<span class="w"> </span><span class="s1">&#39;Appendix</span>
<span class="s1">            NVRM: A - Supported NVIDIA GPU Products&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>this<span class="w"> </span>release<span class="err">&#39;</span>s
<span class="w">            </span>NVRM:<span class="w"> </span>at<span class="w"> </span>www.nvidia.com.
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.545903<span class="o">]</span><span class="w"> </span>nvidia:<span class="w"> </span>probe<span class="w"> </span>of<span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w"> </span>failed<span class="w"> </span>with<span class="w"> </span>error<span class="w"> </span>-1
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.546254<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>The<span class="w"> </span>NVIDIA<span class="w"> </span>probe<span class="w"> </span>routine<span class="w"> </span>failed<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>device<span class="o">(</span>s<span class="o">)</span>.
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.546491<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>None<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>NVIDIA<span class="w"> </span>graphics<span class="w"> </span>adapters<span class="w"> </span>were<span class="w"> </span>initialized!
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.782970<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.783084<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.814046<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Loading<span class="w"> </span>NVIDIA<span class="w"> </span>Kernel<span class="w"> </span>Mode<span class="w"> </span>Setting<span class="w"> </span>Driver<span class="w"> </span><span class="k">for</span><span class="w"> </span>UNIX<span class="w"> </span>platforms<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:33:30<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span>
<span class="o">[</span><span class="w">   </span><span class="m">20</span>.264453<span class="o">]</span><span class="w"> </span><span class="o">[</span>drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>nvidia-drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>GPU<span class="w"> </span>ID<span class="w"> </span>0x00008200<span class="o">]</span><span class="w"> </span>Loading<span class="w"> </span>driver
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360807<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">3</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input19
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360885<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">7</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input20
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360996<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">8</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input21
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.361065<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">9</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input22
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.896510<span class="o">]</span><span class="w"> </span><span class="o">[</span>drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>nvidia-drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>GPU<span class="w"> </span>ID<span class="w"> </span>0x00008200<span class="o">]</span><span class="w"> </span>Unloading<span class="w"> </span>driver
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.935658<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Unloading
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.967939<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Unregistered<span class="w"> </span>the<span class="w"> </span>Nvlink<span class="w"> </span>Core,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.034671<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.034724<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.275804<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Unregistered<span class="w"> </span>the<span class="w"> </span>Nvlink<span class="w"> </span>Core,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.993460<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.993486<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">35</span>.110461<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Loading<span class="w"> </span>NVIDIA<span class="w"> </span>Kernel<span class="w"> </span>Mode<span class="w"> </span>Setting<span class="w"> </span>Driver<span class="w"> </span><span class="k">for</span><span class="w"> </span>UNIX<span class="w"> </span>platforms<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:33:30<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span>
<span class="o">[</span><span class="w">   </span><span class="m">35</span>.111628<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Allocated<span class="w"> </span>GPU:0<span class="w"> </span><span class="o">(</span>GPU-ccc95482-6681-052e-eb30-20b138412b92<span class="o">)</span><span class="w"> </span>@<span class="w"> </span>PCI:0000:82:00.0
<span class="o">[</span><span class="m">349272</span>.210486<span class="o">]</span><span class="w"> </span>nvidia-uvm:<span class="w"> </span>Loaded<span class="w"> </span>the<span class="w"> </span>UVM<span class="w"> </span>driver<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">8</span><span class="w"> </span>mode,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">243</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #2 : récupérez les informations de votre machine avec `dmesg | grep -i nvidia`</strong></p>
<ul class="simple">
<li><p>Quelle est la version de pilote chargée par le noyau ?</p></li>
<li><p>Que représente, s’il existe, le  périphérique <code class="docutils literal notranslate"><span class="pre">input:</span> <span class="pre">HDA</span> <span class="pre">NVidia</span></code> ?</p></li>
<li><p>Est-ce un périphérique graphique ?</p></li>
</ul>
</div>
<p>Le <code class="docutils literal notranslate"><span class="pre">lsmod</span></code> offre la liste des modules chargés par le noyau. Ces modules sont de petits programmes dédiés au support d’une fontion très spécifique du noyau, le moteur du système d’exploitation. Le support d’un périphérique nécessite souvent plusieurs modules.</p>
<p>Un exemple de <code class="docutils literal notranslate"><span class="pre">lsmod</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">nvidia</span></code> sur une station de travail :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvidia_uvm<span class="w">            </span><span class="m">778240</span><span class="w">  </span><span class="m">0</span>
nvidia_drm<span class="w">             </span><span class="m">40960</span><span class="w">  </span><span class="m">4</span>
nvidia_modeset<span class="w">       </span><span class="m">1044480</span><span class="w">  </span><span class="m">3</span><span class="w"> </span>nvidia_drm
nvidia<span class="w">              </span><span class="m">16797696</span><span class="w">  </span><span class="m">108</span><span class="w"> </span>nvidia_modeset,nvidia_uvm
ipmi_msghandler<span class="w">        </span><span class="m">49152</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>nvidia
drm_kms_helper<span class="w">        </span><span class="m">155648</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>nvidia_drm
drm<span class="w">                   </span><span class="m">360448</span><span class="w">  </span><span class="m">7</span><span class="w"> </span>nvidia_drm,drm_kms_helper
</pre></div>
</div>
<p>Nous voyons que 4 modules sont chargés. La dernière colonne (vide pour les deux premières lignes) liste les dépendances entre les modules. Ici <code class="docutils literal notranslate"><span class="pre">nvidia_modeset</span></code> and <code class="docutils literal notranslate"><span class="pre">nvidia_uvm</span></code> dépendent du module <code class="docutils literal notranslate"><span class="pre">nvidia</span></code>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #3 : récupérez les informations de l’hôte par la commande `lsmod | grep nvidia`</strong></p>
<ul class="simple">
<li><p>Les informations sont-elles identiques à celles ci-dessus ? Caractère par caractère ?</p></li>
</ul>
</div>
<p>Le périphérique apparaît également dans le dossier <code class="docutils literal notranslate"><span class="pre">/dev</span></code> (pour <em>device</em>), le dossier parent pour tous les périphériques.</p>
<p>Un <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span> <span class="pre">/dev/nvidia*</span></code> offre ce genre d’informations :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w">   </span><span class="m">0</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidia0
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w"> </span><span class="m">255</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidiactl
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w"> </span><span class="m">254</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidia-modeset
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">243</span>,<span class="w">   </span><span class="m">0</span><span class="w"> </span>Jul<span class="w">  </span><span class="m">4</span><span class="w"> </span><span class="m">19</span>:17<span class="w"> </span>/dev/nvidia-uvm
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">243</span>,<span class="w">   </span><span class="m">1</span><span class="w"> </span>Jul<span class="w">  </span><span class="m">4</span><span class="w"> </span><span class="m">19</span>:17<span class="w"> </span>/dev/nvidia-uvm-tools
</pre></div>
</div>
<p>Vous pouvez voir que chacun peut accéder au périphérique, à la fois en lecture ET en écriture (le <code class="docutils literal notranslate"><span class="pre">RW</span></code>). Ici, vous avez un seul périphérique Nvidia, <code class="docutils literal notranslate"><span class="pre">nvidia0</span></code>. Sur une machine disposant de plusieurs périphériques Nvidia, nous aurions : <code class="docutils literal notranslate"><span class="pre">nvidia0</span></code>, <code class="docutils literal notranslate"><span class="pre">nvidia1</span></code>, etc…</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #4 : récupérez les informations de votre machine avec `ls -l /dev/* | grep -i nvidia`</strong></p>
<ul class="simple">
<li><p>Combien de <code class="docutils literal notranslate"><span class="pre">/dev/nvidia&lt;number&gt;</span></code> avez-vous ?</p></li>
<li><p>Cette information est-elle cohérente avec les 3 précédentes ?</p></li>
</ul>
</div>
<p>Nvidia présente des informations sur l’usage instantané de ses circuits avec la commande <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>. Cette commande peut aussi être exploitée pour régler certains paramètres du GPU.</p>
<p>Voici un exemple de sortie de la commande <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Fri<span class="w"> </span>Jul<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">07</span>:46:56<span class="w"> </span><span class="m">2017</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">375</span>.66<span class="w">                 </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">375</span>.66<span class="w">                    </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w">      </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">23</span>%<span class="w">   </span>31C<span class="w">    </span>P8<span class="w">    </span>10W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">     </span>35MiB<span class="w"> </span>/<span class="w"> </span>11172MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">  </span>Type<span class="w">  </span>Process<span class="w"> </span>name<span class="w">                               </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">4108</span><span class="w">    </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                              </span>32MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Beaucoup d’informations sont disponibles sur cette sortie :</p>
<ul class="simple">
<li><p>version du pilote et du logiciel <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></p></li>
<li><p>l’identifiant de chaque GPU</p></li>
<li><p>son nom</p></li>
<li><p>sa localisation sur le bus PCIe</p></li>
<li><p>sa vitesse de ventilateur</p></li>
<li><p>sa température</p></li>
<li><p>ses puissances : instantanée et maximale</p></li>
<li><p>ses « occupations » mémoire : instantanée et maximale</p></li>
<li><p>les processus les exploitant, leur consommation de mémoire et le GPU associé</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #5 : récupérez les informations avec la commande `nvidia-smi`</strong></p>
<ul class="simple">
<li><p>Identifiez les caractéristiques ci-dessus et comparer les éléments</p></li>
<li><p>Combien de processus sont-ils listés ?</p></li>
</ul>
</div>
<p>Comme nous l’avons vu dans l’introduction sur le GPU, leur programmation peut-être réalisée par différentes voies. La première, pour les périphériques Nvidia, est d’utiliser l’environnement CUDA. Le problème sera qu’il est impossible de réexploiter votre programme sur une autre plate-forme (un CPU) ou la comparer avec d’autres GPU. <a class="reference external" href="https://www.khronos.org/opencl/">OpenCL</a> reste une approche beaucoup plus polyvalente !</p>
<p>Sur les stations du CBP, la majorité des implémentations de OpenCL sont disponibles, autant sur CPU que sur GPU.</p>
<p>La commande <code class="docutils literal notranslate"><span class="pre">clinfo</span></code> récupère des informations liées à tous les périphériques OpenCL disponibles.
Pour récupérer une sortie compacte, utilisez <code class="docutils literal notranslate"><span class="pre">clinfo</span> <span class="pre">'-l'</span></code>.</p>
<p>Tous les périphériques OpenCL sont présentés suivant une hiérarchie plateforme/périphérique (<code class="docutils literal notranslate"><span class="pre">Platform/Device</span></code>).</p>
<p>Voici une sortie de <code class="docutils literal notranslate"><span class="pre">clinfo</span> <span class="pre">'-l'</span></code> pour une des stations de travail :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Platform<span class="w"> </span><span class="c1">#0: AMD Accelerated Parallel Processing</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Platform<span class="w"> </span><span class="c1">#1: Portable Computing Language</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Platform<span class="w"> </span><span class="c1">#2: NVIDIA CUDA</span>
+--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: GeForce GTX 1080 Ti</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#1: Quadro K420</span>
Platform<span class="w"> </span><span class="c1">#3: Intel(R) OpenCL</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">#0,#0</span></code> <strong>AMD Accelerated Parallel Processing</strong> : implémentation CPU de AMD, la plus ancienne, très proche de OpenMP en performances</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">#1,#0</span></code> <strong>Portable Computing Language</strong> : implémentation CPU OpenSource. Pas vraiment efficace</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">#2,#0</span></code> <strong>Nvidia CUDA</strong> : implémentation CUDA de Nvidia, périphérique 0, une GeForce GTX 1080 Ti</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">#2,#1</span></code> <strong>Nvidia CUDA</strong> : implémentation CUDA de Nvidia, périphérique 1, une Quadro K420</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">#3,#0</span></code> <strong>Intel(R) OpenCL</strong> : implémentation CPU Intel, plutôt très efficace</p></li>
</ul>
<p>Ainsi, dans cette machine, 5 périphériques OpenCL sont accessibles, 3 permettent de s’adresser au processeur (vu pour le coup comme un périphérique) et 2 sont des GPU Nvidia.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #6 : récupérez les informations avec la commande `clinfo -l`</strong></p>
<ul class="simple">
<li><p>Identifiez et comparez votre sortie avec la liste ci-dessus</p></li>
<li><p>De combien de périphériques graphiques disposez-vous ?</p></li>
</ul>
</div>
<p>L’appel de la commande <code class="docutils literal notranslate"><span class="pre">clinfo</span></code> fournit également de nombreuses informations. Cependant, il est impossible avec cette commande de ne récupérer les informations que d’un seul périphérique : la commande <code class="docutils literal notranslate"><span class="pre">egrep</span></code> permet alors de restreindre seulement certains attributs, par exemple <code class="docutils literal notranslate"><span class="pre">Platform</span> <span class="pre">Name</span></code>, <code class="docutils literal notranslate"><span class="pre">Device</span> <span class="pre">Name</span></code>, <code class="docutils literal notranslate"><span class="pre">Max</span> <span class="pre">compute</span></code>, <code class="docutils literal notranslate"><span class="pre">Max</span> <span class="pre">clock</span></code></p>
<p>Sur la plateforme précédente, la commande <code class="docutils literal notranslate"><span class="pre">clinfo</span> <span class="pre">|</span> <span class="pre">egrep</span> <span class="pre">'(Platform</span> <span class="pre">Name|Device</span> <span class="pre">Name|Max</span> <span class="pre">compute|Max</span> <span class="pre">clock)'</span></code> offre comme sortie:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Platform<span class="w"> </span>Name<span class="w">                                   </span>AMD<span class="w"> </span>Accelerated<span class="w"> </span>Parallel<span class="w"> </span>Processing
Platform<span class="w"> </span>Name<span class="w">                                   </span>Portable<span class="w"> </span>Computing<span class="w"> </span>Language
Platform<span class="w"> </span>Name<span class="w">                                   </span>NVIDIA<span class="w"> </span>CUDA
Platform<span class="w"> </span>Name<span class="w">                                   </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>OpenCL
Platform<span class="w"> </span>Name<span class="w">                                   </span>AMD<span class="w"> </span>Accelerated<span class="w"> </span>Parallel<span class="w"> </span>Processing
Device<span class="w"> </span>Name<span class="w">                                     </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>1200MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>Portable<span class="w"> </span>Computing<span class="w"> </span>Language
Device<span class="w"> </span>Name<span class="w">                                     </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>3501MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>NVIDIA<span class="w"> </span>CUDA
Device<span class="w"> </span>Name<span class="w">                                     </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">28</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>1582MHz
Device<span class="w"> </span>Name<span class="w">                                     </span>Quadro<span class="w"> </span>K420
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">1</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>875MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>OpenCL
Device<span class="w"> </span>Name<span class="w">                                     </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>3500MHz
</pre></div>
</div>
<p>Nous distinguons bien les éléments des 5 périphériques OpenCL déjà identifiés au-dessus (3 pour les 3 implémentations de CPU, respectivement d’AMD, PortableCL et Intel) et les deux GPU Nvidia (GTX 1080 Ti et Quadro K420).</p>
<p>Nous constatons par exemple que les nombres d’unités de traitement sont identiques pour les implémentations CPU (16) mais que leurs fréquences ne le sont pas (1200, 3501, 3500 MHz).</p>
<p>L’implémentation AMD récupère, elle, la fréquence instantanée, et les deux autres la fréquence maximale.</p>
<p>Pour les GPU, nous constatons que les fréquences sont bien inférieures à celles des GPU (1582 et 875 MHz).</p>
<p>Quant aux nombres d’unités de calcul (<em>compute units</em>), la première en dispose de 28 et la seconde de 1. Il sera donc intéressant de comparer ces valeurs par rapport aux valeurs trouvables dans les spécifications constructeur.</p>
<p>La notion d’unité de traitement (<em>compute unit</em>) pour les CPU n’est pas la même pour les GPU:</p>
<ul class="simple">
<li><p>pour les CPU, c’est généralement le produit du nombre de coeurs physiques et du nombre de <em>threads</em></p></li>
<li><p>pour les GPU, c’est le nombre de macro-unités de traitement : unité <strong>SM</strong> (pour <em>Stream multiprocessor</em>) chez Nvidia, unité <strong>CU</strong> (pour <em>Compute Unit</em>) chez AMD/ATI.</p></li>
</ul>
<p>Ces unités de traitement disposent (autant pour les GPU que les CPU) d’unités arithmétiques et logiques (<em>Arithmetic and Login Unit</em>) lesquelles sont <em>vraiment</em> en charge du traitement des opérations.</p>
<p>Ainsi, le nombre d’ALU dans chaque <em>Compute Unit</em> varie de 64 à 192 selon les générations de GPU. Ainsi, pour le GPU ci-dessus GTX 1080 Ti, le nombre de <em>Compute Unit</em> mentionné est 28, et le nombre d’ALU (appelé également <em>cuda core</em> par Nvidia) est de 3584 soit 28*128. Le schéma du constructeur du circuit GP102 suivant est trompeur : en fait, il dispose de 30 unités SM, mais sur un GP102, seuls 28 sont activés.</p>
<img alt="Diagramme GP102" class="img-fluid center" src="../../_images/gp102-block-diagram.jpg" />
<div class="note note-warning docutils container">
<p><strong>Exercice #7 : récupérez les informations à l’aide de deux commandes précédentes utilisant `clinfo`</strong></p>
<ul class="simple">
<li><p>Comparez les informations entre les implémentations CPU. Pourquoi ces différences ?</p></li>
<li><p>Comparez le nombre d’unités de traitement des CPU avec celles du Web : <a class="reference external" href="https://ark.intel.com/fr">Ark d’Intel</a></p></li>
<li><p>Comparez le nombre d’unités de traitement des GPU avec celles du Web : site <a class="reference external" href="https://www.nvidia.com/page/products.html#Architectures">spécifications</a> de Nvidia ou Wikipedia</p></li>
<li><p>Comparez les fréquences identifiées avec celles trouvées sur le Web.</p></li>
<li><p>Retrouvez-vous une cohérence entre le nombre de <em>Compute Units</em> et le nombre de <em>cuda cores</em> ?</p></li>
<li><p>Combien de <em>cuda cores</em> contient chaque <em>Compute Unit</em> ?</p></li>
</ul>
</div>
<p>Il est aussi possible de choisir quel GPU Nvidia exploiter avec la variable d’environnement <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>. Il existe deux manières de l’exploiter :</p>
<ul class="simple">
<li><p>en préfixant la commande à exécuter (ou son programme) par <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=#GPU</span></code></p></li>
<li><p>en <em>exportant</em> la variable de manière permanente avec : <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">CUDA_VISIBLE_DEVICES=#GPU</span></code></p></li>
</ul>
<p>La commande <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> offrait une liste de périphériques Nvidia identifiés mais les <code class="docutils literal notranslate"><span class="pre">ID</span></code> donnés sont dans l’ordre inverse de celui exigé par <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>. Par exemple, <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> donne comme <code class="docutils literal notranslate"><span class="pre">ID</span></code> les nombres <code class="docutils literal notranslate"><span class="pre">0</span></code> et <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># N&#39;exploiter que le GPU identifie #0 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># N&#39;exploiter que le GPU identifie #1 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># Exploiter les GPUs identifies #0 et #1 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># N&#39;exploiter aucun GPU</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="sb">``</span><span class="w"> </span>&lt;MonProgramme&gt;
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #8 : récupérez les informations avec `clinfo -l` préfixée de CUDA_VISIBLE_DEVICES</strong></p>
<ul class="simple">
<li><p>Mettez <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=0</span> <span class="pre">clinfo</span> <span class="pre">-l</span></code> et observez la sortie</p></li>
<li><p>Mettez <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=1</span> <span class="pre">clinfo</span> <span class="pre">-l</span></code> et observez la sortie</p></li>
<li><p>Mettez <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=0,1</span> <span class="pre">clinfo</span> <span class="pre">-l</span></code> et observez la sortie</p></li>
<li><p>Mettez <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=\'\'</span> <span class="pre">clinfo</span> <span class="pre">-l</span></code> et observez la sortie</p></li>
<li><p>Avez-vous constaté la sélection des différents périphériques ?</p></li>
</ul>
</div>
</section>
</section>
<section id="exploration-avec-le-coeur-du-gpu-xgemm">
<h2>Exploration avec le « coeur » du GPU : xGEMM<a class="headerlink" href="#exploration-avec-le-coeur-du-gpu-xgemm" title="Lien vers cette rubrique">¶</a></h2>
<p>Dans l’introduction sur les GPU, il était présenté le GPU comme un « gros » multiplicateur de matrices.</p>
<p>En effet, la méthode par <em>shadering</em> exploitait de nombreuses multiplications matricielles pour générer une image numérique (CGI ou <em>Compute Generated Image</em>). Il n’est donc pas étonnant que les GPU soient, historiquement, plutôt « efficaces » pour ce type de tâches : nous allons l’évaluer.</p>
<section id="de-blas-aux-xgemm-les-differentes-implementations">
<h3>De BLAS aux xGEMM : les différentes implémentations<a class="headerlink" href="#de-blas-aux-xgemm-les-differentes-implementations" title="Lien vers cette rubrique">¶</a></h3>
<p>En calcul scientifique, l’objectif est de ne pas réinventer la roue à chaque modélisation numérique. Depuis presque 40 ans, la libraire d’algèbre linéaire la plus courante est la BLAS pour <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">Basic Linear Algebra Subprograms</a>.</p>
<p>Ces routines peuvent être considérées comme des <em>standards</em>. De nombreuses implémentations existent pour toutes les architectures. Sur GPU, Nvidia propose sa propre version avec <a class="reference external" href="http://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a> et AMD a placé en <em>Open Source</em> la sienne <a class="reference external" href="https://github.com/clMathLibraries/clBLAS">clBLAS</a>.</p>
<p>Sur les CPU, Intel propose son implémentation largement optimisée pour ses processeurs au sein des <a class="reference external" href="https://software.intel.com/en-us/mkl">librairies MKL</a> mais les versions Open Sourcen notamment <a class="reference external" href="http://www.openblas.net/">OpenBLAS</a>, n’ont rien à leur envier. D’autres implémentations sont installées au CBP : l”<a class="reference external" href="http://math-atlas.sourceforge.net/">ATLAS</a> et la <a class="reference external" href="https://www.gnu.org/software/gsl/">GSL</a>.</p>
<p>Les librairies BLAS sont dans 3 catégories : celles manipulant exclusivement les vecteurs (1 dimension), celles manipulant les matrices et les vecteurs (1 et 2 dimensions), enfin celles manipulant exclusivement les matrices (2 dimensions).</p>
<p>L’implémentation de la multiplication de matrices dans les libairies BLAS est la <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code>, avec <code class="docutils literal notranslate"><span class="pre">x</span></code> à remplacer par <code class="docutils literal notranslate"><span class="pre">S</span></code>, <code class="docutils literal notranslate"><span class="pre">D</span></code>, <code class="docutils literal notranslate"><span class="pre">C</span></code> et <code class="docutils literal notranslate"><span class="pre">Z</span></code> respectivement pour la <strong>S</strong> imple précision (32 bits), la <strong>D</strong> ouble précision (64 bits), la <strong>C</strong> omplexe &amp; simple précision et complexe &amp; double précision ( <strong>Z</strong> ).</p>
<p>L’objectif de cette première manipulation est de commencer à comparer les GPU et les CPU avec cette opération simple.</p>
<section id="recuperation-des-sources">
<h4>Récupération des sources<a class="headerlink" href="#recuperation-des-sources" title="Lien vers cette rubrique">¶</a></h4>
<p>La (presque) totalité des outils exploités par le CBP pour comparer les CPU et les GPU se trouve dans le projet <a class="reference external" href="https://forge.cbp.ens-lyon.fr/redmine/projects/bench4gpu">bench4gpu</a> du Centre Blaise Pascal.</p>
<p>La récupération des sources est libre et se réalise par l’outil subversion :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>svn<span class="w"> </span>checkout<span class="w"> </span>https://forge.cbp.ens-lyon.fr/svn/bench4gpu/
</pre></div>
</div>
<p>Dans ce dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu</span></code>, il y a plusieurs dossiers :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BLAS</span></code> contenant les dossiers <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> et <code class="docutils literal notranslate"><span class="pre">xTRSV</span></code> : tests exploitant toutes les implémentations de librairies BLAS</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Epidevomath</span></code> : un prototype d’implémentation sur GPU d’un projet (abandonné)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FFT</span></code> contenant une première exploitation de <strong>cuFFT</strong> (en suspens)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Ising</span></code> : implémentations multiples du <a class="reference external" href="https://fr.wikipedia.org/wiki/Mod%C3%A8le_d%27Ising">modèle d’Ising</a> en Python (multiples parallélisations)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NBody</span></code> : implémentation en OpenCL d’un modèle N-Corps newtonien</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi</span></code> : implémentation multiples d’un <a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo">Pi Monte Carlo</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Splutter</span></code> : un modèle de <code class="docutils literal notranslate"><span class="pre">postillonneur</span> <span class="pre">mémoire</span></code>, très utile pour évaluer les //fonctions atomiques//</p></li>
</ul>
<p>De tous ces programmes, seuls ceux présents dans <code class="docutils literal notranslate"><span class="pre">BLAS</span></code>, <code class="docutils literal notranslate"><span class="pre">NBody</span></code> et <code class="docutils literal notranslate"><span class="pre">Pi</span></code> seront exploités dans le cadre de ces travaux pratiques.</p>
</section>
</section>
<section id="exploitations-de-xgemm">
<h3>Exploitations de xGEMM<a class="headerlink" href="#exploitations-de-xgemm" title="Lien vers cette rubrique">¶</a></h3>
<p>Le dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu/BLAS/xGEMM</span></code> contient peu de fichiers dont les importants sont : un unique programme source, <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code>, et un fichier de construction, <code class="docutils literal notranslate"><span class="pre">Makefile</span></code>. C’est ce fichier qui va <code class="docutils literal notranslate"><span class="pre">construire</span></code> tous les exécutables d’un coup, à la fois pour les différentes implémentations de BLAS, mais aussi pour les deux précisions <strong>SP</strong> (simple précision sur 32 bits) et <strong>DP</strong> (double précision sur 64 bits).</p>
<section id="le-source">
<h4>Le source<a class="headerlink" href="#le-source" title="Lien vers cette rubrique">¶</a></h4>
<p>Le programme source <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code> a été conçu pour fonctionner avec n’importe quelle implémentation. Si vous l’éditez, vous réalisez qu’il n’est pas si simple d’avoir un programme qui s’exécute indifféremment quelle que soit la librairie. Même si les appels sont comparables (même nombre d’attributs dans les fonctions), leur nom change de librairie à librairie. Pour n’avoir qu’un seul source, les directives sont largement exploitées. C’est donc le <code class="docutils literal notranslate"><span class="pre">Makefile</span></code> qui va permettre de ne compiler que telle ou telle portion du programme source.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #9 : éditez le source du programme `xGEMM.c` et repérez les éléments suivants</strong></p>
<ul class="simple">
<li><p>Identifiez dans <code class="docutils literal notranslate"><span class="pre">Makefile</span></code> quelles directives (précédées par <code class="docutils literal notranslate"><span class="pre">-D</span></code>) sont associées aux différentes implémentations</p></li>
<li><p>Identifiez dans <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code> les « directives » C à base de <code class="docutils literal notranslate"><span class="pre">#ifdef</span></code> utilisées pour séparer les différentes implémentations</p></li>
<li><p>Repérez les deux implémentations <strong>FBLAS</strong> et <strong>OpenBLAS</strong> dans le programme à partir de l’analyse du <code class="docutils literal notranslate"><span class="pre">Makefile</span></code></p></li>
<li><p>Quelle différence existe-t-il dans les appels de la fonction <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> ?</p></li>
<li><p>Repérez les deux implémentations pour GPU Nvidia, les <strong>cublas</strong> et <strong>thunking</strong></p></li>
<li><p>Par quoi se distinguent les versions <strong>cublas</strong> et <strong>thunking</strong> ?*</p></li>
</ul>
</div>
</section>
<section id="les-executables">
<h4>Les exécutables<a class="headerlink" href="#les-executables" title="Lien vers cette rubrique">¶</a></h4>
<p>C’est simplement en lançant la commande <code class="docutils literal notranslate"><span class="pre">make</span></code> dans le dossier que la compilation s’opère. Ainsi, tous les exécutables commencent par <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_</span></code> ou <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_</span></code>. Ils sont ensuite suffixés par l’implémentation BLAS :</p>
<p>Nous avons alors 12 exécutables de la forme <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_&lt;version&gt;</span></code> ou <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_&lt;version&gt;</span></code> :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fblas</span></code> utilisant la librairie ATLAS, pour CPU</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openblas</span></code> utilisant la librairie OpenBLAS, pour CPU</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gsl</span></code> utilisant la librairie GSL (pour <em>GNU Scientific Librairies</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cublas</span></code> utilisant la librairie cuBLAS avec une gestion externe de la mémoire</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thunking</span></code> utilisant la librairie cuBLAS avec une gestion interne de la mémoire</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clblas</span></code> utilisant la librairie clBLAS et OpenCL</p></li>
</ul>
<p>Le programme appelé avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> donne quelques informations pour le lancement.</p>
<p>A l’exception de <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_clblas</span></code> et <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_clblas</span></code>, les paramètres d’entrée sont :</p>
<ul class="simple">
<li><p>la taille de la matrice</p></li>
<li><p>le nombre d’itérations</p></li>
</ul>
<p>Pour les programmes <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_clblas</span></code> et <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_clblas</span></code>, les paramètres d’entrée sont :</p>
<ul class="simple">
<li><p>la taille de la matrice</p></li>
<li><p>le nombre d’itérations</p></li>
<li><p>l’ID de la plateforme</p></li>
<li><p>l’ID du périphérique</p></li>
</ul>
<p>En appelant ces deux exécutables avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code>, le programme détecte les plates-formes et périphériques.</p>
<p>La sortie offre comme informations :</p>
<ul class="simple">
<li><p>la durée moyenne d’exécution de chaque cycle</p></li>
<li><p>l’estimation du nombre de GFlops</p></li>
<li><p>l’erreur estimée par le calcul de la trace des matrices</p></li>
</ul>
<p>Voici quelques exemples de lancement de ces exécutables sur une même machine, pour les CPU exclusivement :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_fblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>FBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1597913000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">25</span>.020
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_gsl<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>GSL:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.4037233000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">2</span>.848
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_openblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0109249000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">365</span>.953
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Voici quelques exemples de lancement de ces exécutables sur une même machine, pour les GPU exclusivement :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3678790000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007630000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007413000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">5393</span>.228
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0447023000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">89</span>.436
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Nous constatons d’abord une grosse disparité de performance. En analysant la durée d’un cycle, nous découvrons qu’il est inférieur à la milliseconde. Nous portons donc le nombre d’itérations à 1000, nous obtenons alors :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3984100000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0006670000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005262330<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">7597</span>.395
Error<span class="w"> </span><span class="m">0</span>.0000000000

root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0073920040<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">540</span>.855
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Il faut donc prendre certaines précautions dans chaque évaluation de performances, notamment lorsque les durées d’exécution sont trop courtes.</p>
<p>Nous avons vu que plusieurs GPU peuvent coexister dans la machine. La question est de savoir lequel est sollicité lors d’un lancement de programme. Par défaut, avec les librairies CUDA, un seul GPU est sollicité, souvent le premier découvert. Pour savoir lequel a fait le travail, nous pouvons exploiter la commande <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> présentée ci-dessus pendant l’exécution du programme.</p>
<p>Dans le premier terminal qui nous sert à l’exécution des programmes, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">100000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">100000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3861840000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007770000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005138863<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">7779</span>.931
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Dans le second terminal, dans lequel nous lançons des commandes de supervision, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:~#<span class="w"> </span>nvidia-smi
Sat<span class="w"> </span>Nov<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">12</span>:10:59<span class="w"> </span><span class="m">2018</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">384</span>.130<span class="w">                </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">384</span>.130<span class="w">                   </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:3B:00.0<span class="w">  </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">27</span>%<span class="w">   </span>52C<span class="w">    </span>P2<span class="w">   </span>254W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">    </span>248MiB<span class="w"> </span>/<span class="w"> </span>11171MiB<span class="w"> </span><span class="p">|</span><span class="w">     </span><span class="m">98</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w">   </span><span class="m">1</span><span class="w">  </span>Quadro<span class="w"> </span>K420<span class="w">         </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:A1:00.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">25</span>%<span class="w">   </span>49C<span class="w">    </span>P8<span class="w">    </span>N/A<span class="w"> </span>/<span class="w">  </span>N/A<span class="w"> </span><span class="p">|</span><span class="w">     </span>12MiB<span class="w"> </span>/<span class="w">  </span>1999MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">   </span>Type<span class="w">   </span>Process<span class="w"> </span>name<span class="w">                             </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6477</span><span class="w">      </span>C<span class="w">   </span>./xGEMM_SP_cublas<span class="w">                            </span>199MiB<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6681</span><span class="w">      </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                            </span>36MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Nous voyons que le GPU #0, identifié comme la GTX 1080 Ti, exécute 2 tâches : <code class="docutils literal notranslate"><span class="pre">/usr/lib/xorg/Xorg</span></code> et <code class="docutils literal notranslate"><span class="pre">./xGEMM_SP_cublas</span></code>. Nous avons également l’empreinte mémoire de chacun des processus : 36MiB pour le <code class="docutils literal notranslate"><span class="pre">Xorg</span></code> et 199MiB pour notre programme <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_cublas</span></code>.</p>
<p>La question légitime est de se demander, dans le cas d’une machine multi-gpu, comment « contrôler » sur quel GPU est exécuté le programme. Il existe des méthodes assez comparables à celles de OpenCL pour la découverte des périphériques, mais elles sont généralement peu exploitées dans les programmes. La technique la plus classique reste l’utilisation d’une variable d’environnement, laquelle va « contraindre » l’exploitation d’un (ou plusieurs) GPU(s) : <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>.</p>
<p>Par exemple, si nous précisons que cette variable vaut <code class="docutils literal notranslate"><span class="pre">1</span></code>, le périphérique Nvidia <code class="docutils literal notranslate"><span class="pre">#1</span></code> sera le seul sollicité. Ainsi, en lançant la commande préfixée de cette variable valuée, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1777080000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005750000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0283741830<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">140</span>.903
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Et pendant l’exécution, dans la fenêtre de commandes de supervision :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:~#<span class="w"> </span>nvidia-smi
Sat<span class="w"> </span>Nov<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">12</span>:21:26<span class="w"> </span><span class="m">2018</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">384</span>.130<span class="w">                </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">384</span>.130<span class="w">                   </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:3B:00.0<span class="w">  </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">24</span>%<span class="w">   </span>37C<span class="w">    </span>P8<span class="w">    </span>12W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">     </span>39MiB<span class="w"> </span>/<span class="w"> </span>11171MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w">   </span><span class="m">1</span><span class="w">  </span>Quadro<span class="w"> </span>K420<span class="w">         </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:A1:00.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">30</span>%<span class="w">   </span>59C<span class="w">    </span>P0<span class="w">    </span>N/A<span class="w"> </span>/<span class="w">  </span>N/A<span class="w"> </span><span class="p">|</span><span class="w">     </span>51MiB<span class="w"> </span>/<span class="w">  </span>1999MiB<span class="w"> </span><span class="p">|</span><span class="w">    </span><span class="m">100</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">   </span>Type<span class="w">   </span>Process<span class="w"> </span>name<span class="w">                             </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6681</span><span class="w">      </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                            </span>36MiB<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">1</span><span class="w">      </span><span class="m">8192</span><span class="w">      </span>C<span class="w">   </span>./xGEMM_SP_cublas<span class="w">                             </span>39MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Nous pouvons évidemment appliquer la même approche du préfixe avec l’autre implémentation CUDA (le mode <em>Thunking</em>) :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0361565210<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">110</span>.575
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Avec les implémentations OpenCL, il est possible, sans variable, de s’adresser avec un unique exécutable, à chacun des périphériques (CPU ou GPU) quelle que soit leur implémentation :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2068470000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0105010000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.6236489000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">6</span>.411
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
./xGEMM_SP_clblas:<span class="w"> </span>symbol<span class="w"> </span>lookup<span class="w"> </span>error:<span class="w"> </span>/root/.cache/pocl/kcache/DO/MOINFKPIFEHKLMFJBAMOHIHHPGDFMKFNMCFAG/sgemm_Col_NN_B0_MX032_NX032_KX08/16-16-1/sgemm_Col_NN_B0_MX032_NX032_KX08.so:<span class="w"> </span>undefined<span class="w"> </span>symbol:<span class="w"> </span>mem_fence
root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
./xGEMM_SP_clblas:<span class="w"> </span>symbol<span class="w"> </span>lookup<span class="w"> </span>error:<span class="w"> </span>/root/.cache/pocl/kcache/DO/MOINFKPIFEHKLMFJBAMOHIHHPGDFMKFNMCFAG/sgemm_Col_NN_B0_MX032_NX032_KX08/16-16-1/sgemm_Col_NN_B0_MX032_NX032_KX08.so:<span class="w"> </span>undefined<span class="w"> </span>symbol:<span class="w"> </span>mem_fence

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>:<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3912880000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0025020000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0029808910<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">1341</span>.210
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">1</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>:<span class="w"> </span>Quadro<span class="w"> </span>K420

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2507630000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0019840000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1263268040<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">31</span>.648
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2919330000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0030360000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1896384000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">21</span>.082
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Nous pouvons également constater que certains périphériques ne « passent » pas en OpenCL et que les performances sont très variables.</p>
<p>Voici un synoptique des performances pour les différentes implémentations et les différents GPU en simple précision. Les performances ont été placées en log. Les GPU présentent des performances incroyablement supérieures au processeur (autour d’un facteur 20 pour la GTX 1080 Ti face à la meilleure des implémentations pour CPU).</p>
<img alt="xgemm_sp" class="img-fluid center" src="../../_images/xgemm_sp.png" />
<p>Lors du passage en double précision, les GPU se rapprochent des CPU en performance.</p>
<img alt="xgemm_dp" class="img-fluid center" src="../../_images/xgemm_dp.png" />
<p>Le ratio entre performances en simple sur double précision illustre la grosse différence entre CPU et GPU.</p>
<img alt="xgemm_ratio_spdp" class="img-fluid center" src="../../_images/xgemm_ratio_spdp.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #10 : lancez les `xGEMM_&lt;precision&gt;_&lt;implementation&gt;` avec une taille de 1000</strong></p>
<ul class="simple">
<li><p>Variez le nombre d’itérations pour obtenir une durée d’exécution d’une dizaine de secondes ?</p></li>
<li><p>Laquelle des implémentations CPU est la plus performante ?</p></li>
<li><p>Laquelle des implémentations GPU est la plus performante ?</p></li>
<li><p>Exécutez à nouveau la performance en passant la précision (de SP à DP) sur CPU</p></li>
<li><p>Evaluez le rapport de performances entre SP et DP sur CPU</p></li>
<li><p>Exécutez à nouveau la performance en passant la précision (de SP à DP) sur GPU</p></li>
<li><p>Evaluez le rapport de performances entre SP et DP sur GPU</p></li>
<li><p>Présentez les performances entre implémentations en simple précision</p></li>
<li><p>Présentez les performances entre implémentations en double précision</p></li>
</ul>
</div>
<p>Il est aussi intéressant de constater que la performance dépend non seulement de l’implémentation, du périphérique mais aussi de sa sollicitation. Voici la performance pour l’implémentation CPU avec OpenBLAS et les implémentations cuBLAS et <em>Thunking</em> sur la GTX 1080 Ti.</p>
<img alt="xgemm_sp_size" class="img-fluid center" src="../../_images/xgemm_sp_size.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #11 : lancez les programmes précédents pour différentes tailles</strong></p>
<ul class="simple">
<li><p>Diminuez la taille aux valeurs suivantes <code class="docutils literal notranslate"><span class="pre">125</span></code>, <code class="docutils literal notranslate"><span class="pre">250</span></code>, <code class="docutils literal notranslate"><span class="pre">500</span></code> et exécutez les programmes</p></li>
<li><p>Que constatez-vous pour les performances sur CPU ou GPU ?</p></li>
<li><p>Augmentez la taille à <code class="docutils literal notranslate"><span class="pre">2000</span></code>, <code class="docutils literal notranslate"><span class="pre">4000</span></code>, <code class="docutils literal notranslate"><span class="pre">8000</span></code>, <code class="docutils literal notranslate"><span class="pre">16000</span></code> et exécutez les programmes</p></li>
<li><p>Que constatez-vous pour les performances sur CPU ou GPU ?</p></li>
<li><p>Pendant une exécution, observez la consommation électrique instantanée : que constatez-vous ?</p></li>
<li><p>Présentez les performances en fonction des tailles explorées</p></li>
</ul>
</div>
</section>
</section>
</section>
<section id="exploration-des-gpu-avec-un-pi-monte-carlo">
<h2>Exploration des GPU avec un Pi Monte Carlo<a class="headerlink" href="#exploration-des-gpu-avec-un-pi-monte-carlo" title="Lien vers cette rubrique">¶</a></h2>
<section id="le-pi-monte-carlo-ou-pi-dart-dash-un-code-compute-bound">
<h3>Le « Pi Monte Carlo » ou « Pi Dart Dash »,un code « compute bound »<a class="headerlink" href="#le-pi-monte-carlo-ou-pi-dart-dash-un-code-compute-bound" title="Lien vers cette rubrique">¶</a></h3>
<p>Le calcul de Pi par la  <a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo">méthode de Monte Carlo</a> est exemplaire à plusieurs titres :</p>
<ul class="simple">
<li><p>elle est simple : un générateur de nombres aléatoires, un mécanisme de test et un compteur suffisent</p></li>
<li><p>elle est parallélisable : en distribuant le nombre d’itérations sur les unités de calcul</p></li>
<li><p>elle est <em>compute bound</em> : en n’ayant quasiment aucun accès mémoire (reste dans les registres de calcul)</p></li>
<li><p>elle est cependant notoirement inefficace pour calculer Pi ;-)</p></li>
</ul>
<p>Les versions que vous allez utiliser exploitent de 2 à 4 paramètres en entrée :</p>
<ul class="simple">
<li><p>le nombre total d’itérations</p></li>
<li><p>le régime de Parallélisme (PR) : le <code class="docutils literal notranslate"><span class="pre">découpage</span></code> du travail vers les unités de traitement</p></li>
<li><p>le type de variables : INT32, INT64, FP32, FP64</p></li>
<li><p>le type de <em>Random Number Generator</em> : MWC, CONG, SHR3, KISS</p></li>
</ul>
<p>Intuitivement, le <strong>régime de parallélisme</strong> à explorer est optimal lorsqu’il correspond au nombre d’unités de traitement (<em>Compute Units</em>). Nous verrons que c’est un peu plus compliqué que cela.</p>
<p>Le type de variable va permettre de juger de l’efficacité des <em>Compute Units</em> en fonction des données qu’elles manipulent, notamment lorsque nous passons de 32 à 64 bits.</p>
<p>Le type de <em>RNG</em> a aussi son importance. Les <em>RNG</em> utilisés ici sont ceux de <a class="reference external" href="https://en.wikipedia.org/wiki/George_Marsaglia">Georges Marsaglia</a>. Comme tous les <em>RNG</em> pseudo-aléatoires, ils nécessitent une « graine », laquelle permet une reproductibilité des tirages. Voici leur code source, d’une effroyable efficacité compte-tenu de leur compacité.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#define znew  ((z=36969*(z&amp;65535)+(z&gt;&gt;16))&lt;&lt;16)</span>
<span class="c1">#define wnew  ((w=18000*(w&amp;65535)+(w&gt;&gt;16))&amp;65535)</span>
<span class="c1">#define MWC   (znew+wnew)</span>
<span class="c1">#define SHR3  (jsr=(jsr=(jsr=jsr^(jsr&lt;&lt;17))^(jsr&gt;&gt;13))^(jsr&lt;&lt;5))</span>
<span class="c1">#define CONG  (jcong=69069*jcong+1234567)</span>
<span class="c1">#define KISS  ((MWC^CONG)+SHR3)</span>
</pre></div>
</div>
<p>Comme nous divisons un nombre d’itérations entier par un régime de parallélisme, nous approximons dans le code le nombre d’itérations de chaque calcul élémentaire à l’entier supérieur. Lorsque le nombre d’itérations dépasse le milliard, le nombre d’itérations supplémentaires ne dépasse pas 7%.</p>
<p>Comme résultat, nous avons deux observables simples :</p>
<ul>
<li><p>une estimation de Pi : juste indicative, Pi n’étant pas rationnel</p>
<blockquote>
<div><ul class="simple">
<li><p>par l’addition de tous les résultats sur le nombre total d’itérations que multiplie 4</p></li>
</ul>
</div></blockquote>
</li>
<li><p>le temps écoulé</p></li>
</ul>
<p>Pour évaluer une performance, il est toujours intéressant de choisir une métrique maximaliste : nous définissons le <strong>itops</strong> soit le <em>ITerative Operations Per Second</em> comme le rapport entre ce nombre total d’itérations et le temps écoulé.</p>
</section>
<section id="les-programmes-utilises-opencl-cuda">
<h3>Les programmes utilisés : OpenCL, CUDA<a class="headerlink" href="#les-programmes-utilises-opencl-cuda" title="Lien vers cette rubrique">¶</a></h3>
<p>Le dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu</span></code> contient de nombreuses implémentations de ce calcul élémentaire. Nous nous focaliserons sur 2 d’entre eux :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/OpenCL/PiOpenCL.c</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/XPU/PiXPU.py</span></code></p></li>
</ul>
</section>
<section id="implementation-c-opencl">
<h3>Implémentation C/OpenCL<a class="headerlink" href="#implementation-c-opencl" title="Lien vers cette rubrique">¶</a></h3>
<p>Le programme <code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/OpenCL/PiOpenCL.c</span></code> est une implémentation en C « pur » : il permet de juger de la difficulté d’appropriation de OpenCL. En effet, une grande partie du code est destinée à définir quelle plateforme et quel périphérique utiliser, placer les données à traîter.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #12 : exploration du code OpenCL</strong></p>
<ul class="simple">
<li><p>Repérez dans le programme source le <strong>noyau</strong> OpenCL réalisant le calcul</p></li>
<li><p>Repérez dans le programme source les parties <strong>découverte</strong> des périphériques</p></li>
<li><p>Repérez quel <em>RNG</em> est utilisé dans ce programme</p></li>
</ul>
</div>
<p>Le code se compile très simplement uniquement en appliquant la commande <code class="docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">-o</span> <span class="pre">PiOpenCL</span> <span class="pre">PiOpenCL.c</span> <span class="pre">-lOpenCL</span></code>. L’exécutable <code class="docutils literal notranslate"><span class="pre">PiOpenCL</span></code> est prêt à être utilisé.</p>
<p>Son exécution sans paramètre ne fait qu’une « découverte » des périphériques OpenCL disponibles et présente la documentation. Par exemple :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Performs<span class="w"> </span>a<span class="w"> </span>Pi<span class="w"> </span>estimation<span class="w"> </span>by<span class="w"> </span>Dart<span class="w"> </span>Dash:

<span class="w">    </span><span class="c1">#1 OpenCL Plateform ID (default 0)</span>
<span class="w">    </span><span class="c1">#2 OpenCL Device ID (default 0)</span>
<span class="w">    </span><span class="c1">#3 Minimal number of iterations (default 1000000)</span>
<span class="w">    </span><span class="c1">#4 Parallel Rate (default 1024)</span>
<span class="w">    </span><span class="c1">#5 Loops (default 1)</span>
<span class="w">    </span><span class="c1">#6 Type of variable: INT32, INT64, FP32, FP64 (default FP32)</span>

OpenCL<span class="w"> </span>statistics:<span class="w"> </span><span class="m">4</span><span class="w"> </span>platform<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>detected

Device<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">    </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU
<span class="w">    </span>Device<span class="w"> </span>vendor:<span class="w"> </span>GenuineIntel
<span class="w">    </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>AMD-APP<span class="w"> </span><span class="o">(</span><span class="m">1912</span>.5<span class="o">)</span>
<span class="w">    </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">1912</span>.5<span class="w"> </span><span class="o">(</span>sse2,avx<span class="o">)</span>
<span class="w">    </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">    </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">    </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU<span class="w"> </span>CL_DEVICE_TYPE_DEFAULT
<span class="w">    </span>Device<span class="w"> </span>vendor:<span class="w"> </span>GenuineIntel
<span class="w">    </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span>pocl
<span class="w">    </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">0</span>.13
<span class="w">    </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">2</span>.0
<span class="w">    </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>:<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti
<span class="w">    </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_GPU
<span class="w">    </span>Device<span class="w"> </span>vendor:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation
<span class="w">    </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>CUDA
<span class="w">    </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">384</span>.130
<span class="w">    </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">    </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">28</span>
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>:<span class="w"> </span>Quadro<span class="w"> </span>K420
<span class="w">    </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_GPU
<span class="w">    </span>Device<span class="w"> </span>vendor:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation
<span class="w">    </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>CUDA
<span class="w">    </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">384</span>.130
<span class="w">    </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">    </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">1</span>
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">    </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU
<span class="w">    </span>Device<span class="w"> </span>vendor:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Corporation
<span class="w">    </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span><span class="o">(</span>Build<span class="w"> </span><span class="m">25</span><span class="o">)</span>
<span class="w">    </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">1</span>.2.0.25
<span class="w">    </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">2</span>.0
<span class="w">    </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">    </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<p>Nous découvrons que 4 plates-formes sont détectées, servant 5 périphériques.</p>
<ul class="simple">
<li><p>les 3 implémentations CPU de OpenCL : celles d’AMD, de PortableCL et d’Intel</p></li>
<li><p>les 2 GPU Nvidia <strong>GTX 1080 Ti</strong> et <strong>Quadro K420</strong></p></li>
</ul>
<p>Cette sortie montre également les options (au moins 2) à entrer pour exploiter le programme :</p>
<ul class="simple">
<li><p>#1 l’identifiant de la plateforme</p></li>
<li><p>#2 l’identifiant du périphérique pour cette plateforme</p></li>
<li><p>#3 le nombre minimum d’itérations (par défaut 1000000)</p></li>
<li><p>#4 le régime de parallélisme PR (par défault 1024)</p></li>
<li><p>#5 le nombre de boucles (par défault 1) : bien utile pour évaluer la reproductibilité temporelle</p></li>
<li><p>#6 le type de variable: INT32, INT64, FP32, FP64 (par défault FP32)</p></li>
</ul>
<p>Il est donc nécessaire de préciser uniquement le tuple <code class="docutils literal notranslate"><span class="pre">(plateforme,périphérique)</span></code> pour exécuter le programme.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #13 : compilation et première exécution</strong></p>
<ul class="simple">
<li><p>Compilez le programme avec la ligne de compilation précisée ci-dessus</p></li>
<li><p>Exécutez le programme « à vide » et identifiez les périphériques</p></li>
<li><p>Exécutez le programme sur le premier GPU Nvidia que vous avez repéré</p></li>
</ul>
</div>
<p>Avec ce premier outil, il est possible de juger de la différence fondamentale de performances entre GPU et CPU, en fonction du régime de parallélisme.</p>
<p>Par exemple, sur les périphériques ci-dessus :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>3.98</p></td>
<td><p>251524870</p></td>
<td><p>785423827</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>4.77</p></td>
<td><p>209512671</p></td>
<td><p>785423827</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>26.11</p></td>
<td><p>38299749</p></td>
<td><p>785423825</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>108.52</p></td>
<td><p>9214573</p></td>
<td><p>785423825</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>3.90</p></td>
<td><p>256424327</p></td>
<td><p>785423825</p></td>
</tr>
</tbody>
</table>
<img alt="opencluster2_qpu1" class="img-fluid center" src="../../_images/opencluster2_qpu1.png" />
<p>Il est assez intéressant que les implémentations CPU offrent quasiment la même performance. Par contre les GPU offrent une performance bien moindre (6x moins pour la GTX 1080 Ti et presque 30x moins pour la Quadro K420).</p>
<p>Il est aussi intéressant qu’étrange que le nombre de « coups » à l’intérieur du quadrant d’exploration ne soit pas le même pour toutes les implémentations. C’est un artéfact lié à la multiplication du <em>RNG</em> par la constante pour le placer entre 0 et 1.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #14 : exécution sur tous les périphériques pour un PR=1</strong></p>
<ul class="simple">
<li><p>Exécutez le programme sur tous (GPU &amp; CPU) avec un nombre d’itérations de 1 milliard</p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et le <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio existe entre le ou les GPU et les processeurs ?</p></li>
</ul>
</div>
<p>Nous pouvons maintenant explorer la réponse des périphériques, notamment pour des régimes de parallélisme bien plus élevés, par exemple la valeur par défaut de <code class="docutils literal notranslate"><span class="pre">1024</span></code>. Nous portons par contre le nombre d’itérations à 10000000000, soit 10x plus que précédemment.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>4.28</p></td>
<td><p>2338471813</p></td>
<td><p>7853958701</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>24.23</p></td>
<td><p>412737304</p></td>
<td><p>7853958701</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>0.37</p></td>
<td><p>26864605077</p></td>
<td><p>7853958630</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>3.04</p></td>
<td><p>3287218047</p></td>
<td><p>7853958630</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>1.25</p></td>
<td><p>7973063801</p></td>
<td><p>7853958630</p></td>
</tr>
</tbody>
</table>
<img alt="opencluster2_qpu1024" class="img-fluid center" src="../../_images/opencluster2_qpu1024.png" />
<p>Cette seconde expérience montre de manière assez spectaculaire que les GPU ne dévoilent leur puissance « que » pour des régimes de parallélisme élevé. Notons aussi que les implémentations sur CPU ont des performances très très disparates.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #15 : exécution sur tous les périphériques pour un PR=1024</strong></p>
<ul class="simple">
<li><p>Exécutez le programme sur tous (GPU &amp; CPU) avec un nombre d’itérations de 10 milliards</p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio existe entre le ou les GPU et les processeurs ?</p></li>
</ul>
</div>
<p>Dans l’expérience précédente, nous avons exploité un régime de parallélisme sur les processeurs très supérieur au nombre de <em>Compute Units</em>, lesquelles sont identifiées comme les coeurs. Il y avait 8 coeurs physiques et nous avons « chargé » chaque coeur à 256 fois leur charge. Que se passe-t-il si nous effectuons la même chose avec les GPU ?</p>
<p>Dans notre exemple, la GTX 1080 Ti dispose de 3584 <em>cuda cores</em>. La Quadro K420 de 192 <em>cuda cores</em>. Explorons ces périphériques avec des  <strong>PR</strong> de 256x ces valeurs (nous sommes obligés de porter les itérations à 1000 milliards) :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>3.77</p></td>
<td><p>265583420021</p></td>
<td><p>785397498152</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>290.03</p></td>
<td><p>3447937882</p></td>
<td><p>785398065372</p></td>
</tr>
</tbody>
</table>
<img alt="opencluster2_epu" class="img-fluid center" src="../../_images/opencluster2_epu.png" />
<p>Ce graphique montre sans ambiguité la puissance « brute » qu’offre un GPU de gamer en comparaison de CPU traditionnel (33x dans la meilleure implémentation CPU, celle d’Intel). Notons également que GPU n’est pas synonyme de puissance brute : la « petite » Quadro K420, bien que « professionnelle » présente des performances 77x inférieures.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #16 : exécution sur tous les périphériques pour un PR optimal</strong></p>
<ul class="simple">
<li><p>Reprenez les spécifications des GPU et isolez le nombre de <em>cuda cores</em></p></li>
<li><p>Exécutez le programme sur les GPU avec un nombre d’itérations de 100 milliards et un PR de 256x le nombre de <em>cuda cores</em></p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio de performance existe entre le GPU le plus puissant et la meilleure implémentation des CPU ?</p></li>
</ul>
</div>
<p>Nous avons déjà noté, dans l’exploitation de <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> que les performances pour les GPU étaient largement influencées par la précision utilisée pour les calculs.</p>
<p>Pour les mêmes périphériques mais en passant en double précision, nous avons :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Elapsed</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>4.05</p></td>
<td><p>2472082769</p></td>
<td><p>7853958184</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>18.89</p></td>
<td><p>529471467</p></td>
<td><p>7853958184</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>3.34</p></td>
<td><p>29909278511</p></td>
<td><p>78540290903</p></td>
</tr>
<tr class="row-odd"><td><p>QuadroK420</p></td>
<td><p>12.52</p></td>
<td><p>798857983</p></td>
<td><p>7854068741</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>16.24</p></td>
<td><p>6156907937</p></td>
<td><p>78539995659</p></td>
</tr>
</tbody>
</table>
<img alt="piopencl_dp" class="img-fluid center" src="../../_images/piopencl_dp.png" />
<p>Nous avons présenté dans le cours qu’un mauvais choix de régime de parallélisme pouvait largement influencer la performance.</p>
<p>Par exemple, regardons pour la meilleure implémentation de CPU et pour le GPU le plus puissant, quelle influence a le choix du régime de parallélisme autour du régime de parallélisme optimal.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #17 : exécution sur tous les périphériques pour un PR optimal en double précision</strong></p>
<ul class="simple">
<li><p>Reprenez les expériences ci-dessus en précisant un calcul en double précision</p></li>
<li><p>Tracez l’histogramme avec tous les périphériques OpenCL</p></li>
<li><p>Quel ratio de performance existe entre le GPU le plus puissant et la meilleure implémentation des CPU ?</p></li>
</ul>
</div>
</section>
<section id="implementation-python-opencl-python-cuda">
<h3>Implémentation Python/OpenCL Python/CUDA<a class="headerlink" href="#implementation-python-opencl-python-cuda" title="Lien vers cette rubrique">¶</a></h3>
<p>Dans l’exemple précédent, nous avons exploité un programme en C « pur ». Nous avons vu comment s’intégrait la portion de code (le noyau ou le <em>kernel</em>) qui était exécutée, soit par les GPU, soit par différentes implémentations pour CPU de OpenCL. Nous avons aussi pu « juger » du côté assez « compliqué » de découvertes des périphériques et des mécanismes d’entrée/sortie.</p>
<p>Avec le programme <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code>, nous allons pouvoir exploiter les périphériques de calcul plus simplement, et bénéficier de toutes les facilités d’un langage évolué.</p>
<p>Regardons d’abord sa sortie lorsqu’il est sollicité avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-h
PiXPU.py<span class="w"> </span>-o<span class="w"> </span><span class="o">(</span>Out<span class="w"> </span>of<span class="w"> </span>Core<span class="w"> </span>Metrology<span class="o">)</span><span class="w"> </span>-c<span class="w"> </span><span class="o">(</span>Print<span class="w"> </span>Curves<span class="o">)</span><span class="w"> </span>-k<span class="w"> </span><span class="o">(</span>Case<span class="w"> </span>On<span class="w"> </span>IfThen<span class="o">)</span><span class="w"> </span>-d<span class="w"> </span>&lt;DeviceId&gt;<span class="w"> </span>-g<span class="w"> </span>&lt;CUDA/OpenCL&gt;<span class="w"> </span>-i<span class="w"> </span>&lt;Iterations&gt;<span class="w"> </span>-b<span class="w"> </span>&lt;BlocksBegin&gt;<span class="w"> </span>-e<span class="w"> </span>&lt;BlocksEnd&gt;<span class="w"> </span>-s<span class="w"> </span>&lt;BlocksStep&gt;<span class="w"> </span>-f<span class="w"> </span>&lt;ThreadsFirst&gt;<span class="w"> </span>-l<span class="w"> </span>&lt;ThreadsLast&gt;<span class="w"> </span>-t<span class="w"> </span>&lt;ThreadssTep&gt;<span class="w"> </span>-r<span class="w"> </span>&lt;RedoToImproveStats&gt;<span class="w"> </span>-m<span class="w"> </span>&lt;SHR3/CONG/MWC/KISS&gt;<span class="w"> </span>-v<span class="w"> </span>&lt;INT32/INT64/FP32/FP64&gt;

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>OpenCL<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>CUDA<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 of type GPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#1 of type GPU : Quadro K420</span>
</pre></div>
</div>
<p>Nous disposons de plus d’options pour le lancement. Ce programme étant un programme de test de performances, il permet une exploration de régimes de parallélisme. Dans les approches de programmation CUDA ou OpenCL, il y a deux étages de parallélisme :</p>
<ul class="simple">
<li><p>le premier pour des tâches indépendantes : <em>Blocks</em> et <em>Work items</em> en sont les éléments</p></li>
<li><p>le second pour des tâches nécessitant une synchronisation : ce sont les <em>Threads</em></p></li>
</ul>
<p>Il y a donc, pour explorer ces deux régimes de parallélisme, 6 options différentes :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">&lt;BlocksBegin&gt;</span></code>  : le premier nombre de <em>Work items</em> ou de <em>Blocks</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">&lt;BlocksEnd&gt;</span></code>    : le dernier nombre de <em>Work items</em> ou de <em>Blocks</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">&lt;BlocksStep&gt;</span></code>   : le pas entre deux <em>Work items</em> ou de <em>Blocks</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">&lt;ThreadsFirst&gt;</span></code> : le premier nombre de <em>Threads</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-l</span> <span class="pre">&lt;ThreadsLast&gt;</span></code>  : le dernier nombre de <em>Threads</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">&lt;ThreadssTep&gt;</span></code>  : le pas entre deux <em>Threads</em> à explorer</p></li>
</ul>
<p>Il est aussi possible de coupler les deux régimes de parallélisme en appelant 16 <em>work items</em> avec 16 <em>threads</em>.</p>
<p>Par exemple, pour explorer des régimes de parallélisme de 16 à 128 avec des pas de 16 en <em>Work items</em> et 4 à 8 en <em>Threads</em> avec des pas unitaires, nous aurons <code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">16</span> <span class="pre">-e</span> <span class="pre">128</span> <span class="pre">-s</span> <span class="pre">16</span> <span class="pre">-f</span> <span class="pre">4</span> <span class="pre">-l</span> <span class="pre">8</span> <span class="pre">-p</span> <span class="pre">2</span></code>.</p>
<p>D’autres options :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">&lt;CUDA/OpenCL&gt;</span></code> : pour sélectionner l’utilisation de CUDA ou OpenCL</p></li>
<li><p><a href="#id1"><span class="problematic" id="id2">``</span></a>-i &lt;Iterations&gt; `` : pour le nombre total d’itérations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-r</span> <span class="pre">&lt;RedoToImproveStats&gt;</span></code> : pour refaire plusieurs expériences en série</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-m</span> <span class="pre">&lt;SHR3/CONG/MWC/KISS&gt;</span></code> : pour sélectionner le type de <em>Random Number Generator</em> de Marsaglia</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">&lt;INT32/INT64/FP32/FP64&gt;</span></code> : pour sélectionner le type de variable à exploiter</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-k</span> <span class="pre">(Case</span> <span class="pre">On</span> <span class="pre">IfThen)</span></code> : pour forcer l’exploitation du test avec un mécanisme en <code class="docutils literal notranslate"><span class="pre">IfThen</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">&lt;DeviceId&gt;</span></code> : pour sélectionner le périphérique en utilisant l’ID fourni avec le <code class="docutils literal notranslate"><span class="pre">-h</span></code></p></li>
</ul>
<p>L’appel du programme ci-dessus nous montre qu’il y a le même nombre de périphériques OpenCL visibles (les 3 implémentations OpenCL pour CPU et les 2 GPU Nvidia), la nouveauté est que nous voyons également deux périphériques CUDA.</p>
<p>En sortie, lors d’un appel simple ne précisant que le périphérique, ici le premier, <code class="docutils literal notranslate"><span class="pre">#0</span></code>, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span>
Devices<span class="w"> </span>Identification<span class="w"> </span>:<span class="w"> </span><span class="o">[</span><span class="m">0</span><span class="o">]</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>OpenCL
Iterations<span class="w"> </span>:<span class="w"> </span><span class="m">10000000</span>
Number<span class="w"> </span>of<span class="w"> </span>Blocks<span class="w"> </span>on<span class="w"> </span>begin<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Blocks<span class="w"> </span>on<span class="w"> </span>end<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Step<span class="w"> </span>on<span class="w"> </span>Blocks<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Threads<span class="w"> </span>on<span class="w"> </span>begin<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Threads<span class="w"> </span>on<span class="w"> </span>end<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Step<span class="w"> </span>on<span class="w"> </span>Threads<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>redo<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Metrology<span class="w"> </span><span class="k">done</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span>XPU<span class="w"> </span>:<span class="w"> </span>False
Type<span class="w"> </span>of<span class="w"> </span>Marsaglia<span class="w"> </span>RNG<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>MWC
Type<span class="w"> </span>of<span class="w"> </span>variable<span class="w"> </span>:<span class="w"> </span>FP32
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
<span class="o">([</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span><span class="o">{</span><span class="m">0</span>:<span class="w"> </span><span class="s1">&#39;xPU&#39;</span><span class="o">})</span>
<span class="o">(</span><span class="s1">&#39;Inside &#39;</span>,<span class="w"> </span><span class="o">{</span><span class="s1">&#39;Blocks&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;ValueType&#39;</span>:<span class="w"> </span><span class="s1">&#39;FP32&#39;</span>,<span class="w"> </span><span class="s1">&#39;RNG&#39;</span>:<span class="w"> </span><span class="s1">&#39;MWC&#39;</span>,<span class="w"> </span><span class="s1">&#39;Threads&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;Iterations&#39;</span>:<span class="w"> </span><span class="m">10000000</span>,<span class="w"> </span><span class="s1">&#39;Device&#39;</span>:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="s1">&#39;Steps&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;IfThen&#39;</span>:<span class="w"> </span>False<span class="o">})</span>
<span class="o">(</span><span class="s1">&#39;CPU/GPU selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz&#39;</span><span class="o">)</span>
<span class="o">(</span>Blocks/Threads<span class="o">)=(</span><span class="m">1</span>,1<span class="o">)</span><span class="w"> </span>method<span class="w"> </span><span class="k">done</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.06<span class="w"> </span>s...
<span class="o">{</span><span class="s1">&#39;Duration&#39;</span>:<span class="w"> </span>array<span class="o">([</span><span class="m">0</span>.06270599<span class="o">])</span>,<span class="w"> </span><span class="s1">&#39;Inside&#39;</span>:<span class="w"> </span><span class="m">7852019</span>.0,<span class="w"> </span><span class="s1">&#39;NewIterations&#39;</span>:<span class="w"> </span><span class="m">10000000</span><span class="o">}</span>
Pi<span class="w"> </span>estimation<span class="w"> </span><span class="m">3</span>.14080760
<span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">159474388</span>
</pre></div>
</div>
<p>Deux fichiers de sortie sont créés et reprennent dans leur titre les paramètres d’entrée :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_1_1_1_10000000_Device0_InMetro_opencluster2</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_1_1_1_10000000_Device0_InMetro_opencluster2.npz</span></code></p></li>
</ul>
<p>Le premier est uniquement lisible avec Python, le second est utilisable directement, pas exemple avec GNUplot.</p>
<section id="examen-du-code-source">
<h4>Examen du code source<a class="headerlink" href="#examen-du-code-source" title="Lien vers cette rubrique">¶</a></h4>
<div class="note note-warning docutils container">
<p><strong>Exercice #18 : récupération des éléments dans le code source</strong></p>
<ul class="simple">
<li><p>Editez le code source avec l’outil <code class="docutils literal notranslate"><span class="pre">gedit</span></code></p></li>
<li><p>Identifiez l’appel de la procédure principale OpenCL : ligne</p></li>
<li><p>Identifiez la zone de code de cette procédure OpenCL : lignes</p></li>
<li><p>Examinez dans cette procédure la <strong>construction</strong> du noyau OpenCL : ligne</p></li>
<li><p>Examinez dans cette procédure l”<strong>appel</strong> du noyau OpenCL : ligne</p></li>
<li><p>Identifiez le noyau OpenCL appelé par cette procédure : lignes</p></li>
<li><p>Identifiez l’appel de la procédure principale CUDA : ligne</p></li>
<li><p>Identifiez la zone de code de cette procédure CUDA : lignes</p></li>
<li><p>Identifiez le noyau CUDA appelé par cette procédure : lignes</p></li>
<li><p>Examinez dans cette procédure la <strong>construction</strong> du noyau CUDA : ligne</p></li>
<li><p>Examinez dans cette procédure l”<strong>appel</strong> du noyau CUDA : ligne</p></li>
<li><p>Quelles similarités distinguez-vous entre les noyaux OpenCL et CUDA ?</p></li>
</ul>
</div>
</section>
<section id="exploitation-du-programme">
<h4>Exploitation du programme<a class="headerlink" href="#exploitation-du-programme" title="Lien vers cette rubrique">¶</a></h4>
<p>Ainsi, si nous voulons étudier la scalabilité du CPU en <em>Work items</em> de 1 à 16x le nombre de coeurs (ici 8 physiques) en exploitant l’implémentation AMD de OpenCL, nous appelons la commande :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="m">1</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">8</span><span class="o">*</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">10</span><span class="w"> </span>-i<span class="w"> </span><span class="m">1000000000</span>
</pre></div>
</div>
<p>Dans notre cas, nous avons les deux fichiers suivants à exploiter :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2.npz</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2</span></code></p></li>
</ul>
<p>Nous pouvons ensuite exploiter l’outil simple <code class="docutils literal notranslate"><span class="pre">gnuplot</span></code> pour afficher nos résultats :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>gnuplot
<span class="nb">set</span><span class="w"> </span>xlabel<span class="w"> </span><span class="s1">&#39;Parallel Rate&#39;</span>
<span class="nb">set</span><span class="w"> </span>ylabel<span class="w"> </span><span class="s1">&#39;Itops&#39;</span>
<span class="nb">set</span><span class="w"> </span>yrange<span class="w"> </span><span class="o">[</span><span class="m">0</span>:*<span class="o">]</span>
plot<span class="w"> </span><span class="s1">&#39;Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2&#39;</span><span class="w"> </span>using<span class="w"> </span><span class="m">1</span>:9<span class="w"> </span>title<span class="w"> </span><span class="s1">&#39;OpenCL AMD&#39;</span>
</pre></div>
</div>
<p>Il existe un bouton d’export du graphique en image au format PNG ou SVG. Nous obtenons le suivant :</p>
<img alt="amd_opencluster2_insa" class="img-fluid center" src="../../_images/amd_opencluster2_insa.png" />
<p>Nous observons que la scalabilité pour un code aussi simple n’est pas si triviale que cela à analyser. Il n’y a pas continuité en fonction de PR croissant. Notons une pseudo-période correspondant au nombre de coeurs physiques, avec des maximums locaux pour les multiples de cette valeur (le <em>handsaw curve effect</em>).</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #19 : étude de la scalabilité d’une implémentation CPU</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> un périphérique CPU</p></li>
<li><p>Exécutez le d’un PR=1 à un PR égal à 8x le nombre de coeurs physiques</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
</ul>
</div>
<p>Nous pouvons également « explorer » la scalabilité des GPU forts de notre expérience de <code class="docutils literal notranslate"><span class="pre">PiOpenCL</span></code>. Par exemple, du nombre de <em>cuda cores</em> à ce nombre multiplié par 16, par pas de 128. La commande appelée est la suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">2</span><span class="w"> </span>-b<span class="w"> </span><span class="m">3584</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">8</span><span class="k">))</span><span class="w"> </span>-s<span class="w"> </span><span class="m">128</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">100000000000</span>
</pre></div>
</div>
<p>Nous obtenons pour notre GTX 1080 Ti les résultats suivants :</p>
<img alt="gtx1080ti_opencluster2_insa" class="img-fluid center" src="../../_images/gtx1080ti_opencluster2_insa.png" />
<p>Nous pouvons constater que la scalabilité est très peu continue, encore moins que pour la scalabilité étudiée des CPU. Nous constatons également que des pseudo-lignes se chevauchent. Le PR optimal était autour de 4x le nombre de <em>cuda cores</em> et offrait une performance de <strong>268 Gitops</strong>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #20 : étude de la scalabilité d’un GPU</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> un périphérique GPU</p></li>
<li><p>Exécutez-le d’un PR=&lt;NbCudaCores&gt; à un PR égal à 8x&lt;NbCudaCores&gt; par pas de 128 en OpenCL</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
<li><p>Identifiez pour quel PR la performance est maximale</p></li>
</ul>
</div>
<p>Comme nous avons également la même implémentation en CUDA, lançons l’exploration avec CUDA pour le PR optimal, ici identifié à 4x le nombre de <em>cuda cores</em> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-g<span class="w"> </span>CUDA<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">10000000000</span>
</pre></div>
</div>
<p>Comme résultat de cette implémentation CUDA, nous n’obtenons pas <strong>268 Gitops</strong>, mais seulement <strong>6 Gitops</strong> !</p>
<p>La seule manière de retrouver une performance comparable en CUDA est de solliciter le second étage de parallélisme des GPU, les <em>Threads</em>. Avec la commande suivante, avec 1024 Threads, nous plafonnons à <strong>198 Gitops</strong> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-g<span class="w"> </span>CUDA<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-f<span class="w"> </span><span class="m">1024</span><span class="w"> </span>-l<span class="w"> </span><span class="m">1024</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">1000000000000</span>
</pre></div>
</div>
<p>Et ce n’est pas tout ! La distribution Debian utilisée intègre par défaut un CUDA version 8. Pour l’intégration d’applications de <em>Deep Learning</em>, nous avons été obligé d’intégrer un CUDA version 9. Nous pouvons charger l’environnement pour exploiter cette version avec la commande :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module<span class="w"> </span>load<span class="w"> </span>cuda/9.0
</pre></div>
</div>
<p>En relançant le calcul précédent, nous parvenons à <strong>271 Gitops</strong> soit plus que l’implémentation OpenCL.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #21 : étude de l’implémentation CUDA autour du PR optimal</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> le périphérique GPU déjà utilisé en CUDA</p></li>
<li><p>Exécutez le avec le PR optimal des <em>Blocks</em> en CUDA</p></li>
<li><p>Quel ratio de performance avez-vous entre CUDA et OpenCL ?</p></li>
<li><p>Exécutez le avec le PR optimal des <em>Blocks</em> et 1024 <em>Threads</em></p></li>
<li><p>Quel ratio de performance avez-vous entre CUDA et OpenCL ?</p></li>
</ul>
</div>
<p>Il existe aussi des artéfacts sur des régimes de parallélisme spéciaux en OpenCL sur les GPU Nvidia : en explorant autour du PR optimal, quelles sont les PR qu’il ne faut surtout pas exploiter et quel est leur point commun ?</p>
<p>En lançant cette exploration suivante, nous obtenons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">2</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="o">-</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="o">+</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">100000000000</span>
</pre></div>
</div>
<img alt="gtx1080ti_aroundepu_opencluster2_insa" class="img-fluid center" src="../../_images/gtx1080ti_aroundepu_opencluster2_insa.png" />
<p>Alors que l’optimum de performance est atteint autour d’un PR de 14336 avec <strong>258 Gitops</strong>, nous n’obtenons un Itops que de <strong>8.5 Gitops</strong> (soit 30x moins) sur 5 valeurs particulières : 14321, 14323, 14327, 14341, 14347. Le point commun entre ces valeurs de PR est à rechercher sur le site <a class="reference external" href="http://www.math.com/students/calculators/source/prime-number.htm">de mathématiques</a></p>
<div class="note note-warning docutils container">
<p><strong>Exercice #22 : étude de valeurs particulières de PR</strong></p>
<ul class="simple">
<li><p>Exécutez <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code> autour du PR égal à 4x le nombre de <em>cuda cores</em> (16 avant et 16 après)</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
<li><p>Quels sont les PR avec les performances les plus faibles ?</p></li>
</ul>
</div>
</section>
</section>
</section>
<section id="exploration-par-un-corps-n-corps-a-grain-fin">
<h2>Exploration par un corps N-Corps à « grain fin »<a class="headerlink" href="#exploration-par-un-corps-n-corps-a-grain-fin" title="Lien vers cette rubrique">¶</a></h2>
<p>Le code de test <strong>Pi Monte Carlo</strong> avait pour avantage de ne solliciter que très peu la mémoire. La seule mémoire sollicitée sur les périphériques se résumait au nombre de tirages dans le quadrant de cercle. De plus, l’opération de parallélisation divisait un nombre total d’itérations en un nombre équivalent pour chaque <em>work item</em>, chaque <em>block</em> ou chaque <em>thread</em>. Chaque calcul était indépendant des autres : nous avions non seulement un <strong>code ALU</strong> (ne sollicitant que les unités de traitement) mais aussi un <strong>code gros grain</strong> (indépendance des calculs).</p>
<p>Dans le code <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code>, le principe est de déterminer dans un modèle newtonien la position et la vitesse de chaque particule en intéraction avec toutes les autres. A chaque itération, chaque position et chaque vitesse de chaque particule vont être modifiées par la proximité de toutes les autres : nous disposons d’un <strong>code grain fin</strong>. De plus, la détermination de la vitesse et la position de chaque particule à chaque instant nécessite un accès à la position de chacune des autres : un accès permanent à la mémoire est donc indispensable.</p>
<p>Le programme <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code> n’est disponible qu’en OpenCL. Son invocation avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> offre la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>NBody.py<span class="w"> </span>-h
NBody.py<span class="w"> </span>-h<span class="w"> </span><span class="o">[</span>Help<span class="o">]</span><span class="w"> </span>-r<span class="w"> </span><span class="o">[</span>InitialRandom<span class="o">]</span><span class="w"> </span>-g<span class="w"> </span><span class="o">[</span>OpenGL<span class="o">]</span><span class="w"> </span>-e<span class="w"> </span><span class="o">[</span>VirielStress<span class="o">]</span><span class="w"> </span>-o<span class="w"> </span><span class="o">[</span>Verbose<span class="o">]</span><span class="w"> </span>-p<span class="w"> </span><span class="o">[</span>Potential<span class="o">]</span><span class="w"> </span>-x<span class="w"> </span>&lt;None<span class="p">|</span>NegExp<span class="p">|</span>CorRad&gt;<span class="w"> </span>-d<span class="w"> </span>&lt;DeviceId&gt;<span class="w"> </span>-n<span class="w"> </span>&lt;NumberOfParticules&gt;<span class="w"> </span>-i<span class="w"> </span>&lt;Iterations&gt;<span class="w"> </span>-z<span class="w"> </span>&lt;SizeOfBoxOrBall&gt;<span class="w"> </span>-v<span class="w"> </span>&lt;Velocity&gt;<span class="w"> </span>-s<span class="w"> </span>&lt;Step&gt;<span class="w"> </span>-b<span class="w"> </span>&lt;Ball<span class="p">|</span>Box&gt;<span class="w"> </span>-m<span class="w"> </span>&lt;ImplicitEuler<span class="p">|</span>RungeKutta<span class="p">|</span>ExplicitEuler<span class="p">|</span>Heun&gt;<span class="w"> </span>-t<span class="w"> </span>&lt;FP32<span class="p">|</span>FP64&gt;

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>OpenCL:
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
</pre></div>
</div>
<p>Un certain nombre des paramètres sont à définir avec une valeur :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">&lt;DeviceId&gt;</span></code> : sélection du périphérique (défaut <strong>0</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-n</span> <span class="pre">&lt;NumberOfParticules&gt;</span></code> : nombre de particules du système (défaut <strong>2</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">&lt;Step&gt;</span></code> : pas d’intégration (défaut <strong>1/32</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-m</span> <span class="pre">&lt;ImplicitEuler|RungeKutta|ExplicitEuler|Heun&gt;</span></code> : type d’intégration différentielle (défaut <strong>ImplicitEuler</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">&lt;FP32|FP64&gt;</span></code> : précision de calcul (défaut <strong>FP32</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span> <span class="pre">&lt;Iterations&gt;</span></code> : nombre d’itérations (défaut <strong>10</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-x</span> <span class="pre">&lt;None|NegExp|CorRad&gt;</span></code> : introduction d’un « rayon de coeur » pour éviter les divergences (défaut <strong>None</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-z</span> <span class="pre">&lt;SizeOfBoxOrBall&gt;</span></code> : taille de la boîte ou de la boule (défaut <strong>sqrt(2)</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">&lt;Velocity&gt;</span></code> : vitesse initiale des particules (défaut définie par le Viriel)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">&lt;Ball|Box&gt;</span></code> : type de distribution aléatoire (défaut <strong>Ball</strong>)</p></li>
</ul>
<p>D’autres sont des booléens :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h</span> <span class="pre">[Help]</span></code> : la sortie précédente</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-r</span> <span class="pre">[InitialRandom]</span></code> : défaut</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">[OpenGL]</span></code> : pour une sortie graphique</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">[VirielStress]</span></code> : par défaut</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">[Verbose]</span></code> : impression position et vitesse des particules</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">[Potential]</span></code> : exploitation du potentiel à la place de la force</p></li>
</ul>
<p>Par défaut, une invocation sans option offre la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>NBody.py
Device<span class="w"> </span>choosed<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>
Number<span class="w"> </span>of<span class="w"> </span>particules<span class="w"> </span>:<span class="w"> </span><span class="m">2</span>
Size<span class="w"> </span>of<span class="w"> </span>Shape<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.4142135
Initial<span class="w"> </span>velocity<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.0
Step<span class="w"> </span>of<span class="w"> </span>iteration<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.03125
Number<span class="w"> </span>of<span class="w"> </span>iterations<span class="w"> </span>:<span class="w"> </span><span class="m">10</span>
Method<span class="w"> </span>of<span class="w"> </span>resolution<span class="w"> </span>:<span class="w"> </span>ImplicitEuler
Initial<span class="w"> </span>Random<span class="w"> </span><span class="k">for</span><span class="w"> </span>RNG<span class="w"> </span>Seed<span class="w"> </span>:<span class="w"> </span>False
ValueType<span class="w"> </span>is<span class="w"> </span>:<span class="w"> </span>FP32
Viriel<span class="w"> </span>distribution<span class="w"> </span>of<span class="w"> </span>stress<span class="w"> </span>:<span class="w"> </span>True
OpenGL<span class="w"> </span>real<span class="w"> </span><span class="nb">time</span><span class="w"> </span>rendering<span class="w"> </span>:<span class="w"> </span>False
Speed<span class="w"> </span>rendering<span class="w"> </span>:<span class="w"> </span>False
Interaction<span class="w"> </span><span class="nb">type</span><span class="w"> </span>:<span class="w"> </span>Force
Counter<span class="w"> </span>Artevasion<span class="w"> </span><span class="nb">type</span><span class="w"> </span>:<span class="w"> </span>None
<span class="o">(</span><span class="s1">&#39;CPU/GPU selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz&#39;</span><span class="o">)</span>
<span class="o">(</span><span class="s1">&#39;Platform selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;AMD Accelerated Parallel Processing&#39;</span><span class="o">)</span>
/usr/lib/python2.7/dist-packages/pyopencl/cffi_cl.py:1470:<span class="w"> </span>CompilerWarning:<span class="w"> </span>Non-empty<span class="w"> </span>compiler<span class="w"> </span>output<span class="w"> </span>encountered.<span class="w"> </span>Set<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">PYOPENCL_COMPILER_OUTPUT</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>to<span class="w"> </span>see<span class="w"> </span>more.
<span class="s2">&quot;to see more.&quot;</span>,<span class="w"> </span>CompilerWarning<span class="o">)</span>
All<span class="w"> </span>particles<span class="w"> </span>superimposed.
All<span class="w"> </span>particules<span class="w"> </span>distributed
Center<span class="w"> </span>Of<span class="w"> </span>Mass<span class="w"> </span>estimated:<span class="w"> </span><span class="o">(</span>-0.05390843,0.25029457,-0.0005747825<span class="o">)</span>
All<span class="w"> </span>particules<span class="w"> </span>stressed
Energy<span class="w"> </span>estimated:<span class="w"> </span><span class="nv">Viriel</span><span class="o">=</span>-5.960464477539063e-08<span class="w"> </span><span class="nv">Potential</span><span class="o">=</span>-0.94194394<span class="w"> </span><span class="nv">Kinetic</span><span class="o">=</span><span class="m">0</span>.47097194

Starting!
..........
Ending!

Center<span class="w"> </span>Of<span class="w"> </span>Mass<span class="w"> </span>estimated:<span class="w"> </span><span class="o">(</span>-0.05390393,0.25027496,-0.00055484474<span class="o">)</span>
Energy<span class="w"> </span>estimated:<span class="w"> </span><span class="nv">Viriel</span><span class="o">=</span>-2.7835369110107422e-05<span class="w"> </span><span class="nv">Potential</span><span class="o">=</span>-0.94973665<span class="w"> </span><span class="nv">Kinetic</span><span class="o">=</span><span class="m">0</span>.4748544

Duration<span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">    </span>Mean:<span class="w">   </span><span class="m">0</span>.0017527103424072265
<span class="w">    </span>Median:<span class="w"> </span><span class="m">0</span>.00153350830078125
<span class="w">    </span>Stddev:<span class="w"> </span><span class="m">0</span>.0007242915279449818
<span class="w">    </span>Min:<span class="w">    </span><span class="m">0</span>.0013959407806396484
<span class="w">    </span>Max:<span class="w">    </span><span class="m">0</span>.0039031505584716797

<span class="w">    </span>Variability:<span class="w">    </span><span class="m">0</span>.4723101450288789

FPS<span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">    </span>Mean:<span class="w">   </span><span class="m">623</span>.2326583734787
<span class="w">    </span>Median:<span class="w"> </span><span class="m">653</span>.6473926380554
<span class="w">    </span>Stddev:<span class="w"> </span><span class="m">130</span>.28936462458745
<span class="w">    </span>Min:<span class="w">    </span><span class="m">256</span>.2032862989432
<span class="w">    </span>Max:<span class="w">    </span><span class="m">716</span>.3627668659266

Squertz<span class="w"> </span><span class="k">in</span><span class="w"> </span>log10<span class="w"> </span><span class="p">&amp;</span><span class="w"> </span><span class="nb">complete</span><span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">    </span>Mean:<span class="w">   </span><span class="m">3</span>.396710194304037<span class="w">       </span><span class="m">2492</span>.9306334939147
<span class="w">    </span>Median:<span class="w"> </span><span class="m">3</span>.417403524471372<span class="w">       </span><span class="m">2614</span>.5895705522216
<span class="w">    </span>Stddev:<span class="w"> </span><span class="m">2</span>.716968957513558<span class="w">       </span><span class="m">521</span>.1574584983498
<span class="w">    </span>Min:<span class="w">    </span><span class="m">3</span>.01064468743274<span class="w">        </span><span class="m">1024</span>.813145195773
<span class="w">    </span>Max:<span class="w">    </span><span class="m">3</span>.4571929965271666<span class="w">      </span><span class="m">2865</span>.4510674637063
</pre></div>
</div>
<p>Les éléments de sortie sont les statistiques de chaque itération, exprimées en <strong>squertz</strong>, contraction de <strong>square</strong> avec <strong>Hertz</strong>. En effet, le nombre de calculs élémentaires évolue suivant une loi en <strong>N(N-1)</strong> (chaque particule parmi <strong>N</strong> intéragit avec les <strong>N-1</strong> autres particules).</p>
<p>Lors de l’initialisation du « système N-Corps », plusieurs opérations sont effectuées :</p>
<ul class="simple">
<li><p>l’initialisation de la position des particules</p></li>
<li><p>la distribution aléatoire des particules dans le volume (boule ou cube)</p></li>
<li><p>la détermination du centre de gravité</p></li>
<li><p>la distribution semi-aléatoire des vitesses en fonction du Viriel</p></li>
<li><p>l’évolution du système</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #23 : étude du source de ``NBody.py``</strong></p>
<ul class="simple">
<li><p>Editez le programme avec gedit</p></li>
<li><p>Identifiez le bloc de noyaux OpenCL : lignes</p></li>
<li><p>Identifiez les appels des noyaux OpenCL : lignes</p></li>
<li><p>Identifiez les récupérations de positions et vitesses des particules</p></li>
<li><p>Identifiez la portion de code OpenGL</p></li>
</ul>
</div>
<p>Pour un lancement sur 32768 particules et les différents périphériques (3 CPU et 2 GPU), pour des calculs en 32 et 64 bits en flottants, nous avons les résultats suivants :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Squertz SP</p></th>
<th class="head"><p>Squertz DP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>2583647198</p></td>
<td><p>1141839568</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>1277518016</p></td>
<td><p>782950973</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>104176444905</p></td>
<td><p>2853097176</p></td>
</tr>
<tr class="row-odd"><td><p>QuadroK420</p></td>
<td><p>3242286836</p></td>
<td><p>116285732</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>4728894103</p></td>
<td><p>1444506859</p></td>
</tr>
</tbody>
</table>
<img alt="nbody_opencluster2" class="img-fluid center" src="../../_images/nbody_opencluster2.png" />
<p>La figure ci-dessus illustre l’écrasante performance de la GTX 1080 Ti en comparaison de toutes les autres implémentations : plus d’un facteur 22 en simple précision et presque un facteur 2 en double précision pour la meilleure des implémentations CPU.</p>
<img alt="nbody_log_opencluster2" class="img-fluid center" src="../../_images/nbody_log_opencluster2.png" />
<p>Seule une représentation en log permet de ne pas trop écraser les performances des implémentations CPU.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #24 : lancement de ``NBody.py`` pour 32768 particules</strong></p>
<ul class="simple">
<li><p>Exécutez le programme pour tous les périphériques détectés</p></li>
<li><p>Ajoutez l’option pour un calcul en 64 bits et réexécutez</p></li>
<li><p>Tracez les histogrammes de performances</p></li>
<li><p>Quel est le ratio entre le meilleur GPU et le meilleur en CPU en 32 bits</p></li>
<li><p>Quel est le ratio entre le meilleur GPU et le meilleur en CPU en 64 bits</p></li>
<li><p>Quel est le ratio pour un même périphérique entre 32 et 64 bits ?</p></li>
</ul>
</div>
<p>Vous pouvez également exécuter <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code> avec l’option <code class="docutils literal notranslate"><span class="pre">-g</span></code> pour disposer d’une animation en temps réel du calcul.</p>
<img alt="nbody_005" class="img-fluid center" src="../../_images/nbody_005.png" />
<p>La fenêtre de rendu offre la vision suivante :</p>
<img alt="nbodygl_004" class="img-fluid center" src="../../_images/nbodygl_004.png" />
<p>La pression sur la touche <code class="docutils literal notranslate"><span class="pre">&lt;Esc&gt;</span></code> permet de sortir du programme pour afficher les statistiques de la simulation.</p>
<img alt="nbody_006" class="img-fluid center" src="../../_images/nbody_006.png" />
<p>Si nous changeons de manière insignifiante le nombre de particules (de 8192 à 8191), nous obtenons des performances très différentes :</p>
<img alt="nbody_007" class="img-fluid center" src="../../_images/nbody_007.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #25 : lancement de ``NBody.py`` en mode ``-g``</strong></p>
<ul class="simple">
<li><p>Exécutez le programme pour le meilleur des CPU sur 8192 particules</p></li>
<li><p>Appuyez sur <code class="docutils literal notranslate"><span class="pre">s</span></code> pour passer des positions aux vitesses</p></li>
<li><p>Utilisez les flèches pour les opérations de rotations</p></li>
<li><p>Utilisez les &lt;+&gt; ou &lt;-&gt; pour les opérations de zoom ou dézoom</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez finalement la performance médiane en Squertz</p></li>
<li><p>Exécutez le programme sur le GPU le plus puissant avec 8192 particules</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez la performance médiane en Squertz</p></li>
<li><p>Exécutez le programme sur le GPU le plus puissant avec 8192 particules</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez la performance médiane en Squertz</p></li>
<li><p>Quel ratio entre Squertz existe entre 8192 et 8191 particules ?</p></li>
<li><p>Pourquoi un tel ratio ?</p></li>
</ul>
</div>
</section>
<section id="exploration-de-codes-metiers">
<h2>Exploration de « codes métiers »<a class="headerlink" href="#exploration-de-codes-metiers" title="Lien vers cette rubrique">¶</a></h2>
<section id="introduction-a-l-integration-de-codes">
<h3>Introduction à l’intégration de codes<a class="headerlink" href="#introduction-a-l-integration-de-codes" title="Lien vers cette rubrique">¶</a></h3>
<p>Les « codes métiers » sont des programmes « de production scientifique ». Il n’est pas question, pour un utilisateur, de modifier le source du programme pour ses activités, notamment de recherche. Le programme est exploité « tel quel » et seuls les paramètres d’entrées changent.</p>
<p>Par contre l”<strong>intégration</strong> d’un code dans un <strong>environnement informatique</strong> (<em>tuple</em> matériel, système d’exploitation, librairies, logiciel, usage) peut s’avérer compliqué, voire complexe. Cette activité d’intégration forme une grande partie de l’activité des personnels des infrastructures de calcul scientifique.</p>
</section>
<section id="exploitation-en-deep-learning-avec-tensorflow">
<h3>Exploitation en Deep Learning avec TensorFlow<a class="headerlink" href="#exploitation-en-deep-learning-avec-tensorflow" title="Lien vers cette rubrique">¶</a></h3>
<p>Nous allons tenter d’exploiter un des exemples présentés dans les <a class="reference external" href="https://www.tensorflow.org/tutorials">tutoriels</a> de <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p>L’exploitation des GPU a littéralement « explosé » lorsque le <em>Machine Learning</em> ou le <em>Deep Learning</em> sont devenus des modes. En effet, la puissance « brute » des GPU peut enfin être exploitée sans trop de portage, notamment par l’exploitation des librairies BLAS.</p>
<p>L’exemple sur lequel nous allons nous pencher est le <a class="reference external" href="https://www.tensorflow.org/tutorials/images/deep_cnn">DeepCNN</a>.</p>
<p>L’intégration de TensorFlow avec une exploitation des GPU est plutôt ardue à partir des sources, étant donné le nombre de dépendances. L’approche <a class="reference external" href="https://docs.conda.io/en/latest/">Conda</a> permet d’installer un « environnement système » bâti essentiellement autour d’applications Python. Conda permet également à tout utilisateur de créer son propre environnement complet lui permettant un suivi personnel de ses outils.</p>
<p>Au CBP, un environnement Conda a été installé pour permettre l’exploitation de la majorité des outils construits autour de TensorFlow. Le chargement de l’environnement se réalise en « sourçant » l’environnement CONDA avec la commande suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/etc/tensorflow.init
</pre></div>
</div>
<p>La commande précédente « paramètre » les variables d’environnement nécessaires l’exploitation de l’environnement complet CONDA installé pour vous dans <code class="docutils literal notranslate"><span class="pre">/opt/anaconda3/</span></code></p>
<p>L’objectif de la session est de lancer un apprentissage sur une base de 60000 mini-images <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>. Là se pose une contrainte dont il faut <strong>impérativement</strong> prendre conscience quand ces outils de <a href="#id4"><span class="problematic" id="id5">*</span></a>-Learning sont exploités : les bases d’apprentissage, leur stockage et leur exploitation. Ces bases ont souvent des tailles de plusieurs GigaBytes à plusieurs dizaines de GB et le nombre de fichiers atteint facilement plusieurs centaines de milliers de fichiers. Leur téléchargement et leur exploitation non maîtrisés peuvent entraîner de graves dysfonctionnements sur des dossiers partagés. Pour cette raison, nous allons exécuté cet apprentissage sur un espace « local », c’est à dire stocké localement sur la machine. Par défaut, le profil utilisateur et ses données de base reposent sur un espace distant pour être retrouvé lors d’un changement de machine. Mais dans ce cas particulier d’exploitation, si 50 personnes chargent et exploitent simultanément de gros volumes de dizaines de milliers de fichiers simultanément, des problèmes apparaissent. Voici la procédure pour l’éviter dans notre cas :</p>
<p>Création de l’espace utilisateur dans l’espace local</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-d<span class="w"> </span>/local/<span class="nv">$USER</span><span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>mkdir<span class="w"> </span>/local/<span class="nv">$USER</span>
<span class="nb">cd</span><span class="w"> </span>/local/<span class="nv">$USER</span>
</pre></div>
</div>
<p>Téléchargement de l’ensemble des tutoriels de TensorFlow au 29 mai :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>http://www.cbp.ens-lyon.fr/emmanuel.quemener/software/tf-models-20190524-1429.tgz
tar<span class="w"> </span>xzf<span class="w"> </span>tf-models-20190524-1429.tgz
</pre></div>
</div>
<p>Déplacement dans le dossier <code class="docutils literal notranslate"><span class="pre">cifar10</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>models/tutorials/image/cifar10
</pre></div>
</div>
<p>Paramétrage et modification de quelques fichiers pour l’exécution</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Paramétrage de la métrologie</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TIME</span><span class="o">=</span><span class="k">$(</span>cat<span class="w"> </span>/etc/time_command.cfg<span class="k">)</span>
<span class="c1"># Définition du dossier de téléchargement par défaut des bases TensorFlow</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">DATADIR</span><span class="o">=</span>/local/<span class="nv">$USER</span>
sed<span class="w"> </span>-i<span class="w"> </span><span class="s2">&quot;s|tfds\.load(name|tfds\.load(data_dir\=\&#39;</span><span class="nv">$DATADIR</span><span class="s2">\&#39;\,name|g&quot;</span><span class="w"> </span>cifar10_input.py
<span class="c1"># Modification du dossier de sauvegarde de l&#39;apprentissage</span>
sed<span class="w"> </span>-i<span class="w"> </span><span class="s1">&#39;s/\/tmp\//$DATADIR/g&#39;</span><span class="w"> </span>cifar10_train.py
<span class="c1"># Réduction du nombre d&#39;itérations de 100000 à 10000</span>
sed<span class="w"> </span>-i<span class="w"> </span><span class="s1">&#39;s/100000/10000/g&#39;</span><span class="w"> </span>cifar10_train.py
</pre></div>
</div>
<p>L’exécution de l’apprentissage s’effectue avec</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/usr/bin/time<span class="w"> </span>python3<span class="w"> </span>cifar10_train.py
</pre></div>
</div>
<p>Voici la sortie sur une machine équipée de GPUs Nvidia RTX 2080 Ti et GTX 1660 Ti.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TIME<span class="w"> </span>Command<span class="w"> </span>being<span class="w"> </span>timed:<span class="w"> </span><span class="s2">&quot;python3 cifar10_train.py&quot;</span>
TIME<span class="w"> </span>User<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">889</span>.04
TIME<span class="w"> </span>System<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">597</span>.06
TIME<span class="w"> </span>Elapsed<span class="w"> </span><span class="o">(</span>wall<span class="w"> </span>clock<span class="o">)</span><span class="w"> </span><span class="nb">time</span><span class="w"> </span>:<span class="w"> </span><span class="m">234</span>.10
TIME<span class="w"> </span>Percent<span class="w"> </span>of<span class="w"> </span>CPU<span class="w"> </span>this<span class="w"> </span>job<span class="w"> </span>got:<span class="w"> </span><span class="m">634</span>%
TIME<span class="w"> </span>Average<span class="w"> </span>shared<span class="w"> </span>text<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>unshared<span class="w"> </span>data<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>stack<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>total<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Maximum<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">5098888</span>
TIME<span class="w"> </span>Average<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Major<span class="w"> </span><span class="o">(</span>requiring<span class="w"> </span>I/O<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">329</span>
TIME<span class="w"> </span>Minor<span class="w"> </span><span class="o">(</span>reclaiming<span class="w"> </span>a<span class="w"> </span>frame<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">1227196</span>
TIME<span class="w"> </span>Voluntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">15535406</span>
TIME<span class="w"> </span>Involuntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">8247917</span>
TIME<span class="w"> </span>Swaps:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>inputs:<span class="w"> </span><span class="m">10117019</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>outputs:<span class="w"> </span><span class="m">1282614</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>sent:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>received:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Signals<span class="w"> </span>delivered:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Page<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>bytes<span class="o">)</span>:<span class="w"> </span><span class="m">4096</span>
TIME<span class="w"> </span>Exit<span class="w"> </span>status:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<p>Le souci, c’est que le temps écoulé ici comprend (la première fois) le téléchargement et l’expansion des archives. Pour disposer d’une comparaison objective du temps de calcul pour 10000 itérations, il faut relancer l’apprentissage.</p>
<p>Une relance du même apprentissage offre la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TIME<span class="w"> </span>Command<span class="w"> </span>being<span class="w"> </span>timed:<span class="w"> </span><span class="s2">&quot;python3 cifar10_train.py&quot;</span>
TIME<span class="w"> </span>User<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">827</span>.48
TIME<span class="w"> </span>System<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">592</span>.54
TIME<span class="w"> </span>Elapsed<span class="w"> </span><span class="o">(</span>wall<span class="w"> </span>clock<span class="o">)</span><span class="w"> </span><span class="nb">time</span><span class="w"> </span>:<span class="w"> </span><span class="m">123</span>.09
TIME<span class="w"> </span>Percent<span class="w"> </span>of<span class="w"> </span>CPU<span class="w"> </span>this<span class="w"> </span>job<span class="w"> </span>got:<span class="w"> </span><span class="m">1153</span>%
TIME<span class="w"> </span>Average<span class="w"> </span>shared<span class="w"> </span>text<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>unshared<span class="w"> </span>data<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>stack<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>total<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Maximum<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">4100296</span>
TIME<span class="w"> </span>Average<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Major<span class="w"> </span><span class="o">(</span>requiring<span class="w"> </span>I/O<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Minor<span class="w"> </span><span class="o">(</span>reclaiming<span class="w"> </span>a<span class="w"> </span>frame<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">933283</span>
TIME<span class="w"> </span>Voluntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">15603184</span>
TIME<span class="w"> </span>Involuntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">8643170</span>
TIME<span class="w"> </span>Swaps:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>inputs:<span class="w"> </span><span class="m">5857597</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>outputs:<span class="w"> </span><span class="m">49573</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>sent:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>received:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Signals<span class="w"> </span>delivered:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Page<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>bytes<span class="o">)</span>:<span class="w"> </span><span class="m">4096</span>
TIME<span class="w"> </span>Exit<span class="w"> </span>status:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<p>Dans le cas d’une exécution uniquement sur CPU (ici 2 Xeon E5-2637 v4 &#64; 3.50GHz), nous avons comme sortie :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TIME<span class="w"> </span>Command<span class="w"> </span>being<span class="w"> </span>timed:<span class="w"> </span><span class="s2">&quot;python3 cifar10_train.py&quot;</span>
TIME<span class="w"> </span>User<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">21180</span>.80
TIME<span class="w"> </span>System<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">1391</span>.54
TIME<span class="w"> </span>Elapsed<span class="w"> </span><span class="o">(</span>wall<span class="w"> </span>clock<span class="o">)</span><span class="w"> </span><span class="nb">time</span><span class="w"> </span>:<span class="w"> </span><span class="m">1711</span>.02
TIME<span class="w"> </span>Percent<span class="w"> </span>of<span class="w"> </span>CPU<span class="w"> </span>this<span class="w"> </span>job<span class="w"> </span>got:<span class="w"> </span><span class="m">1319</span>%
TIME<span class="w"> </span>Average<span class="w"> </span>shared<span class="w"> </span>text<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>unshared<span class="w"> </span>data<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>stack<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Average<span class="w"> </span>total<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Maximum<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">2804244</span>
TIME<span class="w"> </span>Average<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Major<span class="w"> </span><span class="o">(</span>requiring<span class="w"> </span>I/O<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Minor<span class="w"> </span><span class="o">(</span>reclaiming<span class="w"> </span>a<span class="w"> </span>frame<span class="o">)</span><span class="w"> </span>page<span class="w"> </span>faults:<span class="w"> </span><span class="m">283823921</span>
TIME<span class="w"> </span>Voluntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">26722288</span>
TIME<span class="w"> </span>Involuntary<span class="w"> </span>context<span class="w"> </span>switches:<span class="w"> </span><span class="m">6182435</span>
TIME<span class="w"> </span>Swaps:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>inputs:<span class="w"> </span><span class="m">5857601</span>
TIME<span class="w"> </span>File<span class="w"> </span>system<span class="w"> </span>outputs:<span class="w"> </span><span class="m">83979</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>sent:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Socket<span class="w"> </span>messages<span class="w"> </span>received:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Signals<span class="w"> </span>delivered:<span class="w"> </span><span class="m">0</span>
TIME<span class="w"> </span>Page<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>bytes<span class="o">)</span>:<span class="w"> </span><span class="m">4096</span>
TIME<span class="w"> </span>Exit<span class="w"> </span>status:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #26 : appliquez les commandes ci-dessus</strong></p>
<ul>
<li><p>Préparez votre environnement</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>créez le dossier personnel dans <code class="docutils literal notranslate"><span class="pre">/local</span></code></p></li>
<li><p>placez vous dans le dossier fraîchement créé</p></li>
<li><p>récupérer l’archive des tutoriels de TensorFlow</p></li>
<li><p>expandez l’archive dans votre dossier</p></li>
<li><p>définissez la variable <code class="docutils literal notranslate"><span class="pre">TIME</span></code> pour sa métrologie</p></li>
<li><p>déplacez vous dans le dossier <code class="docutils literal notranslate"><span class="pre">models/tutorials/image/cifar10</span></code></p></li>
<li><p>modifiez comme précisé les dossiers de téléchargement et de sauvegarde</p></li>
<li><p>modifiez le nombre d’itérations</p></li>
</ol>
</div></blockquote>
</li>
<li><p>Lancez une première fois l’apprentissage avec <code class="docutils literal notranslate"><span class="pre">cifar10_train.py</span></code></p>
<blockquote>
<div><ul>
<li><p>en cas de plantage lors de l’apprentissage</p>
<blockquote>
<div><ul class="simple">
<li><p>lisez attentivement les messages d’erreur</p></li>
<li><p>si le GPU pose problème, exploitez la variable d’environnement <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
<ol class="arabic simple">
<li><p>notez les informations de sortie préfixées par <code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></li>
</ol>
</div></blockquote>
</li>
<li><p>Lancez une seconde fois l’apprentissage</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>notez les informations de sortie préfixées par <code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></li>
</ol>
</div></blockquote>
</li>
<li><p>Lancez une seconde fois l’apprentissage avec <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES='</span> <span class="pre">'</span></code></p>
<blockquote>
<div><ol class="arabic simple">
<li><p>notez les informations de sortie</p></li>
</ol>
</div></blockquote>
</li>
<li><p>Comparez les résultats</p>
<blockquote>
<div><ul class="simple">
<li><p>Qu’apporte le GPU comme gain de performance par rapport au processeur ?</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</section>
<section id="integration-et-exploitation-du-code-gromacs">
<h3>Intégration et exploitation du code Gromacs<a class="headerlink" href="#integration-et-exploitation-du-code-gromacs" title="Lien vers cette rubrique">¶</a></h3>
<p>Nous allons tenter de reproduire une <a class="reference external" href="https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/gromacs/">expérience de Nvidia</a> vantant l’efficacité des GPGPU pour le logiciel de <a class="reference external" href="https://fr.wikipedia.org/wiki/Dynamique_mol%C3%A9culaire">dynamique moléculaire</a> <a class="reference external" href="http://www.gromacs.org/">Gromacs</a>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #27 : appliquez la « recette » de Nvidia</strong></p>
<ul>
<li><p>La documentation offre ceci :</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>récupérez le source</p></li>
<li><p>étendez l’archive</p></li>
<li><p>créez un dossier pour la construction</p></li>
<li><p>passez dans ce dossier</p></li>
<li><p>préparez la compilation</p></li>
<li><p>compilez le code</p></li>
<li><p>installez les exécutables</p></li>
</ol>
</div></blockquote>
</li>
<li><p>A quelle étape est-ce que cela bloque ? Quel message avez-vous ?</p></li>
<li><p>Trouvez une méthode permettant de régler ce problème.</p></li>
</ul>
</div>
<p>En cas de difficultés, appliquez la <a class="reference internal" href="gromacsGPU.html#gromacsgpu"><span class="std std-ref">recette de Gromacs pour Debian Stretch</span></a> ;-)</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #28 : Exécutez l’exemple `1536`</strong></p>
<ul class="simple">
<li><p>Quel <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> avez-vous pour l’exécution sur GPU (et CPU) ?</p></li>
<li><p>Quel <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> avez-vous pour l’exécution uniquement sur CPU ?</p></li>
<li><p>Quel ratio de performances existe entre les deux exécutions ?</p></li>
</ul>
</div>
</section>
<section id="integration-et-exploitation-du-code-pkdgrav3">
<h3>Intégration et exploitation du code PKDGRAV3<a class="headerlink" href="#integration-et-exploitation-du-code-pkdgrav3" title="Lien vers cette rubrique">¶</a></h3>
<p>Le code PKDGRAV3 est un logiciel de simulation hydrodynamique à la large couverture médiatique en juin 2017. Présenté comme exploitant massivement les GPU, il est disponible sur <a class="reference external" href="https://bitbucket.org/dpotter/pkdgrav3/">bitbucket</a>.</p>
<p>Le code source est accessible par <code class="docutils literal notranslate"><span class="pre">git</span></code> à l’adresse : <a class="reference external" href="https://bitbucket.org/dpotter/pkdgrav3.git">https://bitbucket.org/dpotter/pkdgrav3.git</a></p>
<div class="note note-warning docutils container">
<p><strong>Exercice #29 : Récupérez et compilez le code suivant la documentation fournie</strong></p>
<ul>
<li><p>La documentation offre ceci :</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>récupérez le source</p></li>
<li><p>étendez l’archive</p></li>
<li><p>créez un dossier pour la construction</p></li>
<li><p>passez dans ce dossier</p></li>
<li><p>préparez la compilation</p></li>
<li><p>compilez le code</p></li>
</ol>
</div></blockquote>
</li>
<li><p>A quelle étape est-ce que cela bloque ? Quel message avez-vous ?</p></li>
<li><p>Nouvelle compilation :</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>nettoyez le dossier de construction</p></li>
<li><p>préparez la compilation en précisant un autre compilateur</p></li>
<li><p>compilez le code</p></li>
</ol>
</div></blockquote>
</li>
</ul>
</div>
<p>L’exécution du programme s’effectue en associant l’exécutable <code class="docutils literal notranslate"><span class="pre">pkdgrav3</span></code> au fichier de paramètres <code class="docutils literal notranslate"><span class="pre">cosmology.par</span></code> dans le dossiers <code class="docutils literal notranslate"><span class="pre">examples</span></code>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #30 : Exécutez l’exemple `cosmology.par`</strong></p>
<ul class="simple">
<li><p>Passez dans le dossier <code class="docutils literal notranslate"><span class="pre">examples</span></code></p></li>
<li><p>Exécutez <code class="docutils literal notranslate"><span class="pre">pkdgrav3</span></code> sur <code class="docutils literal notranslate"><span class="pre">cosmology.par</span></code></p></li>
<li><p>L’exécution se déroule-t-elle correctement ?</p></li>
</ul>
</div>
<p>En cas de difficultés, appliquez la <a class="reference internal" href="pkdgrav3.html#pkdgrav3"><span class="std std-ref">recette d’un PKDGRAV3 pour Debian Stretch</span></a> ;-)</p>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Lien vers cette rubrique">¶</a></h2>
<p>Comme vous l’aurez remarqué au cours de ces Travaux Pratiques, l’exploitation peut être pleine de surprises : une métrologie pertinente ne peut se passer de la connaissance du matériel exploité.</p>
<p>L’exploitation de « codes métier » vous aura aussi permis d’entrevoir la difficulté d’intégrer et d’exécuter des programmes dans des environnements pourtant bien homogènes : toutes les stations exploitées ont exactement le même système d’exploitation, <a class="reference internal" href="../../Science/Publications/Sidus/SidusDoc.html#sidusdoc"><span class="std std-ref">SIDUS</span></a>. Les « astuces » permettant de simplement pouvoir exécuter les programmes illustraient aussi que, sans expérience, difficile de s’en sortir.</p>
<p>— <a class="reference external" href="mailto:emmanuel&#46;quemener&#37;&#52;&#48;ens-lyon&#46;fr">Emmanuel Quemener</a> 2020/01/01 19:44</p>
</section>
</section>


              </div>
              <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper mt-4 d-flex justify-content-between">
  <div role="note" aria-label="source link">
    <ul class="this-page-menu">
      <li><a href="../../_sources/Plateformes/Autres/INSAGPU2019.rst.txt"
            rel="nofollow">Montrer le code source</a></li>
    </ul>
   </div>

        </div>
      </div>-->
            </div>
            <div class="clearer"></div>
          </div>
        </div>
      </div>

  
      <div class="clearer"></div>
    </div>
<div class="orange-border right"></div>
  <footer class="container text-white bg-dark mt-5" style="text-align: center; width: 85%;">
    <p class="fs-11 mt-1">
    Centre Blaise Pascal et Pôle Scientifique de Modélisation Numérique, ENS de Lyon - 46, allée d'Italie - 69364 Lyon cedex 07 - France <br>
    Téléphone : +33 (0)4 72 72 86 37 - Email : cbp@ens-lyon.fr 
</p>
      <p class="fs-13">
    &#169; Copyright 2024, PSMN&#39;s Staff.
          Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
      </p>
  </footer>
  <script src="../../_static/main.js"></script>
  <script src="../../_static/jquery.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_bundle.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_popper.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_cdn.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>