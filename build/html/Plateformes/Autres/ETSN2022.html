<!DOCTYPE html>

<html lang="fr" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="shortcut icon" type="image/x-icon" href="../../_static/cbpsmn_logo.png" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>ETSN 2022 : les GPU, la technologie disruptive du 21ème siècle &#8212; Documentation PSMN-CBP </title>
    <script src="../../_static/documentation_options.js?v=d1a510d7"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/translations.js?v=bf059b8c"></script>
    <link href="../../_static/Bootstrap/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/style.css">
    <script src="https://www.google.com/recaptcha/api.js" async defer></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" /> 
  </head><body>  

    <div class="document">
      <div class="orange-border"></div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            <div class="container contenu">
              <header class="list-inline-item" >
    <div class="d-flex justify-content-between">
        <div class="wid-header pt-3">
            <a href="../../index.html">
                <img id="logo_cbp_light" class="img-fluid" src="../../_static/header/cbpsmn_logo.png" alt="logo CBPsmn">
                <img id="logo_cbp_dark" class="img-fluid" src="../../_static/header/cbpsmn_logo_dark.png" alt="logo CBPsmn">
            </a>
        </div>
        <div class="wid-header">
            <button class="btn-theme" id="theme"></button>
            <a href="https://www.ens-lyon.fr/">
                <img id="logo_ens_light" class="img-fluid" src="../../_static/header/Logo_ENS_Lyon.png" alt="logo ENS de Lyon">
                <img id="logo_ens_dark" class="img-fluid" src="../../_static/header/Logo_ENS_Lyon_dark.png" alt="logo ENS de Lyon">
            </a>
        </div>
    </div>
    
    <nav class="navbar navbar-expand-lg">
        <div class="container-fluid">
            
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav me-auto mb-2 mb-lg-0" id="menu">

                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" aria-current="page" role="button" data-bs-toggle="dropdown" aria-expanded="false">Accueil</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../Accueil/Actualites.html">Actualités PSMN</a></li>
                                <li><a class="dropdown-item" href="../../Accueil/Bureau.html">Bureau des Correspondants</a></li>
                                <li><a class="dropdown-item" href="../../Accueil/Evenements.html">Évènements CBP</a></li>
                                <li><a class="dropdown-item" href="../../Accueil/Liens.html">Liens</a></li>
                                <li><a class="dropdown-item" href="../../Accueil/Services.html">Services</a></li>
                                <li class="nav-item dropend">
                                    <a class="dropdown-toggle dropdown-item" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Partenaires</a>
                                    <div class="dropdown-menu">
                                        <ul>
                                            <li><a class="dropdown-item" href="../../Accueil/Laboratoires/ENS.html">Les laboratoires ENS Lyon</a></li> 
                                            <li><a class="dropdown-item" href="../../Accueil/Laboratoires/Udl.html">Les laboratoires Udl</a></li>
                                            <li><a class="dropdown-item" href="../../Accueil/Laboratoires/AURA.html">Les laboratoires région AURA</a></li>
                                            <li><a class="dropdown-item" href="../../Accueil/Laboratoires/CdC.html">Les Centres de Calculs</a></li>
                                            <li><a class="dropdown-item" href="../../Accueil/Laboratoires/PP.html">Les partenaires privés</a></li>
                                        </ul>
                                    </div>
                                </li>
                            </ul>   
                        </div>
                    </li>
                
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Informations</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../Informations/News.html">Fil des news</a></li>
                                <li><a class="dropdown-item" href="../../Informations/Arrets.html">Les arrêts prévus</a></li>
                                <li><a class="dropdown-item" href="../../Informations/Absences.html">Les absences des opérateurs</a></li>
                                <li><a class="dropdown-item" href="../../Informations/StatsUtil.html">Statistiques d'utilisation</a></li>
                                <li><a class="dropdown-item" href="../../Informations/Calendrier.html">Calendrier des évolutions</a></li>
                                <li><a class="dropdown-item" href="../../Informations/Adaptation.html">Adaptation aux nouveaux besoins</a></li>
                                <li><a class="dropdown-item" href="../../Informations/Calculer.html">Pour calculer</a></li>
                                <li><a class="dropdown-item" href="#">F.A.Q.</a></li>
                                <li class="nav-item dropend">
                                    <a class="dropdown-toggle dropdown-item" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Réalisations et solutions</a>
                                    <div class="dropdown-menu">
                                        <ul> 
                                            <li><a class="dropdown-item" href="../../Informations/Realisations/Logiciels.html">Logiciels</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Realisations/Outils.html">Outils système</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Realisations/Materiel.html">Matériel</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Realisations/Reseaux.html">Réseaux</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Realisations/Plateaux.html">Plateaux techniques</a></li> 
                                        </ul>
                                    </div>
                                </li>
                                <li class="nav-item dropend">
                                    <a class="dropdown-toggle dropdown-item" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Classification par activités</a>
                                    <div class="dropdown-menu">
                                        <ul> 
                                            <li><a class="dropdown-item" href="../../Informations/Classification/Etudes.html">Etudes</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Classification/Integration.html">Intégration</a></li> 
                                            <li><a class="dropdown-item" href="../../Informations/Classification/Qualification.html">Qualification</a></li> 
                                        </ul>
                                    </div>
                                </li>
                            </ul>       
                        </div>
                    </li> 
                
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Plateformes</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../DataCenter.html">Data Center</a></li>
                                <li><a class="dropdown-item" href="https://www.ens-lyon.fr/PSMN/Documentation/">Documentations</a></li>
                                <li><a class="dropdown-item" href="../ClustersServeurs.html">Les clusters et les serveurs</a></li>
                                <li><a class="dropdown-item" href="../EquipInfo.html">Equipements informatique</a></li>
                                <li><a class="dropdown-item" href="../ProjetsInfra.html">Projets d'infrastructure</a></li>
                                <li class="nav-item dropend">
                                    <a class="dropdown-toggle dropdown-item" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Supports</a>
                                    <div class="dropdown-menu">
                                        <ul>   
                                            <li><a class="dropdown-item" href="../Supports/RCS.html">Recherche en calcul scientifique</a></li> 
                                            <li><a class="dropdown-item" href="../Supports/RIS.html">Recherche en informatique scientifique</a></li>
                                            <li><a class="dropdown-item" href="../Supports/HN.html">En humanités numériques</a></li>
                                            <li><a class="dropdown-item" href="../Supports/AFJ.html">Administratif, financier et juridique</a></li>
                                        </ul>                                        
                                    </div>
                                </li>  
                            </ul>   
                        </div>
                    </li>
                
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Formation</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../Formation/Formation.html">Formation</a></li>
                                <li><a class="dropdown-item" href="../../Formation/Stage.html">Propositions de stage</a></li>
                            </ul>   
                        </div>
                    </li>
                    
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Science</a>
                        <div class="dropdown-menu">
                            <ul> 
                                <li><a class="dropdown-item" href="../../Science/Publications2024.html">Publications</a></li>
                                <li><a class="dropdown-item" href="../../Science/Theses.html">Thèses</a></li>
                                <li><a class="dropdown-item" href="../../Science/CreationsMulti.html">Créations multimédia</a></li>
                                <li><a class="dropdown-item" href="../../Science/Chercheurs.html">Chercheurs associés</a></li>
                                <li><a class="dropdown-item" href="../../Science/Projets.html">Projets scientifiques + utilisateurs</a></li>
                            </ul>   
                        </div>
                    </li>
                    
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Animation</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../Animation/EvenementsScient.html">Évènements scientifiques</a></li>
                                <li><a class="dropdown-item" href="../../Animation/Services.html">Services proposés aux organisateurs</a></li>
                                <li><a class="dropdown-item" href="../../Animation/PAS.html">Projets d'animation scientifique</a></li>
                                <li><a class="dropdown-item" href="../../Animation/Appels.html">Appel à projets</a></li>
                                <li><a class="dropdown-item" href="../../Animation/Media.html">Médias</a></li>
                                <li class="nav-item dropend">
                                    <a class="dropdown-toggle dropdown-item" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Ateliers HM / PN-SHS</a>
                                    <div class="dropdown-menu">
                                        <ul>
                                            <li><a class="dropdown-item" href="../../Animation/Ateliers/AHN.html">Humanités Numériques (AHN)</a></li> 
                                            <li><a class="dropdown-item" href="../../Animation/Ateliers/ABC.html">Biologie Computationnelle (ABC)</a></li>
                                            <li><a class="dropdown-item" href="../../Animation/Ateliers/ACT.html">Chimie Théorique</a></li>
                                            <li><a class="dropdown-item" href="https://groupes.renater.fr/wiki/apn-shs/index">Pratiques Numériques en SHS (ED483)</a></li>
                                            <li><a class="dropdown-item" href="../../Animation/Ateliers/Guides.html">Guides et Tutoriels</a></li>
                                        </ul>
                                    </div>
                                </li>
                            </ul>   
                        </div>
                    </li>
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Réseaux</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/CECAM.html">CECAM-FR-RA</a></li> 
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/FLMSN.html">FLMSN</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/IXXI.html">IXXI</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/PBIL.html">Pôle Bioinformatique Lyonnais</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/CIRA.html">CIRA: Calcul intensif en Rhône-Alpes</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/GDR.html">GDR Calcul</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/LC.html">LyonCalcul</a></li>
                                <li><a class="dropdown-item" href="../../R%C3%A9seaux/Sierra.html">Sierra</a></li>
                            </ul>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Contacts</a>
                        <div class="dropdown-menu">
                            <ul>
                                <li><a class="dropdown-item" href="../../Contacts/Acces.html ">Accès aux sites</a></li>
                                <li><a class="dropdown-item" href="../../Contacts/Equipe.html">Équipe / Staff</a></li>                                        
                                <li><a class="dropdown-item" href="../../Contacts/Calendrier.html">Calendrier de la salle TP</a></li>
                                <li><a class="dropdown-item" href="../../Contacts/Formulaires.html">Formulaires</a></li>
                            </ul>   
                        </div>
                    </li>  
                </ul>
            </div>
            <div class="container w-25">

<search id="searchbox" role="search">
    <form class="d-flex" style="height: 35px;" action="../../search.html" method="get">
      <input class="form-control me-2 input-search" type="text" name="q" placeholder="Rechercher" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input class="btn btn-search" type="submit" value="Go" />
    </form>
</search>

            </div>

        </div>
    </nav>
</header>
              <div class="pt-4 border-top border-secondary" id="contenu">
                
  <section id="etsn-2022-les-gpu-la-technologie-disruptive-du-21eme-siecle">
<span id="etsn"></span><h1>ETSN 2022 : les GPU, la technologie disruptive du 21ème siècle<a class="headerlink" href="#etsn-2022-les-gpu-la-technologie-disruptive-du-21eme-siecle" title="Lien vers cette rubrique">¶</a></h1>
<div class="note note-warning docutils container">
<p>Contient certainement encore un nombre non négligeable de coquilles… Merci de votre compréhension. Mon adresse de courriel est en bas pour vous permettre d’en assurer l’amélioration !</p>
</div>
<p>Cette session de travaux pratiques se compose de 7 séances de 1h30 du workshop <a class="reference external" href="https://conferences.cirm-math.fr/2842.html">Les GPU, technologie disruptive du 21ème siècle</a>. Elle s’accompagne de 5 cours suivants donnés par Emmanuel Quémener.</p>
<ul class="simple">
<li><p>Cours 1 &amp; 2 : <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/ETSN_IntroductionGPU_Cours12.pdf">Les GPU : technologie disruptive du 21e siècle</a></p></li>
<li><p>Cours 3 : <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/ETSN_PortageEtMetrologie_Cours3.pdf">Portage d’un vieux code, l’occasion d’un retour sur 40 ans d’informatique</a></p></li>
<li><p>Cours 4 : <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/ETSN_MetrologieGPU_Cours4.pdf">Métrologie d’applications</a></p></li>
<li><p>Cours 5 : <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/ETSN_CodesMatrices_Cours5.pdf">Emergence de Codes « Matrices » et conclusion</a></p></li>
</ul>
<section id="cqqcoqp-comment-qui-quand-combien-ou-quoi-pourquoi">
<h2>CQQCOQP : Comment ? Qui ? Quand ? Combien ? Où ? Quoi ? Pourquoi ?<a class="headerlink" href="#cqqcoqp-comment-qui-quand-combien-ou-quoi-pourquoi" title="Lien vers cette rubrique">¶</a></h2>
<ul class="simple">
<li><p><strong>Pourquoi ?</strong> Faire un tour d’horizon des GPUs et appréhender des méthodes d’investigation</p></li>
<li><p><strong>Quoi ?</strong> Programmer, tester et comparer les GPU sur des exemples simples pendant 6 séances de 1h30 heure</p></li>
<li><p><strong>Quand ?</strong> Entre le 25 et le 29 juillet 2022</p></li>
<li><p><strong>Combien ?</strong> Mesurer la performance que les GPUs offrent en comparaison des autres machines</p></li>
<li><p><strong>Où ?</strong> Sur des stations de travail, des noeuds de cluster, des portables (bien configurés), dans des terminaux</p></li>
<li><p><strong>Qui ?</strong> Pour les édudiants, enseignants, chercheurs, personnels techniques curieux</p></li>
<li><p><strong>Comment ?</strong> En appliquant quelques commandes simples, généralement dans des terminaux.</p></li>
</ul>
</section>
<section id="but-de-la-session">
<h2>But de la session<a class="headerlink" href="#but-de-la-session" title="Lien vers cette rubrique">¶</a></h2>
<p>C’est de prendre en main les GPU dans les machines, d’appréhender la programmation en OpenCL et CUDA, de comparer les performances avec des CPU classiques par l’intermédiaire de quelques exemples simples et des codes de production.</p>
</section>
<section id="deroulement-des-sessions-pratiques">
<h2>Déroulement des sessions pratiques<a class="headerlink" href="#deroulement-des-sessions-pratiques" title="Lien vers cette rubrique">¶</a></h2>
<p>Le programme est volontairement touffu mais les explications données et les corrigés devraient permettre de poursuivre l’apprentissage par la pratique hors de cette école d’une unique semaine.</p>
<ul class="simple">
<li><p>Prise en main de l’environnement à distance du <a class="reference external" href="https://www.cbp.ens-lyon.fr/doku.php">Centre Blaise Pascal</a> à l”<a class="reference external" href="https://www.ens-lyon.fr">ENS-Lyon</a></p></li>
<li><p>Découverte du matériel, autant CPU que GPU</p></li>
<li><p>Exploration progressive en OpenCL avec l”<a class="reference external" href="https://documen.tician.de/pyopencl/">exemple de base</a> de la documentation Python/OpenCL</p></li>
<li><p>Un intermède Python/CUDA pour tester <em>l’autre</em> implémentation sur GPU</p></li>
<li><p>La réalisation et le portage d’une transformée de Fourier discrète</p></li>
<li><p>Choix du périphérique en Python et sa programmation</p></li>
<li><p>Utilisation des librairies externes : exemple avec xGEMM</p></li>
<li><p>Intégration de « codes métier » : <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>, <a class="reference external" href="https://www.r-ccs.riken.jp/labs/cbrt/">GENESIS</a> et <a class="reference external" href="http://www.gromacs.org/">Gromacs</a></p></li>
<li><p>Expoitation de codes <em>Matrices</em> pour la métrologie</p></li>
</ul>
<p>De manière à disposer d’une trace de votre travail et de pouvoir l’évaluer, il est recommandé de rédiger un « livre de bord » sur la base des questions posées. N’hésitez pas à faire des copies d’écran et à les intégrer dans votre document.</p>
</section>
<section id="demarrage-de-la-session">
<h2>Démarrage de la session<a class="headerlink" href="#demarrage-de-la-session" title="Lien vers cette rubrique">¶</a></h2>
<section id="prerequis-en-materiel-logiciel-et-humain">
<h3>Prérequis en matériel, logiciel et humain<a class="headerlink" href="#prerequis-en-materiel-logiciel-et-humain" title="Lien vers cette rubrique">¶</a></h3>
<p>De manière à proposer un environnement pleinement fonctionnel, le Centre Blaise Pascal fournit le matériel, les logiciels et un OS correctement intégré. Les personnes qui veulent réaliser cette session sur leur laptop doivent disposer d’un « vrai » système d’exploitation de type Unix, équipé de tout l’environnement adéquat.</p>
<section id="prerequis-pour-le-materiel">
<h4>Prérequis pour le matériel<a class="headerlink" href="#prerequis-pour-le-materiel" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Si vous n’utilisez PAS le CBP, une machine relativement récente avec une GPU intégrée avec circuit Nvidia</p></li>
<li><p>Si vous utilisez le CBP, un laptop disposant d’un écran assez confortable pour afficher une fenêtre de 1024x768, une connexion réseau la plus stable possible et la capacité d’y installer un logiciel adapté.</p></li>
</ul>
</section>
<section id="prerequis-pour-le-logiciel">
<h4>Prérequis pour le logiciel<a class="headerlink" href="#prerequis-pour-le-logiciel" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Si vous n’utilisez pas le CBP, un OS GNU/Linux correctement configuré pour la GPU embarquée avec tous les composants Nvidia, OpenCL, PyOpenCL, PyCUDA.</p>
<ul>
<li><p>Un “apt install time pciutils clinfo nvidia-opencl-icd nvidia-smi pocl-opencl-icd python3-pyopencl python-pyopencl-doc python-pycuda-doc python3-pycuda” devrait être suffisant comme prérequis pour une machine avec un circuit Nvidia pas trop ancien</p></li>
<li><p>Pour les implémentations OpenCL sur CPU sur Debian ou Ubuntu, essayez d’installer celle d”<a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/software/opencl-1.2-intel-cpu_6.4.0.25-2_amd64.deb">Intel</a> et celle d”<a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/software/amd-opencl-icd_15.12-2~bpo8+3_fixed.deb">AMD</a>. A votre environnement s’ajoute un navigateur pour voir cette page ainsi qu’un traitement de texte pour rédiger le compte-rendu de ces séances.</p></li>
</ul>
</li>
<li><p>Si vous utilisez le CBP, il faut avoir installé le logiciel <a class="reference external" href="https://wiki.x2go.org/doku.php/download:start">x2goclient</a> suivant les recommandations de la <a class="reference internal" href="x2go.html#x2go"><span class="std std-ref">documentation du CBP</span></a>. Il est recommandé d’exploiter le traitement de texte et le navigateur dans la session distante.</p></li>
</ul>
<p>Pour choisir « judicieusement » une machine parmi les plus de 130 de machines à disposition, consultez la page <a class="reference external" href="https://www.cbp.ens-lyon.fr/python/forms/CloudCBP">Cloud&#64;CBP</a>. Il est recommandé de prendre une machine disposant d’une GPU de type « Gamer » ou d’une « GPGPU ». Les sélecteurs de la page précédente peuvent vous aider dans ce choix. Coordonnez-vous entre vous pour être si possible chacun sur la vôtre. Ensuite, une fois connecté via x2go, il peut être intéressant de se connecter sur une autre machine de configuration différente pour comparer les résultats de vos expérimentations.</p>
<div class="note note-warning docutils container">
<p>Etant donné la combinatoire des machines, leurs matériels respectifs et la galaxie des OS GNU/Linux et leurs versions, cela peut prendre de quelques minutes à plusieurs heures (voire jamais) de s’assurer de la compatibilité de sa machine avec le prérequis logiciel. Donc l’exploitation de l’environnement du CBP, exactement construit pour suivre ces travaux pratiques, est TRES FORTEMENT recommandée.</p>
</div>
</section>
<section id="prerequis-pour-l-humain">
<h4>Prérequis pour l’humain<a class="headerlink" href="#prerequis-pour-l-humain" title="Lien vers cette rubrique">¶</a></h4>
<ul class="simple">
<li><p>Une allergie à la commande en ligne peut dramatiquement réduire la portée de cette session pratique</p></li>
<li><p>Une pratique des scripts shell sera un avantage, sinon vous avez cette session pour parfaire vos connaissances.</p></li>
</ul>
</section>
</section>
</section>
<section id="investiguer-le-materiel-gpu">
<h2>Investiguer le matériel GPU<a class="headerlink" href="#investiguer-le-materiel-gpu" title="Lien vers cette rubrique">¶</a></h2>
<section id="qu-y-a-t-il-dans-ma-machine">
<h3>Qu’y a-t-il dans ma machine ?<a class="headerlink" href="#qu-y-a-t-il-dans-ma-machine" title="Lien vers cette rubrique">¶</a></h3>
<p>Le matériel en Informatique Scientifique est défini par <a class="reference external" href="https://upload.wikimedia.org/wikipedia/commons/e/e5/Von_Neumann_Architecture.svg">l’architecture de Von Neumann</a> :</p>
<ul class="simple">
<li><p>CPU (Unité Centrale de Traitement) avec CU (Unité de Contrôle) et ALU (Unité Arithmétique &amp; Logique)</p></li>
<li><p>MU (Unité de Mémoire)</p></li>
<li><p>Input and Output Devices : Périphériques d’Entrée et Sortie</p></li>
</ul>
<p>Les GPU sont généralement considérés comme des périphériques d’Entrée/Sortie. Comme la plupart des périphériques installés dans les machines, elles exploitent un bus d’interconnexion <a class="reference external" href="https://en.wikipedia.org/wiki/Conventional_PCI">PCI</a> ou <a class="reference external" href="https://en.wikipedia.org/wiki/PCI_Express">PCI Express</a>.</p>
<p>Pour récupérer la liste des périphériques PCI, utilisez la commande “lspci -nn”. A l’intérieur d’une longue liste apparaissent quelques périphériques <strong>VGA</strong> ou <strong>3D</strong>. Ce sont les périphériques GPU ou GPGPU.</p>
<p>Voici une sortie de la commande “lspci -nn | egrep “(VGA|3D)” “ :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>3b:00.0<span class="w"> </span>VGA<span class="w"> </span>compatible<span class="w"> </span>controller<span class="w"> </span><span class="o">[</span><span class="m">0300</span><span class="o">]</span>:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation<span class="w"> </span>GP102<span class="w"> </span><span class="o">[</span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti<span class="o">]</span><span class="w"> </span><span class="o">[</span>10de:1b06<span class="o">]</span><span class="w"> </span><span class="o">(</span>rev<span class="w"> </span>a1<span class="o">)</span>
a1:00.0<span class="w"> </span>VGA<span class="w"> </span>compatible<span class="w"> </span>controller<span class="w"> </span><span class="o">[</span><span class="m">0300</span><span class="o">]</span>:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation<span class="w"> </span>GK107GL<span class="w"> </span><span class="o">[</span>Quadro<span class="w"> </span>K420<span class="o">]</span><span class="w"> </span><span class="o">[</span>10de:0ff3<span class="o">]</span><span class="w"> </span><span class="o">(</span>rev<span class="w"> </span>a1<span class="o">)</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.1: récuperez la liste des périphériques (GP)GPU</strong></p>
<ul class="simple">
<li><p>Combien de périphériques VGA sont listés ?</p></li>
<li><p>Combien de périphériques 3D sont listés ?</p></li>
<li><p>Récupérez le modèle du circuit de GPU, dans son nom étendu.</p></li>
<li><dl class="simple">
<dt>Récupérez sur le web les informations suivantes pour chaque GPU :</dt><dd><ul>
<li><p>le nombre d’unités de calcul (les « cuda cores » ou les « stream processors »)</p></li>
<li><p>la fréquence de base des coeurs de calcul</p></li>
<li><p>la fréquence de la mémoire</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<p>La (presque) totalité des stations de travail contiennent des cartes Nvidia.</p>
<p>Dans les systèmes <strong>Posix</strong> (<strong>Unix</strong> dans le langage courant), tout est fichier. Les informations sur les circuits Nvidia et leur découverte par le système d’exploitation peuvent être récupérées avec un <code class="docutils literal notranslate"><span class="pre">grep</span></code> dans la commande <code class="docutils literal notranslate"><span class="pre">dmesg</span></code>.</p>
<p>Si le démarrage de la machine n’est pas trop ancien, vous disposez des informations comparables aux suivantes :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="w">   </span><span class="m">19</span>.545688<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>The<span class="w"> </span>NVIDIA<span class="w"> </span>GPU<span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w"> </span><span class="o">(</span>PCI<span class="w"> </span>ID:<span class="w"> </span>10de:1b06<span class="o">)</span>
<span class="w">            </span>NVRM:<span class="w"> </span>NVIDIA<span class="w"> </span>Linux<span class="w"> </span>driver<span class="w"> </span>release.<span class="w">  </span>Please<span class="w"> </span>see<span class="w"> </span><span class="s1">&#39;Appendix</span>
<span class="s1">            NVRM: A - Supported NVIDIA GPU Products&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>this<span class="w"> </span>release<span class="err">&#39;</span>s
<span class="w">            </span>NVRM:<span class="w"> </span>at<span class="w"> </span>www.nvidia.com.
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.545903<span class="o">]</span><span class="w"> </span>nvidia:<span class="w"> </span>probe<span class="w"> </span>of<span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w"> </span>failed<span class="w"> </span>with<span class="w"> </span>error<span class="w"> </span>-1
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.546254<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>The<span class="w"> </span>NVIDIA<span class="w"> </span>probe<span class="w"> </span>routine<span class="w"> </span>failed<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>device<span class="o">(</span>s<span class="o">)</span>.
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.546491<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>None<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>NVIDIA<span class="w"> </span>graphics<span class="w"> </span>adapters<span class="w"> </span>were<span class="w"> </span>initialized!
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.782970<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.783084<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">19</span>.814046<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Loading<span class="w"> </span>NVIDIA<span class="w"> </span>Kernel<span class="w"> </span>Mode<span class="w"> </span>Setting<span class="w"> </span>Driver<span class="w"> </span><span class="k">for</span><span class="w"> </span>UNIX<span class="w"> </span>platforms<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:33:30<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span>
<span class="o">[</span><span class="w">   </span><span class="m">20</span>.264453<span class="o">]</span><span class="w"> </span><span class="o">[</span>drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>nvidia-drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>GPU<span class="w"> </span>ID<span class="w"> </span>0x00008200<span class="o">]</span><span class="w"> </span>Loading<span class="w"> </span>driver
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360807<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">3</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input19
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360885<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">7</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input20
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.360996<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">8</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input21
<span class="o">[</span><span class="w">   </span><span class="m">23</span>.361065<span class="o">]</span><span class="w"> </span>input:<span class="w"> </span>HDA<span class="w"> </span>NVidia<span class="w"> </span>HDMI/DP,pcm<span class="o">=</span><span class="m">9</span><span class="w"> </span>as<span class="w"> </span>/devices/pci0000:80/0000:80:02.0/0000:82:00.1/sound/card2/input22
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.896510<span class="o">]</span><span class="w"> </span><span class="o">[</span>drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>nvidia-drm<span class="o">]</span><span class="w"> </span><span class="o">[</span>GPU<span class="w"> </span>ID<span class="w"> </span>0x00008200<span class="o">]</span><span class="w"> </span>Unloading<span class="w"> </span>driver
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.935658<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Unloading
<span class="o">[</span><span class="w">   </span><span class="m">32</span>.967939<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Unregistered<span class="w"> </span>the<span class="w"> </span>Nvlink<span class="w"> </span>Core,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.034671<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.034724<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.275804<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Unregistered<span class="w"> </span>the<span class="w"> </span>Nvlink<span class="w"> </span>Core,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.993460<span class="o">]</span><span class="w"> </span>nvidia-nvlink:<span class="w"> </span>Nvlink<span class="w"> </span>Core<span class="w"> </span>is<span class="w"> </span>being<span class="w"> </span>initialized,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">244</span>
<span class="o">[</span><span class="w">   </span><span class="m">33</span>.993486<span class="o">]</span><span class="w"> </span>NVRM:<span class="w"> </span>loading<span class="w"> </span>NVIDIA<span class="w"> </span>UNIX<span class="w"> </span>x86_64<span class="w"> </span>Kernel<span class="w"> </span>Module<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">15</span>:29:16<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span><span class="w"> </span><span class="o">(</span>using<span class="w"> </span>threaded<span class="w"> </span>interrupts<span class="o">)</span>
<span class="o">[</span><span class="w">   </span><span class="m">35</span>.110461<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Loading<span class="w"> </span>NVIDIA<span class="w"> </span>Kernel<span class="w"> </span>Mode<span class="w"> </span>Setting<span class="w"> </span>Driver<span class="w"> </span><span class="k">for</span><span class="w"> </span>UNIX<span class="w"> </span>platforms<span class="w">  </span><span class="m">375</span>.66<span class="w">  </span>Mon<span class="w"> </span>May<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:33:30<span class="w"> </span>PDT<span class="w"> </span><span class="m">2017</span>
<span class="o">[</span><span class="w">   </span><span class="m">35</span>.111628<span class="o">]</span><span class="w"> </span>nvidia-modeset:<span class="w"> </span>Allocated<span class="w"> </span>GPU:0<span class="w"> </span><span class="o">(</span>GPU-ccc95482-6681-052e-eb30-20b138412b92<span class="o">)</span><span class="w"> </span>@<span class="w"> </span>PCI:0000:82:00.0
<span class="o">[</span><span class="m">349272</span>.210486<span class="o">]</span><span class="w"> </span>nvidia-uvm:<span class="w"> </span>Loaded<span class="w"> </span>the<span class="w"> </span>UVM<span class="w"> </span>driver<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">8</span><span class="w"> </span>mode,<span class="w"> </span>major<span class="w"> </span>device<span class="w"> </span>number<span class="w"> </span><span class="m">243</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.2 : récupérez les informations de votre machine avec “dmesg | grep -i nvidia”</strong></p>
<ul class="simple">
<li><p>Quelle est la version de pilote chargée par le noyau ?</p></li>
<li><p>Que représente, s’il existe, le  périphérique “input: HDA NVidia” ?</p></li>
<li><p>Est-ce un périphérique graphique ?</p></li>
</ul>
</div>
<p>Le “lsmod” offre la liste des modules chargés par le noyau. Ces modules sont de petits programmes dédiés au support d’une fontion très spécifique du noyau, le moteur du système d’exploitation. Le support d’un périphérique nécessite souvent plusieurs modules.</p>
<p>Un exemple de “lsmod | grep nvidia” sur une station de travail :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvidia_uvm<span class="w">            </span><span class="m">778240</span><span class="w">  </span><span class="m">0</span>
nvidia_drm<span class="w">             </span><span class="m">40960</span><span class="w">  </span><span class="m">4</span>
nvidia_modeset<span class="w">       </span><span class="m">1044480</span><span class="w">  </span><span class="m">3</span><span class="w"> </span>nvidia_drm
nvidia<span class="w">              </span><span class="m">16797696</span><span class="w">  </span><span class="m">108</span><span class="w"> </span>nvidia_modeset,nvidia_uvm
ipmi_msghandler<span class="w">        </span><span class="m">49152</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>nvidia
drm_kms_helper<span class="w">        </span><span class="m">155648</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>nvidia_drm
drm<span class="w">                   </span><span class="m">360448</span><span class="w">  </span><span class="m">7</span><span class="w"> </span>nvidia_drm,drm_kms_helper
</pre></div>
</div>
<p>Nous voyons que 4 modules sont chargés. La dernière colonne (vide pour les deux premières lignes) liste les dépendances entre les modules. Ici <code class="docutils literal notranslate"><span class="pre">nvidia_modeset</span></code> and <code class="docutils literal notranslate"><span class="pre">nvidia_uvm</span></code> dépendent du module <code class="docutils literal notranslate"><span class="pre">nvidia</span></code>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.3 : récupérez les informations de l’hôte par la commande `lsmod | grep nvidia` :</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Les informations sont-elles identiques à celles ci-dessus ? Caractère par caractère ?</p></li>
</ul>
</div></blockquote>
</div>
<p>Le périphérique apparaît également dans le dossier “/dev” (pour <em>device</em>), le dossier parent pour tous les périphériques.</p>
<p>Un “ls -l /dev/nvidia*” offre ce genre d’informations :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w">   </span><span class="m">0</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidia0
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w"> </span><span class="m">255</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidiactl
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">195</span>,<span class="w"> </span><span class="m">254</span><span class="w"> </span>Jun<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">18</span>:17<span class="w"> </span>/dev/nvidia-modeset
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">243</span>,<span class="w">   </span><span class="m">0</span><span class="w"> </span>Jul<span class="w">  </span><span class="m">4</span><span class="w"> </span><span class="m">19</span>:17<span class="w"> </span>/dev/nvidia-uvm
crw-rw-rw-<span class="w"> </span><span class="m">1</span><span class="w"> </span>root<span class="w"> </span>root<span class="w"> </span><span class="m">243</span>,<span class="w">   </span><span class="m">1</span><span class="w"> </span>Jul<span class="w">  </span><span class="m">4</span><span class="w"> </span><span class="m">19</span>:17<span class="w"> </span>/dev/nvidia-uvm-tools
</pre></div>
</div>
<p>Vous pouvez voir que chacun peut accéder au périphérique, à la fois en lecture ET en écriture (le “RW”). Ici, vous avez un seul périphérique Nvidia, “nvidia0”. Sur une machine disposant de plusieurs périphériques Nvidia, nous aurions : “nvidia0”, “nvidia1”, etc…</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.4 : récupérez les informations de votre machine avec “ls -l /dev/* | grep -i nvidia”</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Combien de “/dev/nvidia&lt;number&gt;” avez-vous ?</p></li>
<li><p>Cette information est-elle cohérente avec les 3 précédentes ?</p></li>
</ul>
</div></blockquote>
</div>
<p>Nvidia présente des informations sur l’usage instantané de ses circuits avec la commande “nvidia-smi”. Cette commande peut aussi être exploitée pour régler certains paramètres de la GPU.</p>
<p>Voici un exemple de sortie de la commande “nvidia-smi” :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Fri<span class="w"> </span>Jul<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">07</span>:46:56<span class="w"> </span><span class="m">2017</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">375</span>.66<span class="w">                 </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">375</span>.66<span class="w">                    </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0000</span>:82:00.0<span class="w">      </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">23</span>%<span class="w">   </span>31C<span class="w">    </span>P8<span class="w">    </span>10W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">     </span>35MiB<span class="w"> </span>/<span class="w"> </span>11172MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">  </span>Type<span class="w">  </span>Process<span class="w"> </span>name<span class="w">                               </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">4108</span><span class="w">    </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                              </span>32MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Beaucoup d’informations sont disponibles sur cette sortie :</p>
<ul class="simple">
<li><p>version du pilote et du logiciel “nvidia-smi”</p></li>
<li><p>l’identifiant de chaque GPU</p></li>
<li><p>son nom</p></li>
<li><p>sa localisation sur le bus PCIe</p></li>
<li><p>sa vitesse de ventilateur</p></li>
<li><p>sa température</p></li>
<li><p>ses puissances : instantanée et maximale</p></li>
<li><p>ses « occupations » mémoire : instantanée et maximale</p></li>
<li><p>les processus les exploitant, leur consommation de mémoire et la GPU associée</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.5 : récupérez les informations avec la commande “nvidia-smi”</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Identifiez les caractéristiques ci-dessus et comparer les éléments</p></li>
<li><p>Combien de processus sont-ils listés ?</p></li>
</ul>
</div></blockquote>
</div>
<p>Comme nous l’avons vu dans l’introduction sur la GPU, leur programmation peut-être réalisée par différentes voies. La première, pour les périphériques Nvidia, est d’utiliser l’environnement CUDA. Le problème sera qu’il est impossible de réexploiter votre programme sur une autre plate-forme (une CPU) ou la comparer avec d’autres GPU. <a class="reference external" href="https://www.khronos.org/opencl/">OpenCL</a> reste une approche beaucoup plus polyvalente !</p>
<p>Sur les stations du CBP, la majorité des implémentations de OpenCL sont disponibles, autant sur CPU que sur GPU.</p>
<p>La commande “clinfo” récupère des informations liées à tous les périphériques OpenCL disponibles.
Pour récupérer une sortie compacte, utilisez “clinfo “-l” “.</p>
<p>Tous les périphériques OpenCL sont présentés suivant une hiérarchie plateforme/périphérique (“Platform/Device”).</p>
<p>Voici une sortie de “clinfo “-l” “ pour une des stations de travail :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Platform<span class="w"> </span><span class="c1">#0: AMD Accelerated Parallel Processing</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Platform<span class="w"> </span><span class="c1">#1: Portable Computing Language</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Platform<span class="w"> </span><span class="c1">#2: NVIDIA CUDA</span>
+--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: GeForce GTX 1080 Ti</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#1: Quadro K420</span>
Platform<span class="w"> </span><span class="c1">#3: Intel(R) OpenCL</span>
<span class="sb">`</span>--<span class="w"> </span>Device<span class="w"> </span><span class="c1">#0: Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
</pre></div>
</div>
<ul class="simple">
<li><p>“#0,#0” <strong>AMD Accelerated Parallel Processing</strong> : implémentation CPU de AMD, la plus ancienne, très proche de OpenMP en performances</p></li>
<li><p>“#1,#0” <strong>Portable Computing Language</strong> : implémentation CPU OpenSource. Pas vraiment efficace</p></li>
<li><p>“#2,#0” <strong>Nvidia CUDA</strong> : implémentation CUDA de Nvidia, périphérique 0, une GeForce GTX 1080 Ti</p></li>
<li><p>“#2,#1” <strong>Nvidia CUDA</strong> : implémentation CUDA de Nvidia, périphérique 1, une Quadro K420</p></li>
<li><p>“#3,#0” <strong>Intel(R) OpenCL</strong> : implémentation CPU Intel, plutôt très efficace</p></li>
</ul>
<p>Ainsi, dans cette machine, 5 périphériques OpenCL sont accessibles, 3 permettent de s’adresser au processeur (vu pour le coup comme un périphérique) et 2 sont des GPU Nvidia.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.6 : récupérez les informations avec la commande “clinfo -l”</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Identifiez et comparez votre sortie avec la liste ci-dessus</p></li>
<li><p>De combien de périphériques graphiques disposez-vous ?</p></li>
</ul>
</div></blockquote>
</div>
<p>L’appel de la commande “clinfo” fournit également de nombreuses informations. Cependant, il est impossible avec cette commande de ne récupérer les informations que d’un seul périphérique : la commande “egrep” permet alors de restreindre seulement certains attributs, par exemple “Platform Name”,”Device Name”,”Max compute”,”Max clock”</p>
<p>Sur la plateforme précédente, la commande “clinfo | egrep “(Platform Name|Device Name|Max compute|Max clock)” “ offre comme sortie:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Platform<span class="w"> </span>Name<span class="w">                                   </span>AMD<span class="w"> </span>Accelerated<span class="w"> </span>Parallel<span class="w"> </span>Processing
Platform<span class="w"> </span>Name<span class="w">                                   </span>Portable<span class="w"> </span>Computing<span class="w"> </span>Language
Platform<span class="w"> </span>Name<span class="w">                                   </span>NVIDIA<span class="w"> </span>CUDA
Platform<span class="w"> </span>Name<span class="w">                                   </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>OpenCL
Platform<span class="w"> </span>Name<span class="w">                                   </span>AMD<span class="w"> </span>Accelerated<span class="w"> </span>Parallel<span class="w"> </span>Processing
Device<span class="w"> </span>Name<span class="w">                                     </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>1200MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>Portable<span class="w"> </span>Computing<span class="w"> </span>Language
Device<span class="w"> </span>Name<span class="w">                                     </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>3501MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>NVIDIA<span class="w"> </span>CUDA
Device<span class="w"> </span>Name<span class="w">                                     </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">28</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>1582MHz
Device<span class="w"> </span>Name<span class="w">                                     </span>Quadro<span class="w"> </span>K420
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">1</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>875MHz
Platform<span class="w"> </span>Name<span class="w">                                   </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>OpenCL
Device<span class="w"> </span>Name<span class="w">                                     </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">16</span>
Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>3500MHz
</pre></div>
</div>
<p>Nous distinguons bien les éléments des 5 périphériques OpenCL déjà identifiés au-dessus (3 pour les 3 implémentations de CPU, respectivement d’AMD, PortableCL et Intel) et les deux GPU Nvidia (GTX 1080 Ti et Quadro K420).</p>
<p>Nous constatons par exemple que les nombres d’unités de traitement sont identiques pour les implémentations CPU (16) mais que leurs fréquences ne le sont pas (1200, 3501, 3500 MHz).</p>
<p>L’implémentation AMD récupère, elle, la fréquence instantanée, et les deux autres la fréquence maximale.</p>
<p>Pour les GPU, nous constatons que les fréquences sont bien inférieures à celles des GPU (1582 et 875 MHz).</p>
<p>Quant aux nombres d’unités de calcul (<em>compute units</em>), la première en dispose de 28 et la seconde de 1. Il sera donc intéressant de comparer ces valeurs par rapport aux valeurs trouvables dans les spécifications constructeur.</p>
<p>La notion d’unité de traitement (<em>compute unit</em>) pour les CPU n’est pas la même pour les GPU:</p>
<ul class="simple">
<li><p>pour les CPU, c’est généralement le produit du nombre de coeurs physiques et du nombre de <em>threads</em></p></li>
<li><p>pour les GPU, c’est le nombre de macro-unités de traitement : unité <strong>SM</strong> (pour <em>Stream multiprocessor</em>) chez Nvidia, unité <strong>CU</strong> (pour <em>Compute Unit</em>) chez AMD/ATI.</p></li>
</ul>
<p>Ces unités de traitement disposent (autant pour les GPU que les CPU) d’unités arithmétiques et logiques (<em>Arithmetic and Login Unit</em>) lesquelles sont <em>vraiment</em> en charge du traitement des opérations.</p>
<p>Ainsi, le nombre d’ALU dans chaque <em>Compute Unit</em> varie de 64 à 192 selon les générations de GPU. Ainsi, pour le GPU ci-dessus GTX 1080 Ti, le nombre de <em>Compute Unit</em> mentionné est 28, et le nombre d’ALU (appelé également <em>cuda core</em> par Nvidia) est de 3584 soit 28*128. Le schéma du constructeur du circuit GP102 suivant est trompeur : en fait, il dispose de 30 unités SM, mais sur un GP102, seuls 28 sont activés.</p>
<img alt="Diagramme gp102" class="img-fluid center mb-3" src="../../_images/gp102-block-diagram.jpg" />
<div class="note note-warning docutils container">
<p><strong>Exercice #1.7 : récupérez les informations à l’aide de deux commandes précédentes utilisant “clinfo”</strong></p>
<ul class="simple">
<li><p>Comparez les informations entre les implémentations CPU. Pourquoi ces différences ?</p></li>
<li><p>Comparez le nombre d’unités de traitement des CPU avec celles du Web : <a class="reference external" href="https://ark.intel.com/fr">Ark d’Intel</a></p></li>
<li><p>Comparez le nombre d’unités de traitement des GPU avec celles du Web : site <a class="reference external" href="https://www.nvidia.com/page/products.html#Architectures">spécifications</a> de Nvidia ou Wikipedia</p></li>
<li><p>Comparez les fréquences identifiées avec celles trouvées sur le Web.</p></li>
<li><p>Retrouvez-vous une cohérence entre le nombre de <em>Compute Units</em> et le nombre de <em>cuda cores</em> ?</p></li>
<li><p>Combien de <em>cuda cores</em> contient chaque <em>Compute Unit</em> ?</p></li>
</ul>
</div>
<p>Il est aussi possible de choisir quelle GPU Nvidia exploiter avec la variable d’environnement “CUDA_VISIBLE_DEVICES”. Il existe deux manières de l’exploiter :</p>
<ul class="simple">
<li><p>en préfixant la commande à exécuter (ou son programme) par “CUDA_VISIBLE_DEVICES=#GPU”</p></li>
<li><p>en <em>exportant</em> la variable de manière permanente avec : “export CUDA_VISIBLE_DEVICES=#GPU”</p></li>
</ul>
<p>La commande “nvidia-smi” offrait une liste de périphériques Nvidia identifiés mais les “ID” donnés sont dans l’ordre inverse de celui exigé par “CUDA_VISIBLE_DEVICES”. Par exemple, <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> donne comme <code class="docutils literal notranslate"><span class="pre">ID</span></code> les nombres <code class="docutils literal notranslate"><span class="pre">0</span></code> et <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># N&#39;exploiter que la GPU identifie #0 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># N&#39;exploiter que la GPU identifie #1 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># Exploiter les GPUs identifies #0 et #1 avec nvidia-smi</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span>&lt;MonProgramme&gt;
<span class="c1"># N&#39;exploiter aucune GPU</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="w"> </span>&lt;MonProgramme&gt;
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.8 : récupérez les informations avec `clinfo -l` préfixée de CUDA_VISIBLE_DEVICES</strong></p>
<ul class="simple">
<li><p>Mettez CUDA_VISIBLE_DEVICES=0 clinfo -l et observez la sortie</p></li>
<li><p>Mettez CUDA_VISIBLE_DEVICES=1 clinfo -l et observez la sortie</p></li>
<li><p>Mettez CUDA_VISIBLE_DEVICES=0,1 clinfo -l et observez la sortie</p></li>
<li><p>Mettez CUDA_VISIBLE_DEVICES='' clinfo -l et observez la sortie</p></li>
<li><p>Avez-vous constaté la sélection des différents périphériques ?</p></li>
</ul>
</div>
<p>Durant toutes les séances de travaux pratiques, l’accent sera mis sur la sollicitation de ressources matérielles, CPU ou GPU, lors des exécutions. Pour avoir une idée des ressources exploitées en temps réel sur la machine sollicitée, il est intéressant d’exploiter les commandes <code class="docutils literal notranslate"><span class="pre">dstat</span></code> et <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> (déjà connue) dans deux terminaux sur votre bureau à distance avec les options <code class="docutils literal notranslate"><span class="pre">-cim</span></code> pour la première et <code class="docutils literal notranslate"><span class="pre">dmon</span></code> pour la seconde.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #1.9 : lancez les commandes suivantes</strong></p>
<ul class="simple">
<li><p>Ouvrez un terminal, tapez <code class="docutils literal notranslate"><span class="pre">dstat</span> <span class="pre">-cim</span></code> et observez la sortie</p></li>
<li><p>Détaillez à quoi servent les paramètres de sortie <code class="docutils literal notranslate"><span class="pre">c</span></code>, <code class="docutils literal notranslate"><span class="pre">i</span></code> et <code class="docutils literal notranslate"><span class="pre">m</span></code></p></li>
<li><p>Ouvrez un terminal, tapez <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">dmon</span></code> et observez la sortie</p></li>
<li><p>Détaillez à quoi sert l’option <code class="docutils literal notranslate"><span class="pre">dmon</span></code></p></li>
<li><p>Arrêtez l’exécution de la précédente avec <code class="docutils literal notranslate"><span class="pre">&lt;Ctrl&gt;&lt;C&gt;</span></code></p></li>
<li><p>Relancez la commande précédente avec <code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">0</span></code> ou <code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">1</span></code></p></li>
<li><p>Détaillez à quoi sert l’option <code class="docutils literal notranslate"><span class="pre">-d</span></code> suivie d’un entier</p></li>
</ul>
</div>
</section>
</section>
<section id="recuperation-des-sources">
<h2>Récupération des sources<a class="headerlink" href="#recuperation-des-sources" title="Lien vers cette rubrique">¶</a></h2>
<p>La (presque) totalité des outils exploités par le CBP pour comparer les CPU et les GPU se trouve dans le projet <a class="reference external" href="https://forge.cbp.ens-lyon.fr/redmine/projects/bench4gpu">bench4gpu</a> du Centre Blaise Pascal.</p>
<p>La récupération des sources est libre et se réalise par l’outil <strong>subversion</strong> (<em>NDLR : oui, je sais tout le monde est passé à GIT mais ce projet a plus de 10 ans</em>) :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>svn<span class="w"> </span>checkout<span class="w"> </span>https://forge.cbp.ens-lyon.fr/svn/bench4gpu/
</pre></div>
</div>
<p>Dans ce dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu</span></code>, il y a plusieurs dossiers :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BLAS</span></code> contenant les dossiers <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> et <code class="docutils literal notranslate"><span class="pre">xTRSV</span></code> : tests exploitant toutes les implémentations de librairies BLAS</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Epidevomath</span></code> : un prototype d’implémentation sur GPU d’un projet (abandonné)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FFT</span></code> contenant une première exploitation de <strong>cuFFT</strong> (en suspens)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Ising</span></code> : implémentations multiples du <a class="reference external" href="https://fr.wikipedia.org/wiki/Mod%C3%A8le_d%27Ising">modèle d’Ising</a> en Python (multiples parallélisations)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NBody</span></code> : implémentation en OpenCL d’un modèle N-Corps newtonien</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi</span></code> : implémentation multiples d’un <a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo">Pi Monte Carlo</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Splutter</span></code> : un modèle de <code class="docutils literal notranslate"><span class="pre">postillonneur</span> <span class="pre">mémoire</span></code>, très utile pour évaluer les <em>fonctions atomiques</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TrouNoir</span></code> : un exemple de portage de code de 1994, porté en C en 1997 puis en Python/OpenCL et Python/CUDA en 2019</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ETSN</span></code> : les programmes <em>corrigés</em> associés à cette école ETSN 2022</p></li>
</ul>
<p>De tous ces programmes, seuls ceux présents dans <code class="docutils literal notranslate"><span class="pre">BLAS</span></code>, <code class="docutils literal notranslate"><span class="pre">NBody</span></code>, <code class="docutils literal notranslate"><span class="pre">Pi</span></code> et <code class="docutils literal notranslate"><span class="pre">ETSN</span></code> seront exploités dans le cadre de ces travaux pratiques. Il est quand même conseillé de ne pas se précipiter sur les corrigés situés dans ETSN pour le déroulement de ces séances. Le <em>no pain, no gain</em> s’applique <em>aussi</em> dans l’apprentissage en informatique.</p>
</section>
</section>
<section id="premiere-exploration-de-l-association-python-et-opencl">
<h1>Première exploration de l’association Python et OpenCL<a class="headerlink" href="#premiere-exploration-de-l-association-python-et-opencl" title="Lien vers cette rubrique">¶</a></h1>
<p>Basons-nous pour ce premier programme sur celui présenté sur la <a class="reference external" href="https://documen.tician.de/pyopencl/">documentation officielle de PyOpenCL</a>. Il se propose d’ajouter deux vecteurs <code class="docutils literal notranslate"><span class="pre">a_np</span></code> et <code class="docutils literal notranslate"><span class="pre">b_np</span></code> en un vecteur <code class="docutils literal notranslate"><span class="pre">res_np</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>

import<span class="w"> </span>numpy<span class="w"> </span>as<span class="w"> </span>np
import<span class="w"> </span>pyopencl<span class="w"> </span>as<span class="w"> </span>cl

<span class="nv">a_np</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>np.random.rand<span class="o">(</span><span class="m">50000</span><span class="o">)</span>.astype<span class="o">(</span>np.float32<span class="o">)</span>
<span class="nv">b_np</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>np.random.rand<span class="o">(</span><span class="m">50000</span><span class="o">)</span>.astype<span class="o">(</span>np.float32<span class="o">)</span>

<span class="nv">ctx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.create_some_context<span class="o">()</span>
<span class="nv">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.CommandQueue<span class="o">(</span>ctx<span class="o">)</span>

<span class="nv">mf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.mem_flags
<span class="nv">a_g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.Buffer<span class="o">(</span>ctx,<span class="w"> </span>mf.READ_ONLY<span class="w"> </span><span class="p">|</span><span class="w"> </span>mf.COPY_HOST_PTR,<span class="w"> </span><span class="nv">hostbuf</span><span class="o">=</span>a_np<span class="o">)</span>
<span class="nv">b_g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.Buffer<span class="o">(</span>ctx,<span class="w"> </span>mf.READ_ONLY<span class="w"> </span><span class="p">|</span><span class="w"> </span>mf.COPY_HOST_PTR,<span class="w"> </span><span class="nv">hostbuf</span><span class="o">=</span>b_np<span class="o">)</span>

<span class="nv">prg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.Program<span class="o">(</span>ctx,<span class="w"> </span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">__kernel void sum(</span>
<span class="s2">    __global const float *a_g, __global const float *b_g, __global float *res_g)</span>
<span class="s2">{</span>
<span class="s2">int gid = get_global_id(0);</span>
<span class="s2">res_g[gid] = a_g[gid] + b_g[gid];</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span><span class="o">)</span>.build<span class="o">()</span>

<span class="nv">res_g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cl.Buffer<span class="o">(</span>ctx,<span class="w"> </span>mf.WRITE_ONLY,<span class="w"> </span>a_np.nbytes<span class="o">)</span>
<span class="nv">knl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>prg.sum<span class="w">  </span><span class="c1"># Use this Kernel object for repeated calls</span>
knl<span class="o">(</span>queue,<span class="w"> </span>a_np.shape,<span class="w"> </span>None,<span class="w"> </span>a_g,<span class="w"> </span>b_g,<span class="w"> </span>res_g<span class="o">)</span>

<span class="nv">res_np</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>np.empty_like<span class="o">(</span>a_np<span class="o">)</span>
cl.enqueue_copy<span class="o">(</span>queue,<span class="w"> </span>res_np,<span class="w"> </span>res_g<span class="o">)</span>

<span class="c1"># Check on CPU with Numpy:</span>
print<span class="o">(</span>res_np<span class="w"> </span>-<span class="w"> </span><span class="o">(</span>a_np<span class="w"> </span>+<span class="w"> </span>b_np<span class="o">))</span>
print<span class="o">(</span>np.linalg.norm<span class="o">(</span>res_np<span class="w"> </span>-<span class="w"> </span><span class="o">(</span>a_np<span class="w"> </span>+<span class="w"> </span>b_np<span class="o">)))</span>
assert<span class="w"> </span>np.allclose<span class="o">(</span>res_np,<span class="w"> </span>a_np<span class="w"> </span>+<span class="w"> </span>b_np<span class="o">)</span>
</pre></div>
</div>
<p>Un programme aussi simple, que nous allons peu à peu modifier, va nous servir de socle pour explorer de nombreuses facettes de Python en général et l’exploitation des GPU en particulier.</p>
<p>En cas de succès à l’exécution, sur une machine du CBP, par exemple la machine <strong>gtxtitan</strong>, le programme demande d’abord de choisir une plateforme :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Choose<span class="w"> </span>platform:
<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Platform<span class="w"> </span><span class="s1">&#39;NVIDIA CUDA&#39;</span><span class="w"> </span>at<span class="w"> </span>0x288ab00&gt;
<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Platform<span class="w"> </span><span class="s1">&#39;Portable Computing Language&#39;</span><span class="w"> </span>at<span class="w"> </span>0x14b6a4754008&gt;
<span class="o">[</span><span class="m">2</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Platform<span class="w"> </span><span class="s1">&#39;AMD Accelerated Parallel Processing&#39;</span><span class="w"> </span>at<span class="w"> </span>0x14b69c602a18&gt;
<span class="o">[</span><span class="m">3</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Platform<span class="w"> </span><span class="s1">&#39;Intel(R) OpenCL&#39;</span><span class="w"> </span>at<span class="w"> </span>0x2a47810&gt;
</pre></div>
</div>
<p>Puis un périphérique (s’il y en a plusieurs) :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Choose<span class="w"> </span>device<span class="o">(</span>s<span class="o">)</span>:
<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Device<span class="w"> </span><span class="s1">&#39;NVIDIA GeForce GTX TITAN&#39;</span><span class="w"> </span>on<span class="w"> </span><span class="s1">&#39;NVIDIA CUDA&#39;</span><span class="w"> </span>at<span class="w"> </span>0x286dab0&gt;
<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span>&lt;pyopencl.Device<span class="w"> </span><span class="s1">&#39;Quadro K420&#39;</span><span class="w"> </span>on<span class="w"> </span><span class="s1">&#39;NVIDIA CUDA&#39;</span><span class="w"> </span>at<span class="w"> </span>0x289ef90&gt;
</pre></div>
</div>
<p>Une fois le choix effectué, la sortie est la suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Set<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">PYOPENCL_CTX</span><span class="o">=</span><span class="s1">&#39;0:0&#39;</span><span class="w"> </span>to<span class="w"> </span>avoid<span class="w"> </span>being<span class="w"> </span>asked<span class="w"> </span>again.
<span class="o">[</span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span>...<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>
<span class="m">0</span>.0
</pre></div>
</div>
<p>Ces choix et cette sortie nous rapportent au chapitre précédent lorsque nous avions exploité la commande “clinfo -l”. Nous avions vu que les périphériques OpenCL sont adressables par un tuple <code class="docutils literal notranslate"><span class="pre">(plateforme,périphérique)</span></code>. Là, dans cet exemple, nous avons 2 périphériques <strong>Nvidia</strong> dont OpenCL nous donne les caractéristiques : <strong>GeForce GTX Titan</strong> et <strong>Quadro K420</strong>.</p>
<p>L’information importante ici est l’exploitation possible d’une variable d’environnement (“PYOPENCL_CTX”) pour sélectionner directement le périphérique à l’exécution. Par exemple, en préfixant l’exécution de <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=0:1</span></code>, nous sélectionnons la <strong>Quadro K420</strong> et avec <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=3</span></code> l’implémentation CPU de Intel <strong>Intel(R) OpenCL</strong>.</p>
<p>Nous verrons par la suite la possibilité de directement choisir le périphérique à l’intérieur même du code. Mais, cette opération étant un peu <em>technique</em>, nous nous contenterons de la variable d’environnement <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX</span></code> préfixant la commande dans un premier temps.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #2.1 : première exécution</strong></p>
<ul class="simple">
<li><p>Exploitez un éditeur (par exemple <strong>gedit</strong>)</p></li>
<li><p>Copiez/Coller le contenu du programme source précédent</p></li>
<li><p>Enregistrez le source avec le nom <code class="docutils literal notranslate"><span class="pre">MySteps.py</span></code></p></li>
<li><p>Lancez le avec et jugez de l’exécution : <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">MySteps.py</span></code></p></li>
<li><p>Lancez le avec et jugez de l’exécution : <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">MySteps.py</span></code></p></li>
<li><p>Changez les droits d’exécution de <code class="docutils literal notranslate"><span class="pre">MySteps.py</span></code></p></li>
<li><p>Lancez le directement avec <code class="docutils literal notranslate"><span class="pre">./MySteps.py</span></code></p></li>
<li><p>En cas d’échec de lancement, modifiez <code class="docutils literal notranslate"><span class="pre">MySteps.py</span></code></p></li>
<li><dl class="simple">
<dt>Préfixez le lancement avec TOUTES les combinaisons de <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX</span></code></dt><dd><ul>
<li><p>par exemple : <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=X:Y</span> <span class="pre">./MySteps.py</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Redirigez les <em>sorties standards</em> dans des fichiers <code class="docutils literal notranslate"><span class="pre">MySteps_XY.out</span></code></dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">(X,Y)</span></code> sont définis comme les <code class="docutils literal notranslate"><span class="pre">(plateforme,périphérique)</span></code></p></li>
<li><p>Attention, s’il n’existe qu’un <code class="docutils literal notranslate"><span class="pre">X</span></code> et pas de <code class="docutils literal notranslate"><span class="pre">Y</span></code>, spécifiez uniquement <code class="docutils literal notranslate"><span class="pre">X</span></code></p></li>
<li><p>Ex.: <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=X:Y</span> <span class="pre">./MySteps.py</span> <span class="pre">&gt;</span> <span class="pre">MySteps_XY.out</span> <span class="pre">2&gt;&amp;1</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<p>Cet exemple de démonstration va être profondément modifié pour le transformer en un <em>code matrice</em>, un exemple de base qu’il sera possible d’exploiter pour toute nouvelle exploration. Sa documentation interne devra être assez explicite pour comprendre toutes les parties.</p>
<p>Nous commençons d’abord par copier ce programme comme la strate <strong>0</strong> de notre apprentissage : nous avons désormais un <code class="docutils literal notranslate"><span class="pre">MySteps_0.py</span></code> dans le même dossier. Comme premières opérations, nous allons :</p>
<ul class="simple">
<li><p>commenter le code en isolant les parties, notamment celles liées à OpenCL</p></li>
<li><p>extraire le processus <em>natif</em>  de calcul dans une fonction <code class="docutils literal notranslate"><span class="pre">NativeAddition</span></code></p></li>
<li><p>extraire le processus <em>OpenCL</em> complet dans une fonction <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code></p></li>
<li><p>appeler la fonction <code class="docutils literal notranslate"><span class="pre">NativeAddition</span></code> pour trouver le résultat <code class="docutils literal notranslate"><span class="pre">res_np</span></code></p></li>
<li><p>appeler la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code> pour trouver le résultat <code class="docutils literal notranslate"><span class="pre">res_cl</span></code></p></li>
<li><p>modifier les tests avec les résultats <code class="docutils literal notranslate"><span class="pre">res_np</span></code> et <code class="docutils literal notranslate"><span class="pre">res_cl</span></code></p></li>
</ul>
<p>En ne modifiant pas encore les <em>sorties</em> du programme (<code class="docutils literal notranslate"><span class="pre">stdin</span></code> et <code class="docutils literal notranslate"><span class="pre">stdout</span></code>), nous nous assurons que nous n’avons pas perturbé cette réorganisation interne du programme.</p>
<p>Le travail suivant va être d’effectuer les opérations précédentes sur <code class="docutils literal notranslate"><span class="pre">MySteps_0.py</span></code> afin d’obtenir les mêmes sorties (au caractère près) que celles que nous avons déjà obtenues.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #2.2 : modifier sans changer la sortie</strong></p>
<ul class="simple">
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_0.py</span></code> suivant les 6 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour plusieurs périphériques</p></li>
<li><p>Sauvez pour chaque exécution la sortie standard</p></li>
<li><p>Comparez avec la commande <code class="docutils literal notranslate"><span class="pre">diff</span></code> les sorties des exercices 2.1 et 2.2</p></li>
</ul>
</div>
<p>L’étape suivante va permettre d’explorer le comportement du programme <em>à la charge</em> pour les différents types de périphériques, l’objectif étant de <em>juger</em> de l’intérêt du portage sur OpenCL en général ou sur GPU en particulier.</p>
<p>Le programme <code class="docutils literal notranslate"><span class="pre">MySteps_1.py</span></code> va intégrer les modifications suivantes :</p>
<ul class="simple">
<li><p>la possibilité de passer en argument à l’exécution la taille des vecteurs</p></li>
<li><p>le temps d’exécution de la commande native</p></li>
<li><p>le temps d’exécution de la commande en OpenCL</p></li>
<li><p>une estimation de la vitesse d’exécution en natif pour différentes tailles</p></li>
<li><p>une estimation de la vitesse d’exécution en OpenCL pour différentes tailles</p></li>
<li><p>un ratio de performances entre mode natif et mode OpenCL</p></li>
<li><p>la libération des mémoires réservées dans le bloc <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code></p></li>
</ul>
<p>Deux exécutions consécutives sur GPU et CPU permettront ainsi de visualiser le gain entre une exécution sur CPU et GPU.</p>
<p>Le passage de l’argument au programme exploitera la librairie standard <code class="docutils literal notranslate"><span class="pre">sys</span></code>.</p>
<p>Le temps d’exécution se basera sur un mécanisme très simple : l’exploitation de 2 <em>timers</em>, le premier avant l’exécution, le second après l’exécution. Ce <em>timer</em> est la fonction <code class="docutils literal notranslate"><span class="pre">time()</span></code> de la librairie standard <code class="docutils literal notranslate"><span class="pre">time</span></code>.</p>
<p>Pour libérer l’espace réservé sur le périphérique avec les opérations <code class="docutils literal notranslate"><span class="pre">Buffer</span></code>, il suffit d’appeler la fonction <code class="docutils literal notranslate"><span class="pre">.release()</span></code> en suffixe de la variable.</p>
<p>Par exemple, à la commande <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=0:0</span> <span class="pre">./MySteps_1.py</span> <span class="pre">1048576</span></code>, l’exécution répond :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1048576</span>
NativeRate:<span class="w"> </span><span class="m">899396014</span>
OpenCLRate:<span class="w"> </span><span class="m">2873687</span>
OpenCLvsNative<span class="w"> </span>ratio:<span class="w"> </span><span class="m">0</span>.003195
<span class="o">[</span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span>...<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>
<span class="m">0</span>.0
</pre></div>
</div>
<p>Sur le CPU avec l’implémentation Intel, la commande <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX=3</span> <span class="pre">./MySteps_1.py</span> <span class="pre">1048576</span></code>, l’exécution répond :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NativeRate:<span class="w"> </span><span class="m">916259689</span>
OpenCLRate:<span class="w"> </span><span class="m">2517963</span>
OpenCLvsNative<span class="w"> </span>ratio:<span class="w"> </span><span class="m">0</span>.002748
<span class="o">[</span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span>...<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>
<span class="m">0</span>.0
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #2.3 : instrumentation minimale du code</strong></p>
<ul>
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_1.py</span></code> suivant les 7 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>2^15</strong> à <strong>2^30</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>sur la GPU la plus <em>performante</em></p></li>
<li><p>sur l’implémentation CPU la plus <em>efficace</em> : l’Intel</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Analysez dans quelles situations des problèmes de produisent :</p></li>
<li><p>Raccordez ces difficultés aux spécifications matérielles</p></li>
<li><p>Complétez un tableau avec ces résultats</p></li>
<li><p>Concluez sur l’efficacité de OpenCL dans ce cas d’exploitation</p></li>
</ul>
</div>
<p>Par exemple, sur la machine <strong>gtxtitan</strong> (déjà un peu ancienne), nous avons le tableau de résultats suivant :</p>
<p>Pour la GPU la plus performante, la GTX Titan avec 6GB de RAM :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCLRate</p></th>
<th class="head"><p>Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32768</p></td>
<td><p>892460736</p></td>
<td><p>25740</p></td>
<td><p>0.000029</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1150116765</p></td>
<td><p>213780</p></td>
<td><p>0.000186</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1232636354</p></td>
<td><p>420621</p></td>
<td><p>0.000341</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1329518292</p></td>
<td><p>871262</p></td>
<td><p>0.000655</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1353245080</p></td>
<td><p>1675102</p></td>
<td><p>0.001238</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1007340016</p></td>
<td><p>3765737</p></td>
<td><p>0.003738</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>793727939</p></td>
<td><p>6654994</p></td>
<td><p>0.008384</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>621127212</p></td>
<td><p>13609238</p></td>
<td><p>0.021911</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>637941219</p></td>
<td><p>22441689</p></td>
<td><p>0.035178</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>650779100</p></td>
<td><p>39385219</p></td>
<td><p>0.060520</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>652256978</p></td>
<td><p>59400977</p></td>
<td><p>0.091070</p></td>
</tr>
<tr class="row-odd"><td><p>67108864</p></td>
<td><p>629199642</p></td>
<td><p>82412411</p></td>
<td><p>0.130980</p></td>
</tr>
<tr class="row-even"><td><p>134217728</p></td>
<td><p>653140112</p></td>
<td><p>100425544</p></td>
<td><p>0.153758</p></td>
</tr>
<tr class="row-odd"><td><p>268435456</p></td>
<td><p>650963845</p></td>
<td><p>111139487</p></td>
<td><p>0.170731</p></td>
</tr>
<tr class="row-even"><td><p>536870912</p></td>
<td colspan="3"><p>650737914</p></td>
</tr>
<tr class="row-odd"><td><p>1073741824</p></td>
<td colspan="3"><p>644699087</p></td>
</tr>
</tbody>
</table>
<p>Les cases <em>vides</em> ne sont pas des oublis : pour ces exécutions sur <strong>gtxtitan</strong>, le programme a <em>planté</em>. Dans notre cas, le message suivant s’affichait</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Traceback<span class="w"> </span><span class="o">(</span>most<span class="w"> </span>recent<span class="w"> </span>call<span class="w"> </span>last<span class="o">)</span>:
File<span class="w"> </span><span class="s2">&quot;/home/equemene/bench4gpu/ETSN/./MySteps_1.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">71</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span><span class="nv">res_cl</span><span class="o">=</span>OpenCLAddition<span class="o">(</span>a_np,b_np<span class="o">)</span>
File<span class="w"> </span><span class="s2">&quot;/home/equemene/bench4gpu/ETSN/./MySteps_1.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">38</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>OpenCLAddition
<span class="w">    </span>knl<span class="o">(</span>queue,<span class="w"> </span>a_np.shape,<span class="w"> </span>None,<span class="w"> </span>a_g,<span class="w"> </span>b_g,<span class="w"> </span>res_g<span class="o">)</span>
File<span class="w"> </span><span class="s2">&quot;/usr/lib/python3/dist-packages/pyopencl/__init__.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">887</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>kernel_call
<span class="w">    </span><span class="k">return</span><span class="w"> </span>self._enqueue<span class="o">(</span>self,<span class="w"> </span>queue,<span class="w"> </span>global_size,<span class="w"> </span>local_size,<span class="w"> </span>*args,<span class="w"> </span>**kwargs<span class="o">)</span>
File<span class="w"> </span><span class="s2">&quot;&lt;generated code&gt;&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">8</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>enqueue_knl_sum
pyopencl._cl.MemoryError:<span class="w"> </span>clEnqueueNDRangeKernel<span class="w"> </span>failed:<span class="w"> </span>MEM_OBJECT_ALLOCATION_FAILURE
</pre></div>
</div>
<p>Son origine était assez explicite avec le <strong>MEM_OBJECT_ALLOCATION_FAILURE</strong> renseignant sur un problème mémoire ou plus précisément sur un dépassement de capacité d’allocation mémoire sur le périphérique. Dans cet exemple, la GPU sélectionnée est une <strong>GTX Titan</strong> avec 6GB de RAM. Notre programme planet dès que la taille des vecteurs dépasse 2|29 éléments soit 536870912. Si nous définissons 3 vecteurs composés de 536870912 flottants sur 32 bits, cela représente tout juste 6 GiB mais la GPU ne dispose que d’exactement 6083 MiB. Il en manque à peine, mais il en manque suffisamment !</p>
<p>Pour la CPU en implémentation Intel :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCLRate</p></th>
<th class="head"><p>Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32768</p></td>
<td><p>803736570</p></td>
<td><p>48080</p></td>
<td><p>0.000060</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1179733506</p></td>
<td><p>229426</p></td>
<td><p>0.000194</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1235406323</p></td>
<td><p>464793</p></td>
<td><p>0.000376</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1321528398</p></td>
<td><p>798832</p></td>
<td><p>0.000604</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1369254829</p></td>
<td><p>1753352</p></td>
<td><p>0.001281</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1010348382</p></td>
<td><p>3357138</p></td>
<td><p>0.003323</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>788462981</p></td>
<td><p>7530766</p></td>
<td><p>0.009551</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>608452462</p></td>
<td><p>15324510</p></td>
<td><p>0.025186</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>529925025</p></td>
<td><p>22077438</p></td>
<td><p>0.041661</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>652698625</p></td>
<td><p>44634386</p></td>
<td><p>0.068384</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>646735880</p></td>
<td><p>52990227</p></td>
<td><p>0.081935</p></td>
</tr>
<tr class="row-odd"><td><p>67108864</p></td>
<td><p>657396843</p></td>
<td><p>92453020</p></td>
<td><p>0.140635</p></td>
</tr>
<tr class="row-even"><td><p>134217728</p></td>
<td><p>650361835</p></td>
<td><p>115909284</p></td>
<td><p>0.178223</p></td>
</tr>
<tr class="row-odd"><td><p>268435456</p></td>
<td><p>650222491</p></td>
<td><p>138080711</p></td>
<td><p>0.212359</p></td>
</tr>
<tr class="row-even"><td><p>536870912</p></td>
<td><p>649709195</p></td>
<td><p>151511835</p></td>
<td><p>0.233199</p></td>
</tr>
<tr class="row-odd"><td><p>1073741824</p></td>
<td><p>655357107</p></td>
<td><p>153145848</p></td>
<td><p>0.233683</p></td>
</tr>
</tbody>
</table>
<p>Des résultats, il est possible de voir que, sur une opération aussi simple qu’une addition, dans aucune situation l’implémentation OpenCL n’apporte le moindre intérêt. L’exécution native en Python est toujours plus rapide d’un facteur 4 sur CPU et d’un facteur 6 sur GPU.</p>
<p>Pire, sur GPU, sur une GTX Titan avec 6GB de RAM, le programme a planté. Ce cas d’usage montre dès à présent ce qu”<strong>IL NE FAUT PAS FAIRE</strong> quand on exploite OpenCL en général et les GPU en particulier.</p>
<p>Toutefois, intéressante consolation, nous notons que, lorsque nous augmentons la taille de nos vecteurs, la performance ne cesse d’augmenter pour les implémentations OpenCL :</p>
<div class="note note-important docutils container">
<p>Utiliser OpenCL, autant sur CPU que sur GPU, exige :
un <strong>nombre d’éléments</strong> sur lesquels s’exécutent les opérations élémentaires est <strong>conséquent</strong> en fonction du périphérique de calcul (de plusieurs milliers à plusieurs millions) ; un <strong>nombre d’opérations élémentaires</strong> à effectuer pour chaque élément d’une <strong>densité arithmétique « suffisante »</strong> (supérieures à la dizaine).</p>
</div>
<p>Pour juger de ces deux caractéristiques, nous allons non pas faire une simple addition de deux vacteurs mais une addition de ces deux vecteurs où chaque élément aura subi un ensemble d’opérations arithmétiques significatives.</p>
<p>Partons donc de notre programme précédent <code class="docutils literal notranslate"><span class="pre">MySteps_1.py</span></code> et copions le dans le programme <code class="docutils literal notranslate"><span class="pre">MySteps_2.py</span></code>.</p>
<p>Nous allons intégrer dans ce programme la fonction empilant successivement les 16 opérations suivantes : <code class="docutils literal notranslate"><span class="pre">cos</span></code>, <code class="docutils literal notranslate"><span class="pre">arccos</span></code>, <code class="docutils literal notranslate"><span class="pre">sin</span></code>, <code class="docutils literal notranslate"><span class="pre">arcsin</span></code>, <code class="docutils literal notranslate"><span class="pre">tan</span></code>, <code class="docutils literal notranslate"><span class="pre">arctan</span></code>, <code class="docutils literal notranslate"><span class="pre">cosh</span></code>, <code class="docutils literal notranslate"><span class="pre">arccosh</span></code>, <code class="docutils literal notranslate"><span class="pre">sinh</span></code>, <code class="docutils literal notranslate"><span class="pre">arcsinh</span></code>, <code class="docutils literal notranslate"><span class="pre">tanh</span></code>, <code class="docutils literal notranslate"><span class="pre">arctanh</span></code>, <code class="docutils literal notranslate"><span class="pre">exp</span></code>, <code class="docutils literal notranslate"><span class="pre">log</span></code>, <code class="docutils literal notranslate"><span class="pre">sqrt</span></code> et enfin élévation à la puissance 2. Comme notre générateur de nombres aléatoires <em>tire</em> entre <strong>0</strong> et <strong>1</strong>, nous devrions retrouver notre nombre initial (modulo les approximations).</p>
<p>Cette fonction, nommée <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> devra être intégrée en Python natif et dans le noyau OpenCL. Lors de l’addition des deux vecteurs, nous appliquerons cette fonction aux éléments de <strong>a</strong> et <strong>b</strong> avant leur addition.</p>
<p>De plus, de manière à juger plus finement des opérations nécessaires en OpenCL, nous allons intrumenter la fonction d’appel pour juger du temps passé à l’exécution dans chacune d’elle.</p>
<p>Ainsi, les modifications du programme à effectuer sont les suivantes :</p>
<ol class="arabic simple">
<li><p>dans la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code>, rajouter des timers sur chaque opération</p></li>
<li><p>dans la fonction précédente, préfixez l’appel du noyau OpenCL par la variable <code class="docutils literal notranslate"><span class="pre">CallCL</span></code></p></li>
<li><p>dans la fonction précédente, rajoutez la ligne <code class="docutils literal notranslate"><span class="pre">CallCL.wait()</span></code> la ligne sous la ligne précédente</p></li>
<li><p>intégrer la fonction <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> en python avec les 16 opérations suivant la liste ci-dessus</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>exploiter au besoin la documentation Python de la librairie <a class="reference external" href="https://numpy.org/doc/stable/reference/routines.math.html">numpy</a></p></li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="5">
<li><p>rajouter la fonction <code class="docutils literal notranslate"><span class="pre">NativeSillyAddition</span></code> appliquant <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> dans le programme</p></li>
<li><p>intégrer la fonction <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> dans le noyau OpenCL avec les 16 opérations</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>exploiter au besoin la <a class="reference external" href="https://www.khronos.org/files/opencl-1-2-quick-reference-card.pdf">carte de référence</a> OpenCL</p></li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="7">
<li><p>rajouter la fonction <code class="docutils literal notranslate"><span class="pre">sillysum</span></code> sur la base de <code class="docutils literal notranslate"><span class="pre">sum</span></code> dans le noyau OpenCL</p></li>
<li><p>rajouter la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLSillyAddition</span></code> sur la base de <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code> dans le programme</p></li>
</ol>
<div class="note note-warning docutils container">
<p><strong>Exercice #2.4 :</strong></p>
<ul class="simple">
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_2.py</span></code> suivant les 8 spécifications ci-dessus</p></li>
<li><dl class="simple">
<dt>Exécutez le programme pour une taille de <strong>32</strong> (soit <strong>2|5</strong>)</dt><dd><ul>
<li><p>sur la GPU la plus <em>performante</em></p></li>
<li><p>sur l’implémentation CPU la plus <em>efficace</em> : l’Intel</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Sauvegardez la sortie des deux exécutions précédentes</p></li>
<li><p>Reexécutez les deux exécutions précédentes</p></li>
<li><p>Sauvegardez la sortie des deux exécutions</p></li>
<li><p>Que constatez-vous sur la durée de la synthèse OpenCL</p></li>
<li><dl class="simple">
<dt>Exécutez le programme pour des tailles de vecteurs de <strong>32</strong> à <strong>33554432</strong></dt><dd><ul>
<li><p>sur la GPU la plus <em>performante</em></p></li>
<li><p>sur l’implémentation CPU la plus <em>efficace</em> : l’Intel</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Analysez dans quelles situations des problèmes de produisent</p></li>
<li><p>Complétez un tableau avec ces résultats</p></li>
</ul>
</div>
<p>Le premier problème rencontré lors de l’exécution génère les lignes comparables à :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Traceback<span class="w"> </span><span class="o">(</span>most<span class="w"> </span>recent<span class="w"> </span>call<span class="w"> </span>last<span class="o">)</span>:
File<span class="w"> </span><span class="s2">&quot;/home/equemene/bench4gpu/ETSN/./MySteps_2.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">189</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>assert<span class="w"> </span>np.allclose<span class="o">(</span>res_np,<span class="w"> </span>res_cl<span class="o">)</span>
AssertionError
</pre></div>
</div>
<p>Cette erreur provient du contrôle <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.allclose.html">numpy.allclose</a> du programme originel sur la comparaison entre résultats en mode natif et OpenCL. Comme le <em>budget</em> d’erreur est dépassé, une exception est levée. Etant donné l’accumulation des fonctions et que nous travaillons (pour l’instant) sur des nombres flottants sur 32 bits, entre 0 et 1, une erreur de inférieur à <code class="docutils literal notranslate"><span class="pre">1e-6</span></code> reste acceptable, mais il faut considérer qu’avec un grand nombre d’éléments, l’erreur cumulée devient significative sur l’ensemble du vecteur. Commenter cette ligne sera salutaire dans la suite.</p>
<p>Sur la comparaison entre les durées de synthèse OpenCL, nous constatons que la première exécution est toujours plus longue que la seconde. Sur notre machine référence, nous passons de <code class="docutils literal notranslate"><span class="pre">0.636s</span></code> à <code class="docutils literal notranslate"><span class="pre">0.017s</span></code> sur GPU (facteur 37) et de <code class="docutils literal notranslate"><span class="pre">0.1</span></code> à <code class="docutils literal notranslate"><span class="pre">0.018</span></code> (facteur 5). Cette différence vient du fait qu’entre les exécutions, les noyaux OpenCL n’ont pas changé : il n’y a pas lieu de refaire la synthèse des noyaux pour chaque périphérique. Ces éléments sont stockés dans <code class="docutils literal notranslate"><span class="pre">$HOME/.cache/pyopencl</span></code>. Il est donc nécessaire, sur de très gros noyaux OpenCL ou dans des tests de métrologie, de regarder ces temps de synthèse face aux temps d’exécution des noyaux.</p>
<p>Par exemple, sur la machine <strong>gtxtitan</strong> (déjà un peu ancienne), nous avons le tableau de résultats suivant :</p>
<p>Pour la GPU la plus performante, la GTX Titan avec 6GB de RAM :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCLRate</p></th>
<th class="head"><p>Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32</p></td>
<td><p>248551</p></td>
<td><p>83</p></td>
<td><p>0.000334</p></td>
</tr>
<tr class="row-odd"><td><p>64</p></td>
<td><p>429496</p></td>
<td><p>207</p></td>
<td><p>0.000482</p></td>
</tr>
<tr class="row-even"><td><p>128</p></td>
<td><p>662803</p></td>
<td><p>407</p></td>
<td><p>0.000614</p></td>
</tr>
<tr class="row-odd"><td><p>256</p></td>
<td><p>842811</p></td>
<td><p>802</p></td>
<td><p>0.000952</p></td>
</tr>
<tr class="row-even"><td><p>512</p></td>
<td><p>923648</p></td>
<td><p>1668</p></td>
<td><p>0.001806</p></td>
</tr>
<tr class="row-odd"><td><p>1024</p></td>
<td><p>1087884</p></td>
<td><p>3351</p></td>
<td><p>0.003080</p></td>
</tr>
<tr class="row-even"><td><p>2048</p></td>
<td><p>1140761</p></td>
<td><p>6712</p></td>
<td><p>0.005884</p></td>
</tr>
<tr class="row-odd"><td><p>4096</p></td>
<td><p>1177025</p></td>
<td><p>13102</p></td>
<td><p>0.011131</p></td>
</tr>
<tr class="row-even"><td><p>8192</p></td>
<td><p>1210276</p></td>
<td><p>26014</p></td>
<td><p>0.021494</p></td>
</tr>
<tr class="row-odd"><td><p>16384</p></td>
<td><p>1225470</p></td>
<td><p>60982</p></td>
<td><p>0.049762</p></td>
</tr>
<tr class="row-even"><td><p>32768</p></td>
<td><p>1220627</p></td>
<td><p>101652</p></td>
<td><p>0.083279</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1217372</p></td>
<td><p>215666</p></td>
<td><p>0.177157</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1232780</p></td>
<td><p>414668</p></td>
<td><p>0.336368</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1231938</p></td>
<td><p>883214</p></td>
<td><p>0.716931</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1374541</p></td>
<td><p>1889005</p></td>
<td><p>1.374281</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1535449</p></td>
<td><p>3529675</p></td>
<td><p>2.298790</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>1523263</p></td>
<td><p>6720366</p></td>
<td><p>4.411823</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>1473851</p></td>
<td><p>12703168</p></td>
<td><p>8.619031</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>1479566</p></td>
<td><p>21404615</p></td>
<td><p>14.466820</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>1482238</p></td>
<td><p>36276007</p></td>
<td><p>24.473807</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>1484349</p></td>
<td><p>52485826</p></td>
<td><p>35.359492</p></td>
</tr>
</tbody>
</table>
<p>Pour la CPU en implémentation Intel :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCLRate</p></th>
<th class="head"><p>Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32</p></td>
<td><p>280790</p></td>
<td><p>98</p></td>
<td><p>0.000349</p></td>
</tr>
<tr class="row-odd"><td><p>64</p></td>
<td><p>426765</p></td>
<td><p>243</p></td>
<td><p>0.000569</p></td>
</tr>
<tr class="row-even"><td><p>128</p></td>
<td><p>627919</p></td>
<td><p>435</p></td>
<td><p>0.000693</p></td>
</tr>
<tr class="row-odd"><td><p>256</p></td>
<td><p>886657</p></td>
<td><p>936</p></td>
<td><p>0.001056</p></td>
</tr>
<tr class="row-even"><td><p>512</p></td>
<td><p>953166</p></td>
<td><p>1837</p></td>
<td><p>0.001927</p></td>
</tr>
<tr class="row-odd"><td><p>1024</p></td>
<td><p>1082128</p></td>
<td><p>3099</p></td>
<td><p>0.002864</p></td>
</tr>
<tr class="row-even"><td><p>2048</p></td>
<td><p>1157829</p></td>
<td><p>6770</p></td>
<td><p>0.005847</p></td>
</tr>
<tr class="row-odd"><td><p>4096</p></td>
<td><p>1183023</p></td>
<td><p>14486</p></td>
<td><p>0.012245</p></td>
</tr>
<tr class="row-even"><td><p>8192</p></td>
<td><p>1211043</p></td>
<td><p>27500</p></td>
<td><p>0.022708</p></td>
</tr>
<tr class="row-odd"><td><p>16384</p></td>
<td><p>1228735</p></td>
<td><p>55910</p></td>
<td><p>0.045502</p></td>
</tr>
<tr class="row-even"><td><p>32768</p></td>
<td><p>1217685</p></td>
<td><p>101244</p></td>
<td><p>0.083145</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1222027</p></td>
<td><p>239095</p></td>
<td><p>0.195654</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1228707</p></td>
<td><p>410382</p></td>
<td><p>0.333995</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1231937</p></td>
<td><p>815420</p></td>
<td><p>0.661901</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1344654</p></td>
<td><p>1754317</p></td>
<td><p>1.304661</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1318155</p></td>
<td><p>3223043</p></td>
<td><p>2.445117</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>1478456</p></td>
<td><p>6306681</p></td>
<td><p>4.265721</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>1527815</p></td>
<td><p>9490882</p></td>
<td><p>6.212062</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>1484125</p></td>
<td><p>14247142</p></td>
<td><p>9.599691</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>1482704</p></td>
<td><p>19512883</p></td>
<td><p>13.160336</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>1474004</p></td>
<td><p>22517796</p></td>
<td><p>15.276618</p></td>
</tr>
</tbody>
</table>
<p>Nous constatons que le gain du passage en OpenCL est significatif, autant sur CPU que sur GPU, si la taille des objets approche le million. Nous avons une accélération de 15 pour le CPU et de 35 sur GPU. En augmentant la charge très significativement (par exemple en n’appelant pas seulement une fois <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> mais 4 fois à la suite, le gain sur CPU passe à 21 tandis qu’il dépasse les 127 sur cette GPU !</p>
<p>De plus, quand nous regardons les durées d’exécution des noyaux en OpenCL, elles sont <em>presque</em> marginales. Ainsi, pour qu’une exécution OpenCL soit <em>efficace</em>, il faudra veiller à ce que le temps d’exécution soit bien supérieur aux autres durées telles que les transferts de données entre hôte et périphérique ou l’initialisation du périphérique de calcul. Le programme <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code> illustre de manière parfaite cet équilibre à établir sur le nombre de tâches concurrentielles à lancer et la <em>profondeur calculatoire</em> (ou l”<em>intensité arithmétique</em>) de chaque noyau.</p>
<section id="un-intermede-cuda-et-son-implementation-pycuda">
<h2>Un intermède CUDA et son implémentation PyCUDA<a class="headerlink" href="#un-intermede-cuda-et-son-implementation-pycuda" title="Lien vers cette rubrique">¶</a></h2>
<p>Nvidia a ressenti tôt la nécessité d’offrir une abstraction de programmation simple pour ses GPU. Elle a même sorti <strong>cg-toolkit</strong> dès 2002. Il faudra attendre l’été 2007 pour un langage complet, seulement limité à quelques GPU de sa gamme.</p>
<p>Aujourd’hui, CUDA est omniprésent dans les librairies du constructeur mais aussi dans l’immense majorité des autres développements. Cependant, son problème vient de l’adhérence au constructeur : CUDA ne sert QUE pour Nvidia. Nous verrons que CUDA a aussi d’autres inconvénient, mais à l’usage.</p>
<p>L’impressionnant <a class="reference external" href="https://mathema.tician.de/aboutme/">Andreas Kloeckner</a> a aussi développé, en plus de PyOpenCL, PyCUDA pour exploiter CUDA à travers Python avec des approches : c’est <a class="reference external" href="https://documen.tician.de/pycuda/">PyCUDA</a>.</p>
<p>L’exemple de la page précédente ressemble fortement à celui que nous modifions depuis le début de nos travaux pratiques. Nous allons l’exploiter pour intégrer cette implémentation CUDA dans notre programme <code class="docutils literal notranslate"><span class="pre">MySteps_3.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MySteps_2.py</span></code>).</p>
<p>Les modifications du programme <code class="docutils literal notranslate"><span class="pre">MySteps_3.py</span></code> sont les suivantes :</p>
<ul>
<li><p>créer une fonction Python <code class="docutils literal notranslate"><span class="pre">CudaAddition</span></code></p></li>
<li><p>intégrer les lignes de l’exemple de <a class="reference external" href="https://documen.tician.de/pycuda/">PyCUDA</a> notamment</p>
<blockquote>
<div><ul class="simple">
<li><p>l’appel des librairies Python</p></li>
<li><p>le noyau CUDA où la multiplication a été remplacée par l’addition</p></li>
<li><p>la création du vecteur destination</p></li>
<li><p>l’appel de l’addition</p></li>
</ul>
</div></blockquote>
</li>
<li><p>entourer avec une exception le <code class="docutils literal notranslate"><span class="pre">allclose</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>cette précaution permet d’empêcher un plantage</p></li>
</ul>
</div></blockquote>
</li>
<li><p>dupliquer et adapter à CUDA les éléments de contrôle de cohérence des résultats</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #3.1 :</strong>
- Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_3.py</span></code> suivant les 3 spécifications ci-dessus
- Exécutez le programme pour des tailles de vecteurs de <strong>32</strong> à <strong>32768</strong>
- Analysez dans quelles situations des problèmes de produisent
- Raccordez ces difficultés aux spécifications matérielles
- Complétez un tableau avec ces résultats
- Concluez sur l’efficacité de CUDA dans ce cas d’exploitation</p>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32</p></td>
<td><p>2982616</p></td>
<td><p>84</p></td>
<td><p>24</p></td>
</tr>
<tr class="row-odd"><td><p>64</p></td>
<td><p>5592405</p></td>
<td><p>196</p></td>
<td><p>70</p></td>
</tr>
<tr class="row-even"><td><p>128</p></td>
<td><p>12485370</p></td>
<td><p>404</p></td>
<td><p>138</p></td>
</tr>
<tr class="row-odd"><td><p>256</p></td>
<td><p>21913098</p></td>
<td><p>789</p></td>
<td><p>270</p></td>
</tr>
<tr class="row-even"><td><p>512</p></td>
<td><p>45691141</p></td>
<td><p>1652</p></td>
<td><p>535</p></td>
</tr>
<tr class="row-odd"><td><p>1024</p></td>
<td><p>84215045</p></td>
<td><p>3153</p></td>
<td><p>1143</p></td>
</tr>
<tr class="row-even"><td><p>2048</p></td>
<td><p>156180628</p></td>
<td colspan="2"><p>6097</p></td>
</tr>
<tr class="row-odd"><td><p>4096</p></td>
<td><p>286331153</p></td>
<td colspan="2"><p>14923</p></td>
</tr>
<tr class="row-even"><td><p>8192</p></td>
<td><p>483939977</p></td>
<td colspan="2"><p>25544</p></td>
</tr>
<tr class="row-odd"><td><p>16384</p></td>
<td><p>694136128</p></td>
<td colspan="2"><p>49892</p></td>
</tr>
<tr class="row-even"><td><p>32768</p></td>
<td><p>947854851</p></td>
<td colspan="2"><p>101677</p></td>
</tr>
</tbody>
</table>
<p>Normalement, si l’implémentation a été correcte, la partie CUDA fonctionne pour les tailles de vecteurs inférieures ou égales à 1024… Cette limitation est en fait dûe à une <em>mauvaise</em> utilisation de CUDA. En effet, CUDA (et dans une moindre mesure OpenCL) comporte 2 <em>étages</em> de parallélisation. Sous OpenCL, ces étages sont les <em>Work Items</em> et les <em>Threads</em>. Sous CUDA, ces étages sont les <em>Blocks</em> et les <em>Threads</em>. Hors, dans les deux approches OpenCL et CUDA, l’étage de parallélisation <em>Threads</em> est l’étage le plus fin, destiné à paralléliser des exécutions éponymes de la programmation parallèle. Mais, comme dans leurs implémentations sur processeurs, la parallélisation par <em>Threads</em> exige une « synchronisation ». Sous les implémentations CUDA et OpenCL, le nombre de <em>threads</em> maximal sollicitable dans un appel est seulement 1024 !</p>
<p>Cette limitation de 1024 <em>Threads</em> entre en contradiction avec le cadre d’utilisation présenté sur les GPU qui veut que le nombre de tâches équivalentes à exécuter est de l’ordre d’au moins plusieurs dizaines de milliers. Donc, il ne faut pas, dans un premier temps, exploiter les <em>Threads</em> en CUDA mais les <em>Blocks</em>.</p>
<p>Il faudra donc modifier le programme <code class="docutils literal notranslate"><span class="pre">MySteps_4.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MySteps_3.py</span></code> fonctionnel mais inefficace) pour exploiter les <em>Blocks</em>. Les modifications sont les suivantes :</p>
<ul class="simple">
<li><p>remplacer <code class="docutils literal notranslate"><span class="pre">threadIdx</span></code> par <code class="docutils literal notranslate"><span class="pre">blockIdx</span></code> dans le noyau CUDA</p></li>
<li><p>remplacer dans l’appel de <code class="docutils literal notranslate"><span class="pre">sum</span></code> : <code class="docutils literal notranslate"><span class="pre">block=(a_np.size,1,1)</span></code> par <code class="docutils literal notranslate"><span class="pre">block=(1,1,1)</span></code></p></li>
<li><p>remplacer dans l’appel de <code class="docutils literal notranslate"><span class="pre">sum</span></code> : <code class="docutils literal notranslate"><span class="pre">grid=(1,1)</span></code> par <code class="docutils literal notranslate"><span class="pre">grid=(a_np.size)</span></code></p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #3.2 :</strong></p>
<ul class="simple">
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_4.py</span></code> suivant les 3 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>32768</strong> à <strong>268435456</strong></p></li>
<li><p>Analysez dans quelles situations des problèmes de produisent</p></li>
<li><p>Raccordez ces difficultés aux spécifications matérielles</p></li>
<li><p>Complétez un tableau avec ces résultats</p></li>
<li><p>Concluez sur l’efficacité de CUDA dans ce cas d’exploitation</p></li>
</ul>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32768</p></td>
<td><p>910191744</p></td>
<td><p>93081</p></td>
<td><p>31182</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1150116765</p></td>
<td><p>199750</p></td>
<td><p>71033</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1221679586</p></td>
<td><p>455109</p></td>
<td><p>165674</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1337605386</p></td>
<td><p>793248</p></td>
<td><p>280624</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1397980454</p></td>
<td><p>1572131</p></td>
<td><p>570096</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1069824011</p></td>
<td><p>3060792</p></td>
<td><p>1116513</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>775327723</p></td>
<td><p>5831761</p></td>
<td><p>2246784</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>517143454</p></td>
<td><p>11881835</p></td>
<td><p>4384631</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>642015438</p></td>
<td><p>24217467</p></td>
<td><p>8813252</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>629968524</p></td>
<td><p>39845498</p></td>
<td><p>17001502</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>645555196</p></td>
<td><p>57715607</p></td>
<td><p>29982747</p></td>
</tr>
<tr class="row-odd"><td><p>67108864</p></td>
<td><p>650246900</p></td>
<td><p>80830493</p></td>
<td><p>50612097</p></td>
</tr>
<tr class="row-even"><td><p>134217728</p></td>
<td><p>654420232</p></td>
<td><p>99003136</p></td>
<td><p>75783432</p></td>
</tr>
<tr class="row-odd"><td><p>268435456</p></td>
<td><p>656531263</p></td>
<td><p>111858992</p></td>
<td><p>91297615</p></td>
</tr>
</tbody>
</table>
<p>Nous constatons normalement, avec la sollicitation des <em>blocks</em> et plus des <em>threads</em>, l’implémentation CUDA fonctionne quelle que soit la taille sollicitée. L’implémentation CUDA rattrape l’OpenCL sans jamais la dépasser mais elle reste indigente en comparaison avec la méthode native, mais nous avons déjà vu pourquoi : problème de <em>complexité arithmétique</em>.</p>
<p>Nous allons donc, comme pour OpenCL, augmenter l’intensité arithmétique du traitement en rajoutant l’implémentation CUDA de notre fonction <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> ajoutée à chacun des termes des vecteurs avant leur addition.</p>
<p>Pour il convient de modifier le code <code class="docutils literal notranslate"><span class="pre">MySteps_5.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MySteps_4.py</span></code>) de la manière suivante :</p>
<ul>
<li><p>copier l’implémentation PyCUDA <code class="docutils literal notranslate"><span class="pre">CUDAAddition</span></code> en <code class="docutils literal notranslate"><span class="pre">CUDASillyAddition</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>cette nouvelle fonction Python sera à modifier pour la suite</p></li>
</ul>
</div></blockquote>
</li>
<li><p>rajouter la fonction interne <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code> dans le noyau CUDA</p>
<blockquote>
<div><ul class="simple">
<li><p>une fonction interne doit être préfixée par <code class="docutils literal notranslate"><span class="pre">__device__</span></code></p></li>
</ul>
</div></blockquote>
</li>
<li><p>rajouter la fonction <code class="docutils literal notranslate"><span class="pre">sillysum</span></code> appelée par Python dans le noyau CUDA</p></li>
<li><p>rajouter la synthèse de la fonction <code class="docutils literal notranslate"><span class="pre">sillysum</span></code> comparable à <code class="docutils literal notranslate"><span class="pre">sum</span></code></p></li>
<li><p>modifier l’appel de la fonction PyCUDA de <code class="docutils literal notranslate"><span class="pre">sum</span></code> en <code class="docutils literal notranslate"><span class="pre">sillysum</span></code></p></li>
<li><p>intrumenter temporellement chaque ligne de <code class="docutils literal notranslate"><span class="pre">CUDASillyAddition</span></code></p></li>
<li><p>modifier les appels de fonction <code class="docutils literal notranslate"><span class="pre">Addition</span></code> en <code class="docutils literal notranslate"><span class="pre">SillyAddition</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>pour les 3 implémentations <code class="docutils literal notranslate"><span class="pre">Native</span></code>, <code class="docutils literal notranslate"><span class="pre">OpenCL</span></code> et <code class="docutils literal notranslate"><span class="pre">CUDA</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #3.3 :</strong></p>
<ul class="simple">
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MySteps_5.py</span></code> suivant les 7 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>32768</strong> à <strong>268435456</strong></p></li>
<li><p>Complétez un tableau avec ces résultats</p></li>
<li><p>Concluez sur l’efficacité de CUDA dans ce cas d’exploitation</p></li>
</ul>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NativeRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
<th class="head"><p>OpenCL ratio</p></th>
<th class="head"><p>CUDA ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32768</p></td>
<td><p>1220822</p></td>
<td><p>104351</p></td>
<td><p>29276</p></td>
<td><p>0.085476</p></td>
<td><p>0.023981</p></td>
</tr>
<tr class="row-odd"><td><p>65536</p></td>
<td><p>1220648</p></td>
<td><p>209305</p></td>
<td><p>69271</p></td>
<td><p>0.171470</p></td>
<td><p>0.056749</p></td>
</tr>
<tr class="row-even"><td><p>131072</p></td>
<td><p>1230476</p></td>
<td><p>393187</p></td>
<td><p>140255</p></td>
<td><p>0.319541</p></td>
<td><p>0.113984</p></td>
</tr>
<tr class="row-odd"><td><p>262144</p></td>
<td><p>1248695</p></td>
<td><p>884181</p></td>
<td><p>298047</p></td>
<td><p>0.708084</p></td>
<td><p>0.238687</p></td>
</tr>
<tr class="row-even"><td><p>524288</p></td>
<td><p>1447905</p></td>
<td><p>1790726</p></td>
<td><p>574288</p></td>
<td><p>1.236770</p></td>
<td><p>0.396634</p></td>
</tr>
<tr class="row-odd"><td><p>1048576</p></td>
<td><p>1444680</p></td>
<td><p>3401922</p></td>
<td><p>1118288</p></td>
<td><p>2.354793</p></td>
<td><p>0.774073</p></td>
</tr>
<tr class="row-even"><td><p>2097152</p></td>
<td><p>1484030</p></td>
<td><p>6988430</p></td>
<td><p>2056560</p></td>
<td><p>4.709089</p></td>
<td><p>1.385794</p></td>
</tr>
<tr class="row-odd"><td><p>4194304</p></td>
<td><p>1525560</p></td>
<td><p>13208467</p></td>
<td><p>3606081</p></td>
<td><p>8.658110</p></td>
<td><p>2.363775</p></td>
</tr>
<tr class="row-even"><td><p>8388608</p></td>
<td><p>1478514</p></td>
<td><p>22047721</p></td>
<td><p>5106220</p></td>
<td><p>14.912081</p></td>
<td><p>3.453616</p></td>
</tr>
<tr class="row-odd"><td><p>16777216</p></td>
<td><p>1484119</p></td>
<td><p>37736167</p></td>
<td><p>7228717</p></td>
<td><p>25.426645</p></td>
<td><p>4.870713</p></td>
</tr>
<tr class="row-even"><td><p>33554432</p></td>
<td><p>1484581</p></td>
<td><p>54005921</p></td>
<td><p>9291681</p></td>
<td><p>36.377888</p></td>
<td><p>6.258790</p></td>
</tr>
<tr class="row-odd"><td><p>67108864</p></td>
<td><p>1484264</p></td>
<td><p>75264794</p></td>
<td><p>10552401</p></td>
<td><p>50.708495</p></td>
<td><p>7.109518</p></td>
</tr>
<tr class="row-even"><td><p>134217728</p></td>
<td><p>1486942</p></td>
<td><p>85222066</p></td>
<td><p>11352687</p></td>
<td><p>57.313645</p></td>
<td><p>7.634923</p></td>
</tr>
<tr class="row-odd"><td><p>268435456</p></td>
<td><p>1485632</p></td>
<td><p>102563944</p></td>
<td><p>12149328</p></td>
<td><p>69.037247</p></td>
<td><p>8.177885</p></td>
</tr>
</tbody>
</table>
<p>Les gains sont substantiels en CUDA mais restent quand même bien en dessous de OpenCL. Pour augmenter l’efficacité de CUDA, il conviendra d’augmenter la <em>complexité arithmétique</em> de manière très substantielle. Par exemple, en multipliant par 16 cette complexité (en appelant par exemple 16 fois successivement cette fonction <code class="docutils literal notranslate"><span class="pre">MySillyFunction</span></code>), le <strong>NativeRate</strong> se divise par 16 mais le <strong>OpenCLRate</strong> ne se divise que par 2. L’implémentation CUDA, quand à elle, augmente de 60% !</p>
<p>Pour conclure sue ce petit intermède CUDA se trouvent les programmes <code class="docutils literal notranslate"><span class="pre">MySteps_5b.py</span></code> et <code class="docutils literal notranslate"><span class="pre">MySteps_5c.py</span></code> dérivés de <code class="docutils literal notranslate"><span class="pre">MySteps_5.py</span></code> :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MySteps_5b.py</span></code> : intègre une utilisation hybride des <em>Blocks</em> et des <em>Threads</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MySteps_5c.py</span></code> : augmente la complexité arithmétique d’un facteur 16</p></li>
</ul>
</section>
<section id="implementer-une-fonction-couteuse-la-transformee-de-fourier">
<h2>Implémenter une fonction « coûteuse », la Transformée de Fourier<a class="headerlink" href="#implementer-une-fonction-couteuse-la-transformee-de-fourier" title="Lien vers cette rubrique">¶</a></h2>
<p>L’objectif ici n’est pas de concurrencer une implémentation de la FFT, par ailleurs très bien implémentée en Python natif. Le dessein est plutôt d’illustrer l’exploitation d’un des programmes précédents comme <em>matrice</em> de manière à construire ce programme.</p>
<p>La <a class="reference external" href="https://fr.wikipedia.org/wiki/Transformation_de_Fourier_discr%C3%A8te">Transformée de Fourier discrète</a> est omniprésente en traitement du signal. Elle permet notamment des opérations de filtrage plus efficaces que les convolutions directes.</p>
<p>Le lien <a class="reference external" href="https://fr.wikipedia.org/wiki/Transformation_de_Fourier_discr%C3%A8te">Wikipedia</a> contient tout ce qui est nécessaire à l’implémentation de votre propre TF d’abord en Python « naïf », puis en Python Numpy, ensuite en Python PyOpenCL et enfin en Python CUDA.</p>
<p>Comme le veut la tradition, la DFT s’applique sur un vecteur complexe comprenant donc parties réelle et imaginaire et offre un résultat dans l’espace complexe. Les vecteurs <code class="docutils literal notranslate"><span class="pre">a_np</span></code> et <code class="docutils literal notranslate"><span class="pre">b_np</span></code> seront donc respectivement les parties réelles et imaginaires de notre vecteur d’entrée.</p>
<p>Pour cela, nous partons de <code class="docutils literal notranslate"><span class="pre">MySteps_5.py</span></code> que nous copions en <code class="docutils literal notranslate"><span class="pre">MyDFT_1.py</span></code>. Nous pouvons dans un premier temps commenter toutes les parties que nous ne comptons pas exploiter, ou simplement ne pas les appeler dans la fin du programme.</p>
<p>Pour des valeurs réelles et imaginaires fixées à <strong>1</strong> dans le vecteur complexe, les valeurs théoriques de leur DFT sont :</p>
<ul class="simple">
<li><p>identiques pour les parties réelles et imaginaires</p></li>
<li><p>égales à <strong>1</strong> pour le premier élément</p></li>
<li><p>égales à <strong>0</strong> pour les autres termes</p></li>
</ul>
<p>Ainsi, pour implémenter une DFT « naïve », nous devons :
- commenter toutes les parties inutiles du programme <code class="docutils literal notranslate"><span class="pre">MyDFT_1.py</span></code>
- initialiser les vecteurs <code class="docutils literal notranslate"><span class="pre">a_np</span></code> et <code class="docutils literal notranslate"><span class="pre">b_np</span></code> à <code class="docutils literal notranslate"><span class="pre">1</span></code>
- initialiser les vecteurs <code class="docutils literal notranslate"><span class="pre">C_np</span></code> et <code class="docutils literal notranslate"><span class="pre">D_np</span></code> résultats (ou références)
- créer une fonction Python <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>arguments <code class="docutils literal notranslate"><span class="pre">x</span></code> et <code class="docutils literal notranslate"><span class="pre">y</span></code></p></li>
<li><p>résultats <code class="docutils literal notranslate"><span class="pre">X</span></code> et <code class="docutils literal notranslate"><span class="pre">Y</span></code></p></li>
</ul>
</div></blockquote>
<ul>
<li><p>implémenter la DFT à base d’itérateurs</p></li>
<li><p>appeler la fonction <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code> avec :</p>
<blockquote>
<div><ul class="simple">
<li><p>arguments <code class="docutils literal notranslate"><span class="pre">a_np</span></code> et <code class="docutils literal notranslate"><span class="pre">b_np</span></code></p></li>
<li><p>résultats <code class="docutils literal notranslate"><span class="pre">c_np</span></code> et <code class="docutils literal notranslate"><span class="pre">d_np</span></code></p></li>
</ul>
</div></blockquote>
</li>
<li><p>imprimer la somme des différences normalisées</p>
<blockquote>
<div><ul class="simple">
<li><p>entre <code class="docutils literal notranslate"><span class="pre">c_np</span></code> et <code class="docutils literal notranslate"><span class="pre">C_np</span></code></p></li>
<li><p>entre <code class="docutils literal notranslate"><span class="pre">d_np</span></code> et <code class="docutils literal notranslate"><span class="pre">D_np</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>Il sera alors possible d’estimer l’erreur numérique à ce calcul.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #4.1 : implémentation Python « naïve »</strong></p>
<ul class="simple">
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MyDFT_1.py</span></code> suivant les 7 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour une taille de <strong>16</strong> et contrôler la cohérence</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>16</strong> à <strong>4096</strong></p></li>
<li><p>Placez dans un tableau la performance</p></li>
</ul>
</div>
<p>Si tout va bien, les vecteurs résultats présentent une valeur comparable à la taille du vecteur sur le premier élément et une valeur « proche » de 0 ailleurs. Pour une DFT appliquée sur un vecteur de 1024 éléments, la sortie est la suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1024</span>
NativeRate:<span class="w"> </span><span class="m">23</span>
Precision:<span class="w">  </span><span class="m">6</span>.975449e-05<span class="w"> </span><span class="m">6</span>.9193055e-05
</pre></div>
</div>
<p>La double-itération est particulièrement coûteuse en terme de calcul. La seconde implémentation va exploiter les fonctions <em>broadcast</em> de Numpy pour éviter cette double-boucle en la limitant à une seule boucle.</p>
<p>Pour cela, il est proposé de :</p>
<ul>
<li><p>copier la fonction <code class="docutils literal notranslate"><span class="pre">NumpyDFT</span></code> sur le modèle de <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>dans cette nouvelle fonction, réaliser les opérations suivantes :</p></li>
<li><p>créer un vecteur <code class="docutils literal notranslate"><span class="pre">nj</span></code> correspondant à l’argument des <strong>cos</strong> et <strong>sin</strong> divisé par <strong>i</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>l’exploitation de <code class="docutils literal notranslate"><span class="pre">numpy.multiply</span></code> est suggérée</p></li>
</ul>
</div></blockquote>
</li>
<li><p>créer l’élément <code class="docutils literal notranslate"><span class="pre">X[i]</span></code> par l’enchaînement des opérations :</p>
<blockquote>
<div><ul class="simple">
<li><p>produit de <strong>cos(i*nj)</strong> à <strong>x</strong></p></li>
<li><p>produit de <strong>sin(i*nj)</strong> à <strong>x</strong></p></li>
<li><p>soustraction des deux résultats précédents</p></li>
<li><p>somme de l’ensemble des éléments</p></li>
</ul>
</div></blockquote>
</li>
<li><p>créer l’élément <code class="docutils literal notranslate"><span class="pre">Y[i]</span></code> par l’enchaînement des opérations :</p>
<blockquote>
<div><ul class="simple">
<li><p>produit de <strong>sin(i*nj)</strong> à <strong>x</strong></p></li>
<li><p>produit de <strong>cos(i*nj)</strong> à <strong>x</strong></p></li>
<li><p>addition des deux résultats précédents</p></li>
<li><p>somme de l’ensemble des éléments</p></li>
</ul>
</div></blockquote>
</li>
<li><p>appeler la fonction <code class="docutils literal notranslate"><span class="pre">NumpyDFT</span></code> avec les mêmes arguments</p></li>
<li><p>comparer les résultats entre les deux avec <code class="docutils literal notranslate"><span class="pre">linalg.norm</span></code></p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #4.2 : implémentation Python Numpy</strong></p>
<ul class="simple">
<li><p>Copiez le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_1.py</span></code> en <code class="docutils literal notranslate"><span class="pre">MyDFT_2.py</span></code></p></li>
<li><p>Modifiez <code class="docutils literal notranslate"><span class="pre">MyDFT_2.py</span></code> suivant les 7 spécifications ci-dessus</p></li>
<li><p>Exécutez le programme pour une taille de <strong>1024</strong> et contrôler la cohérence</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>16</strong> à <strong>4096</strong></p></li>
<li><p>Placez dans un tableau la performance</p></li>
</ul>
</div>
<p>Nous constatons que l’exploitation des fonctions <em>broadcast</em> est infiniment plus efficace que l’implémentation naïve. Cependant, une observation des résultats laisse un tantinet perplexe sur la précision des opération. En effet, pour une exécution sur des vecteurs de tail 1024, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1024</span>
Performing<span class="w"> </span>naive<span class="w"> </span>implementation
NativeRate:<span class="w"> </span><span class="m">23</span>
Precision:<span class="w">  </span><span class="m">6</span>.975449e-05<span class="w"> </span><span class="m">6</span>.9193055e-05
Performing<span class="w"> </span>Numpy<span class="w"> </span>implementation
NumpyRate:<span class="w"> </span><span class="m">8030</span>
Precision:<span class="w">  </span><span class="m">0</span>.08201215<span class="w"> </span><span class="m">0</span>.0809835
</pre></div>
</div>
<p>Les résultats par la méthode naïve semblent être plus précis (attention cependant, nous avons forcé les calculs sur des flottants 32 bits). Cela suggère qu’un contrôle calculatoire est plus que jamais nécessaire, quelle que soit la méthode exploitée, en Python ou autre.</p>
<p>L’utilisation de Numba offre une possibilité de parallélisation comparable à <a class="reference external" href="https://fr.wikipedia.org/wiki/OpenMP">OpenMP</a>. Avec une directive préfixant la fonction et quelques modifications, il est possible (normalement simplement) de paralléliser l’exécution d’une boucle sur plusieurs coeurs voire envoyer l’exécution de la boucle sur un périphérique externe. Nous l’utiliserons que la parallélisation sur plusieurs coeurs.</p>
<p>Dans notre cas, il suffira de :</p>
<ul class="simple">
<li><p>importer la librairie <strong>numba</strong> : <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">numba</span></code></p></li>
<li><p>préciser l’appel du <em>décorateur</em> sur CPU : <code class="docutils literal notranslate"><span class="pre">&#64;numba.njit(parallel=True)</span></code></p></li>
<li><p>changer le domaine d’itération pour la boucle : <code class="docutils literal notranslate"><span class="pre">range()</span></code> par <code class="docutils literal notranslate"><span class="pre">numba.prange()</span></code></p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #4.3 : implémentation Python Numpy</strong></p>
<ul class="simple">
<li><p>Copiez le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_2.py</span></code> en <code class="docutils literal notranslate"><span class="pre">MyDFT_3.py</span></code> et exploitez ce dernier</p></li>
<li><p>Copiez la fonction <code class="docutils literal notranslate"><span class="pre">NumpyDFT</span></code> en <code class="docutils literal notranslate"><span class="pre">NumbaDFT</span></code></p></li>
<li><p>Intégrez les deux lignes intégrant <strong>numba</strong></p></li>
<li><p>Dupliquez l’appel de <code class="docutils literal notranslate"><span class="pre">NumpyDFT</span></code> pour appeler <code class="docutils literal notranslate"><span class="pre">NumbaDFT</span></code></p></li>
<li><p>Rajoutez un comparateur de résultats avec le mode natif</p></li>
<li><p>Exécutez le programme pour une taille de <strong>1024</strong> et contrôler la cohérence</p></li>
<li><p>Exécutez le programme pour des tailles de vecteurs de <strong>16</strong> à <strong>4096</strong></p></li>
<li><p>Placez dans un tableau la performance</p></li>
</ul>
</div>
<p>Les résultats ont de quoi laisser effectivement perplexe… L’implémentation avec Numba semble plus lente que l’implémentation Numpy qu’elle exploite !</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1024</span>
Performing<span class="w"> </span>naive<span class="w"> </span>implementation
NativeRate:<span class="w"> </span><span class="m">22</span>
Precision:<span class="w">  </span><span class="m">6</span>.975449e-05<span class="w"> </span><span class="m">6</span>.9193055e-05
Performing<span class="w"> </span>Numpy<span class="w"> </span>implementation
NumpyRate:<span class="w"> </span><span class="m">8157</span>
Precision:<span class="w">  </span><span class="m">0</span>.08201215<span class="w"> </span><span class="m">0</span>.0809835
Performing<span class="w"> </span>Numba<span class="w"> </span>implementation
/usr/lib/python3/dist-packages/numba/np/ufunc/parallel.py:365:<span class="w"> </span>NumbaWarning:<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>requires<span class="w"> </span>TBB<span class="w"> </span>version<span class="w"> </span><span class="m">2019</span>.5<span class="w"> </span>or<span class="w"> </span>later<span class="w"> </span>i.e.,<span class="w"> </span>TBB_INTERFACE_VERSION<span class="w"> </span>&gt;<span class="o">=</span><span class="w"> </span><span class="m">11005</span>.<span class="w"> </span>Found<span class="w"> </span><span class="nv">TBB_INTERFACE_VERSION</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">7001</span>.<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>is<span class="w"> </span>disabled.
warnings.warn<span class="o">(</span>problem<span class="o">)</span>
NumbaRate:<span class="w"> </span><span class="m">393</span>
Precision:<span class="w">  </span><span class="m">0</span>.065024495<span class="w"> </span><span class="m">0</span>.059959255
</pre></div>
</div>
<p>Nous disposons également d’un message d’erreur mais pas vraiment grave… Ca fonctionne quand même ;-)</p>
<p>Pour l’implémentation OpenCL, la version « naïve » de l’implémentation va servir. Pour cela, il suffit de reprendre la définition de la méthode naïve et de l’implémenter en C dans un noyau OpenCL. A noter que Pi n’étant dans une variable définie, il faut explicitement la détailler dans le noyau OpenCL. Autre détail important : le <em>cast</em>. De manière a éviter tout effet de bord, il est fortement recommandé de <em>caster</em> les opérations dans la précision flottante souhaitée pour des opérations sur des indices entiers.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #4.4 : implémentation Python OpenCL</strong></p>
<ul class="simple">
<li><p>Copiez le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_3.py</span></code> en <code class="docutils literal notranslate"><span class="pre">MyDFT_4.py</span></code> et exploitez ce dernier</p></li>
<li><p>Copiez la fonction python <code class="docutils literal notranslate"><span class="pre">OpenCLAddition</span></code> en <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code></p></li>
<li><p>Sur la base de la fonction noyau <code class="docutils literal notranslate"><span class="pre">sum</span></code>, créer la fonction <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Intégrez la valeur de PI en début de noyau OpenCL</p></li>
<li><p>Modifiez les allocations pour la sortie de la fontion OpenCL <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Modifiez la synthèse du noyau OpenCL</p></li>
<li><p>Modifiez l’exécution du noyau OpenCL avec <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Adaptez les transferts de périphérique vers l’hôte</p></li>
<li><p>Appelez la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code> dans la routine</p></li>
<li><p>Inhibez l’implémentation « naïve » trop inefficace</p></li>
<li><p>Exécutez le programme pour une taille de <strong>1024</strong> et contrôler la cohérence</p></li>
<li><p>Exécutez le programme sur CPU pour des tailles de vecteurs de <strong>64</strong> à <strong>65536</strong></p></li>
<li><p>Exécutez le programme sur GPU pour des tailles de vecteurs de <strong>64</strong> à <strong>65536</strong></p></li>
<li><p>Placez dans un tableau la performance</p></li>
</ul>
</div>
<p>Sur la base d’une DFT appliquée sur un vecteur complexe de 1024 éléments avec comme périphérique OpenCL l’implémentation Intel, nous avons la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1024</span>
Performing<span class="w"> </span>Numpy<span class="w"> </span>implementation
NumpyRate:<span class="w"> </span><span class="m">6282</span>
Precision:<span class="w">  </span><span class="m">0</span>.08201215<span class="w"> </span><span class="m">0</span>.0809835
Performing<span class="w"> </span>Numba<span class="w"> </span>implementation
/usr/lib/python3/dist-packages/numba/np/ufunc/parallel.py:365:<span class="w"> </span>NumbaWarning:<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>requires<span class="w"> </span>TBB<span class="w"> </span>version<span class="w"> </span><span class="m">2019</span>.5<span class="w"> </span>or<span class="w"> </span>later<span class="w"> </span>i.e.,<span class="w"> </span>TBB_INTERFACE_VERSION<span class="w"> </span>&gt;<span class="o">=</span><span class="w"> </span><span class="m">11005</span>.<span class="w"> </span>Found<span class="w"> </span><span class="nv">TBB_INTERFACE_VERSION</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">7001</span>.<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>is<span class="w"> </span>disabled.
<span class="w">  </span>warnings.warn<span class="o">(</span>problem<span class="o">)</span>
NumbaRate:<span class="w"> </span><span class="m">356</span>
Precision:<span class="w">  </span><span class="m">0</span>.065024495<span class="w"> </span><span class="m">0</span>.059959255
Copy<span class="w"> </span>from<span class="w"> </span>Host<span class="w"> </span><span class="m">2</span><span class="w"> </span>Device<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Building<span class="w"> </span>kernels<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.013
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Device<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.005
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.007
Copy<span class="w"> </span>from<span class="w"> </span>Device<span class="w"> </span><span class="m">2</span><span class="w"> </span>Host<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
OpenCLRate:<span class="w"> </span><span class="m">3306</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
</pre></div>
</div>
<p>La précision en OpenCL est comparable à la méthode native, bien meilleure que les méthodes Python Numpy ou Numba. La performance est en deça de la méthode Numpy. Par contre, dès que les vecteurs dépassent une certaine taille (8192 avec Numba et 2048 avec OpenCL), Numpy est largement battu.</p>
<p>Avec l’implémentation OpenCL Intel sur CPU :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>64</p></td>
<td><p>15225</p></td>
<td><p>24</p></td>
<td><p>186</p></td>
</tr>
<tr class="row-odd"><td><p>128</p></td>
<td><p>17045</p></td>
<td><p>55</p></td>
<td><p>477</p></td>
</tr>
<tr class="row-even"><td><p>256</p></td>
<td><p>14199</p></td>
<td><p>112</p></td>
<td><p>926</p></td>
</tr>
<tr class="row-odd"><td><p>512</p></td>
<td><p>8361</p></td>
<td><p>218</p></td>
<td><p>1820</p></td>
</tr>
<tr class="row-even"><td><p>1024</p></td>
<td><p>7980</p></td>
<td><p>440</p></td>
<td><p>1550</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>4308</p></td>
<td><p>865</p></td>
<td><p>7945</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>2894</p></td>
<td><p>1626</p></td>
<td><p>12810</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>1584</p></td>
<td><p>2565</p></td>
<td><p>18533</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>852</p></td>
<td><p>2223</p></td>
<td><p>22087</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>435</p></td>
<td><p>2143</p></td>
<td><p>16604</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>221</p></td>
<td><p>1212</p></td>
<td><p>9497</p></td>
</tr>
</tbody>
</table>
<p>Avec l’implémentation OpenCL sur GPU :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>64</p></td>
<td><p>15117</p></td>
<td><p>25</p></td>
<td><p>204</p></td>
</tr>
<tr class="row-odd"><td><p>128</p></td>
<td><p>14398</p></td>
<td><p>54</p></td>
<td><p>463</p></td>
</tr>
<tr class="row-even"><td><p>256</p></td>
<td><p>15201</p></td>
<td><p>111</p></td>
<td><p>948</p></td>
</tr>
<tr class="row-odd"><td><p>512</p></td>
<td><p>8860</p></td>
<td><p>201</p></td>
<td><p>1866</p></td>
</tr>
<tr class="row-even"><td><p>1024</p></td>
<td><p>8061</p></td>
<td><p>441</p></td>
<td><p>3786</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>4605</p></td>
<td><p>874</p></td>
<td><p>5968</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>2892</p></td>
<td><p>1628</p></td>
<td><p>12852</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>1617</p></td>
<td><p>2636</p></td>
<td><p>19731</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>848</p></td>
<td><p>2884</p></td>
<td><p>24280</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>433</p></td>
<td><p>2032</p></td>
<td><p>20077</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>220</p></td>
<td><p>1217</p></td>
<td><p>11054</p></td>
</tr>
</tbody>
</table>
<p>Reste maintenant l’implémentation CUDA sur la base de ce qui a déjà été fait dans l’exercice 3.4.</p>
<p>Il faudra, comme pour l’implémentation OpenCL, veiller à :</p>
<ul class="simple">
<li><p>intégrer la valeur de PI comme constante</p></li>
<li><p>modifier les vecteurs en sortie (2 vecteurs)</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #4.5 : implémentation Python CUDA</strong></p>
<ul class="simple">
<li><p>Copiez le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_4.py</span></code> en <code class="docutils literal notranslate"><span class="pre">MyDFT_5.py</span></code> et exploitez ce dernier</p></li>
<li><p>Copiez la fonction python <code class="docutils literal notranslate"><span class="pre">CUDAAddition</span></code> en <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code></p></li>
<li><p>Sur la base de la fonction noyau <code class="docutils literal notranslate"><span class="pre">sum</span></code>, créer la fonction <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Intégrez la valeur de PI en début de noyau OpenCL</p></li>
<li><p>Modifiez les allocations pour la sortie de la fontion CUDA <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Modifiez la synthèse du noyau CUDA</p></li>
<li><p>Modifiez l’exécution du noyau CUDA avec <code class="docutils literal notranslate"><span class="pre">MyDFT</span></code></p></li>
<li><p>Appelez la fonction <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code> dans la routine</p></li>
<li><p>Exécutez le programme pour une taille de <strong>1024</strong> et contrôler la cohérence</p></li>
<li><p>Exécutez le programme sur GPU pour des tailles de vecteurs de <strong>64</strong> à <strong>65536</strong></p></li>
<li><p>Placez dans un tableau la performance</p></li>
</ul>
</div>
<p>Pour l’exécution de la DFT sur vecteur complexe de 1024 éléments sur GPU, nous avons comme sortie :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Size<span class="w"> </span>of<span class="w"> </span>vectors<span class="w"> </span><span class="nb">set</span><span class="w"> </span>to<span class="w"> </span><span class="m">1024</span>
Performing<span class="w"> </span>Numpy<span class="w"> </span>implementation
NumpyRate:<span class="w"> </span><span class="m">6344</span>
Precision:<span class="w">  </span><span class="m">0</span>.08201215<span class="w"> </span><span class="m">0</span>.0809835
Performing<span class="w"> </span>Numba<span class="w"> </span>implementation
/usr/lib/python3/dist-packages/numba/np/ufunc/parallel.py:365:<span class="w"> </span>NumbaWarning:<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>requires<span class="w"> </span>TBB<span class="w"> </span>version<span class="w"> </span><span class="m">2019</span>.5<span class="w"> </span>or<span class="w"> </span>later<span class="w"> </span>i.e.,<span class="w"> </span>TBB_INTERFACE_VERSION<span class="w"> </span>&gt;<span class="o">=</span><span class="w"> </span><span class="m">11005</span>.<span class="w"> </span>Found<span class="w"> </span><span class="nv">TBB_INTERFACE_VERSION</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">7001</span>.<span class="w"> </span>The<span class="w"> </span>TBB<span class="w"> </span>threading<span class="w"> </span>layer<span class="w"> </span>is<span class="w"> </span>disabled.
<span class="w">  </span>warnings.warn<span class="o">(</span>problem<span class="o">)</span>
NumbaRate:<span class="w"> </span><span class="m">416</span>
Precision:<span class="w">  </span><span class="m">0</span>.065024495<span class="w"> </span><span class="m">0</span>.059959255
Copy<span class="w"> </span>from<span class="w"> </span>Host<span class="w"> </span><span class="m">2</span><span class="w"> </span>Device<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Building<span class="w"> </span>kernels<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.010
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Device<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.003
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.007
Copy<span class="w"> </span>from<span class="w"> </span>Device<span class="w"> </span><span class="m">2</span><span class="w"> </span>Host<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
OpenCLRate:<span class="w"> </span><span class="m">3486</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
Definition<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.018
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.044
CUDARate:<span class="w"> </span><span class="m">6629</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
</pre></div>
</div>
<p>Nous constatons que le l’efficacité de CUDA est presque double de celle OpenCL.</p>
<p>Voyons si cette performance se confirme pour toutes les tailles de vecteurs.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>64</p></td>
<td><p>15297</p></td>
<td><p>25</p></td>
<td><p>201</p></td>
<td><p>556</p></td>
</tr>
<tr class="row-odd"><td><p>128</p></td>
<td><p>13792</p></td>
<td><p>51</p></td>
<td><p>466</p></td>
<td><p>1169</p></td>
</tr>
<tr class="row-even"><td><p>256</p></td>
<td><p>14692</p></td>
<td><p>112</p></td>
<td><p>926</p></td>
<td><p>2297</p></td>
</tr>
<tr class="row-odd"><td><p>512</p></td>
<td><p>8837</p></td>
<td><p>210</p></td>
<td><p>1812</p></td>
<td><p>4248</p></td>
</tr>
<tr class="row-even"><td><p>1024</p></td>
<td><p>7335</p></td>
<td><p>431</p></td>
<td><p>3574</p></td>
<td><p>6653</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>4592</p></td>
<td><p>865</p></td>
<td><p>7214</p></td>
<td><p>7368</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>2753</p></td>
<td><p>1623</p></td>
<td><p>13253</p></td>
<td><p>6019</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>1627</p></td>
<td><p>2577</p></td>
<td><p>21140</p></td>
<td><p>3538</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>852</p></td>
<td><p>2829</p></td>
<td><p>24491</p></td>
<td><p>1835</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>430</p></td>
<td><p>2135</p></td>
<td><p>11410</p></td>
<td><p>929</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>221</p></td>
<td><p>1215</p></td>
<td><p>11048</p></td>
<td><p>466</p></td>
</tr>
</tbody>
</table>
<p>Nous constatons que CUDA monte plus rapidement <em>en charge</em> que OpenCL lorsque la taille du problème augmente. Cependant, CUDA attend une limite pour une taille de 2048 puis régresse drastiquement ensuite alors que OpenCL sa progression jusqu’à une taille de 16384.</p>
<p>Pour CUDA, cela montre que nous sommes arrivés à saturation de l’exploitation du premier étage de parallélisme avec les <em>blocks</em> : il faut maintenant exploiter les <em>threads</em> de manière concomitante. L’exemple <code class="docutils literal notranslate"><span class="pre">MyDFT_5b.py</span></code> illustre cette exploitation hybride. Les résultats pour une exploitation de <strong>1024</strong> <em>threads</em> (donc une taille de vecteur complexe de 1024) parlent d’eux-mêmes :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1024</p></td>
<td><p>6387</p></td>
<td><p>422</p></td>
<td><p>3239</p></td>
<td><p>7480</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>4707</p></td>
<td><p>877</p></td>
<td><p>7206</p></td>
<td><p>14011</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>2968</p></td>
<td><p>1627</p></td>
<td><p>12147</p></td>
<td><p>22127</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>1610</p></td>
<td><p>2620</p></td>
<td><p>19829</p></td>
<td><p>33377</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>849</p></td>
<td><p>2888</p></td>
<td><p>25233</p></td>
<td><p>27880</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>434</p></td>
<td><p>2106</p></td>
<td><p>18805</p></td>
<td><p>21061</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>221</p></td>
<td><p>1214</p></td>
<td><p>11162</p></td>
<td><p>13446</p></td>
</tr>
</tbody>
</table>
<p>Dans ce cas, CUDA est toujours plus performant que OpenCL mais la contrainte reste de pouvoir exploiter efficacement ces deux étages de parallélisme. Cette différence d’efficacité n’est pas systématique : nous réalisons d’abord qu’elle dépend du système considéré mais cela va également complètement dépendre de l’architecture interne de la GPU, donc sa génération, son nombre de coeurs CUDA, sa mémoire, etc…</p>
<p>L’exemple précédent était exécuté sur une <strong>GTX Titan</strong> avec circuit Kepler datant de 2013.</p>
<p>Sur une RTX 6000, la domination de Python/CUDA est plus nuancée :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1024</p></td>
<td><p>31353</p></td>
<td><p>823</p></td>
<td><p>3999</p></td>
<td><p>7795</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>26627</p></td>
<td><p>1735</p></td>
<td><p>8738</p></td>
<td><p>13045</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>27098</p></td>
<td><p>3298</p></td>
<td><p>15042</p></td>
<td><p>18896</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>17416</p></td>
<td><p>5619</p></td>
<td><p>25359</p></td>
<td><p>25075</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>9047</p></td>
<td><p>6585</p></td>
<td><p>40884</p></td>
<td><p>29655</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>2414</p></td>
<td><p>5832</p></td>
<td><p>37860</p></td>
<td><p>32461</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>838</p></td>
<td><p>3540</p></td>
<td><p>24963</p></td>
<td><p>33812</p></td>
</tr>
</tbody>
</table>
<p>Quant à l’exploitation d’une carte professionnelle A100, les différences sont marquantes !</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Size</p></th>
<th class="head"><p>NumpyRate</p></th>
<th class="head"><p>NumbaRate</p></th>
<th class="head"><p>OpenCL Rate</p></th>
<th class="head"><p>CUDA Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1024</p></td>
<td><p>37922</p></td>
<td><p>772</p></td>
<td><p>2042</p></td>
<td><p>1663</p></td>
</tr>
<tr class="row-odd"><td><p>2048</p></td>
<td><p>35043</p></td>
<td><p>1743</p></td>
<td><p>6758</p></td>
<td><p>13978</p></td>
</tr>
<tr class="row-even"><td><p>4096</p></td>
<td><p>25283</p></td>
<td><p>3385</p></td>
<td><p>13559</p></td>
<td><p>25791</p></td>
</tr>
<tr class="row-odd"><td><p>8192</p></td>
<td><p>14887</p></td>
<td><p>6171</p></td>
<td><p>25565</p></td>
<td><p>47268</p></td>
</tr>
<tr class="row-even"><td><p>16384</p></td>
<td><p>8440</p></td>
<td><p>9097</p></td>
<td><p>48969</p></td>
<td><p>76644</p></td>
</tr>
<tr class="row-odd"><td><p>32768</p></td>
<td><p>2562</p></td>
<td><p>9036</p></td>
<td><p>85271</p></td>
<td><p>117726</p></td>
</tr>
<tr class="row-even"><td><p>65536</p></td>
<td><p>715</p></td>
<td><p>6252</p></td>
<td><p>117873</p></td>
<td><p>179320</p></td>
</tr>
</tbody>
</table>
<p>En conclusion de cette partie, une approche progressive qui consiste de partir d’abord d’une implémentation « naïve » agnostique à tout langage, puis d’exploiter les spécificités des uns ou des autres (comme les <em>broadcast</em> Numpy ou la parallélisation par Numba), ensuite de construire avec Python/OpenCL un modèle qui s’exécutera partout (sur CPU ou GPU), enfin construire avec un Python/CUDA si le problème s’y prête, est une approche pertinente. A chaque étape, il est possible de s’arrêter si la performance est en accord avec son <em>budget</em> de développement.</p>
</section>
<section id="le-choix-du-peripherique-en-opencl-et-cuda">
<h2>Le choix du périphérique en OpenCL et CUDA<a class="headerlink" href="#le-choix-du-peripherique-en-opencl-et-cuda" title="Lien vers cette rubrique">¶</a></h2>
<p>Dans le chapitre 1, nous avons vu qu’il était possible de choisir le périphérique CUDA en <em>inhibant</em> sa visibilité avec la variable d’environnement <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>. Seul le ou les périphériques sélectionnés étaient visibles. Cette méthode est cependant un peu brutale, surtout si nous souhaitons adresser plusieurs GPU dans notre exécution.</p>
<p>Dans le chapitre 2, nous avons vu que pour éviter d’avoir à spécifier le périphérique OpenCL, nous pouvions exploiter la variable d’environnement <code class="docutils literal notranslate"><span class="pre">PYOPENCL_CTX</span></code>. C’était effectivement utile mais nous n’avions pas l’assurance d’exécuter <em>réellement</em> sur ce périphérique sauf en regardant attentitivement les résultats des commandes <code class="docutils literal notranslate"><span class="pre">htop</span></code> ou <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">dmon</span></code>”.</p>
<p>Les méthodes présentées dans la suite ont l’avantage d’être systématiques et donc pourront être exploitées dans n’importe quel programme PyOpenCL pour PyCUDA.</p>
<p>A cela s’ajoute également la possibilité d’ajouter des options au lancement du programme, notamment pour spécifier sa GPU. Dans les programmes de l’archive <strong>bench4gpu</strong> en Python, la majorité dispose d’une option <code class="docutils literal notranslate"><span class="pre">-h</span></code> permettant de voir les options ainsi que de lister les périphériques OpenCL ou CUDA détectés.</p>
<p>L’objectif est donc de reprendre notre exemple le plus abouti de notre DFT et d’y ajouter ces éléments. Pour cela, les programmes <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code> et <code class="docutils literal notranslate"><span class="pre">TrouNoir.py</span></code> vont être explorés pour voir comment faire.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #5.1 : exploration de PiXPU.py</strong></p>
<ul class="simple">
<li><p>Identifiez les lignes correspondant aux paramétrages par défaut</p></li>
<li><p>Identifiez les lignes sur la découverte des périphériques OpenCL</p></li>
<li><p>Identifiez les lignes sur la découverte des périphériques CUDA</p></li>
<li><p>Identifiez les lignes de l’extraction des arguments d’entrées</p></li>
<li><p>Identifiez les lignes de selection du périphérique OpenCL à l’exécution</p></li>
<li><p>Identifiez les lignes de selection du périphérique CUDA à l’exécution</p></li>
</ul>
</div>
<p>Une fois ces portions identifiées, la modification du programme <code class="docutils literal notranslate"><span class="pre">MyDFT_6.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MyDFT_5.py</span></code>) portera les éléments suivants :</p>
<ul class="simple">
<li><p>Intégrer l’option <code class="docutils literal notranslate"><span class="pre">--h</span></code> avec la présentation des périphériques <strong>OpenCL</strong> et <strong>CUDA</strong></p></li>
<li><p>Fixer à 1024 la valeur par défaut du nombre de points</p></li>
<li><p>Fixer à OpenCL la méthode par défaut d’exécution</p></li>
<li><p>Fixer à 0 le premier périphérique OpenCL ou CUDA sollicité</p></li>
<li><p>Sélectionner le nombre de points avec l’option <code class="docutils literal notranslate"><span class="pre">-s</span></code></p></li>
<li><p>Sélectionner le périphérique OpenCL ou CUDA (énumération directe) avec <code class="docutils literal notranslate"><span class="pre">-d</span></code></p></li>
<li><p>Sélectionner une exécution sous OpenCL ou CUDA avec l’option <code class="docutils literal notranslate"><span class="pre">-g</span></code></p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #5.2 : modification du programme `MyDFT_6.py`</strong></p>
<ul class="simple">
<li><p>Supprimer la sélection initiale d’argument</p></li>
<li><p>Inhiber pour l’instant l’exécution des fonctions</p></li>
<li><p>Intégrez les 7 spécifications ci-dessus par de judicieux <em>copier/coller</em> de <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code></p></li>
<li><p>Vérifiez l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code></p></li>
</ul>
</div>
<p>Ainsi, pour une sollification avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code>, le programme sort :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./MySteps_6.py<span class="w"> </span>-g<span class="w"> </span>&lt;CUDA/OpenCL&gt;<span class="w"> </span>-s<span class="w"> </span>&lt;SizeOfVector&gt;<span class="w"> </span>-d<span class="w"> </span>&lt;DeviceId&gt;

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>OpenCL<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 from NVIDIA Corporation of type xPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#2 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#3 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>CUDA<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 of type GPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 of type GPU : Quadro K420</span>
</pre></div>
</div>
<p>Maintenant, sur la base de l’exploration de <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code>, il est temps de modifier les appels aux fonctions <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code> et <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code> dans le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_7.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MyDFT_6.py</span></code>)</p>
<p>En regardant en détail la sélection du périphérique, elle est assez simple du moment que l’énumération des périphériques est réalisée. D’abord sur les plates-formes, ensuite sur les périphériques, avec une indentation jusqu’à trouver <em>son</em> périphérique.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">Id</span><span class="o">=</span><span class="m">0</span>
<span class="nv">HasXPU</span><span class="o">=</span>False
<span class="k">for</span><span class="w"> </span>platform<span class="w"> </span><span class="k">in</span><span class="w"> </span>cl.get_platforms<span class="o">()</span>:
<span class="w">    </span><span class="k">for</span><span class="w"> </span>device<span class="w"> </span><span class="k">in</span><span class="w"> </span>platform.get_devices<span class="o">()</span>:
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">Id</span><span class="o">==</span>Device:
<span class="w">            </span><span class="nv">XPU</span><span class="o">=</span>device
<span class="w">            </span>print<span class="o">(</span><span class="s2">&quot;CPU/GPU selected: &quot;</span>,device.name.lstrip<span class="o">())</span>
<span class="w">            </span><span class="nv">HasXPU</span><span class="o">=</span>True
<span class="w">        </span><span class="nv">Id</span><span class="o">+=</span><span class="m">1</span>
<span class="w">        </span><span class="c1"># print(Id)</span>

<span class="k">if</span><span class="w"> </span><span class="nv">HasXPU</span><span class="o">==</span>False:
<span class="w">    </span>print<span class="o">(</span><span class="s2">&quot;No XPU #%i found in all of %i devices, sorry...&quot;</span><span class="w"> </span>%<span class="w"> </span><span class="o">(</span>Device,Id-1<span class="o">))</span>
<span class="w">    </span>sys.exit<span class="o">()</span>
</pre></div>
</div>
<div class="note note-warning docutils container">
<p><strong>Exercice #5.3 : modification du programme `MyDFT_7.py`</strong></p>
<ul class="simple">
<li><p>Libérez pour l’appel à la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code></p></li>
<li><p>Rajoutez le test exploitant la sélection OpenCL ou CUDA</p></li>
<li><p>Modifiez l’appel de <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code> pour intégrer le choix du périphérique</p></li>
<li><p>Modifiez la fonction <code class="docutils literal notranslate"><span class="pre">OpenCLDFT</span></code> sur la base de fonction <code class="docutils literal notranslate"><span class="pre">MetropolisOpenCL</span></code> de <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code></p></li>
<li><p>Exécutez le programme par défaut (sans option)</p></li>
<li><p>Exécutez le programme sur la seconde GPU</p></li>
</ul>
</div>
<p>Par défaut, la taille du vecteur complexe est 1024, le périphérique sollicité est 0 pour une utilisation en OpenCL. La sortie sur la machine ressemble à :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Device<span class="w"> </span>Selection<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>OpenCL
Size<span class="w"> </span>of<span class="w"> </span>complex<span class="w"> </span>vector<span class="w"> </span>:<span class="w"> </span><span class="m">1024</span>
Device<span class="w"> </span><span class="c1">#0 from NVIDIA Corporation of type xPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#2 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#3 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
CPU/GPU<span class="w"> </span>selected:<span class="w">  </span>NVIDIA<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span>TITAN
Copy<span class="w"> </span>from<span class="w"> </span>Host<span class="w"> </span><span class="m">2</span><span class="w"> </span>Device<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Building<span class="w"> </span>kernels<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.014
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Device<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.006
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.007
Copy<span class="w"> </span>from<span class="w"> </span>Device<span class="w"> </span><span class="m">2</span><span class="w"> </span>Host<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
OpenCLRate:<span class="w"> </span><span class="m">5123</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
</pre></div>
</div>
<p>Pour une sollicitation de la seconde GPU, la performance est moindre et c’est normal. La GPU <strong>Quadro K420</strong> est très inférieure en performance à la <strong>GTX Titan</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Device<span class="w"> </span>Selection<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>OpenCL
Size<span class="w"> </span>of<span class="w"> </span>complex<span class="w"> </span>vector<span class="w"> </span>:<span class="w"> </span><span class="m">1024</span>
Device<span class="w"> </span><span class="c1">#0 from NVIDIA Corporation of type xPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#2 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#3 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz</span>
CPU/GPU<span class="w"> </span>selected:<span class="w">  </span>Quadro<span class="w"> </span>K420
Copy<span class="w"> </span>from<span class="w"> </span>Host<span class="w"> </span><span class="m">2</span><span class="w"> </span>Device<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Building<span class="w"> </span>kernels<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.566
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Device<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.007
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.019
Copy<span class="w"> </span>from<span class="w"> </span>Device<span class="w"> </span><span class="m">2</span><span class="w"> </span>Host<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
OpenCLRate:<span class="w"> </span><span class="m">1450</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
</pre></div>
</div>
<p>Maintenant, passons à la sélection du périphérique CUDA. Dans l’analuse de <code class="docutils literal notranslate"><span class="pre">MetropolisCUDA</span></code> de <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code>, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>try:
<span class="w">    </span><span class="c1"># For PyCUDA import</span>
<span class="w">    </span>import<span class="w"> </span>pycuda.driver<span class="w"> </span>as<span class="w"> </span>cuda
<span class="w">    </span>from<span class="w"> </span>pycuda.compiler<span class="w"> </span>import<span class="w"> </span>SourceModule

<span class="w">    </span>cuda.init<span class="o">()</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span>Id<span class="w"> </span><span class="k">in</span><span class="w"> </span>range<span class="o">(</span>cuda.Device.count<span class="o">())</span>:
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">Id</span><span class="o">==</span>Device:
<span class="w">            </span><span class="nv">XPU</span><span class="o">=</span>cuda.Device<span class="o">(</span>Id<span class="o">)</span>
<span class="w">            </span>print<span class="o">(</span><span class="s2">&quot;GPU selected %s&quot;</span><span class="w"> </span>%<span class="w"> </span>XPU.name<span class="o">())</span>
<span class="w">    </span>print

except<span class="w"> </span>ImportError:
<span class="w">    </span>print<span class="o">(</span><span class="s2">&quot;Platform does not seem to support CUDA&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p>Nous allons effectuer ces opérations sur <code class="docutils literal notranslate"><span class="pre">MyDFT_8.py</span></code> (copie de <code class="docutils literal notranslate"><span class="pre">MyDFT7.py</span></code>).</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #5.4 : modification du programme MyDFT_8.py</strong></p>
<ul class="simple">
<li><p>Libérez pour l’appel à la fonction <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code></p></li>
<li><p>Rajoutez le test exploitant la sélection OpenCL ou CUDA</p></li>
<li><p>Modifiez l’appel de <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code> pour intégrer le choix du périphérique</p></li>
<li><p>Modifiez la fonction <code class="docutils literal notranslate"><span class="pre">CUDADFT</span></code> sur la base de la fonction <code class="docutils literal notranslate"><span class="pre">MetropolisCUDA</span></code> dans <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code></p>
<ul>
<li><p>supprimer l’import <code class="docutils literal notranslate"><span class="pre">pycuda.autoinit</span></code></p></li>
<li><p>rajouter la ligne <code class="docutils literal notranslate"><span class="pre">Context=XPU.make_context()</span></code> après le <em>parse</em> des périphériques</p></li>
<li><p>rajouter la ligne <code class="docutils literal notranslate"><span class="pre">Context.pop()</span></code> pour inactiver le contexte à la fin de la fonction</p></li>
<li><p>rajouter la ligne <code class="docutils literal notranslate"><span class="pre">Context.detach()</span></code> ensuite</p></li>
</ul>
</li>
<li><p>Exécutez le programme avec l’option <code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">CUDA</span></code></p></li>
<li><p>Exécutez le programme en sélectionnant la seconde GPU</p></li>
</ul>
</div>
<p>Par défaut, la taille du vecteur complexe est 1024, le périphérique sollicité est 0 pour une utilisation en OpenCL. La sortie sur la machine ressemble à :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Device<span class="w"> </span>Selection<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>CUDA
Size<span class="w"> </span>of<span class="w"> </span>complex<span class="w"> </span>vector<span class="w"> </span>:<span class="w"> </span><span class="m">1024</span>
Device<span class="w"> </span><span class="c1">#0 of type GPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 of type GPU : Quadro K420</span>
GPU<span class="w"> </span>selected<span class="w"> </span>NVIDIA<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span>TITAN
Definition<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.029
Synthesis<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Allocation<span class="w"> </span>on<span class="w"> </span>Host<span class="w"> </span><span class="k">for</span><span class="w"> </span>results<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.000
Execution<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.044
CUDARate:<span class="w"> </span><span class="m">5262</span>
Precision:<span class="w">  </span><span class="m">6</span>.966685e-05<span class="w"> </span><span class="m">6</span>.9132504e-05
</pre></div>
</div>
<p>Sur certaines configurations du CBP, une exécution en PyCUDA peut donner un message comparable au suivant :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Device<span class="w"> </span>Selection<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>CUDA
Size<span class="w"> </span>of<span class="w"> </span>complex<span class="w"> </span>vector<span class="w"> </span>:<span class="w"> </span><span class="m">1024</span>
Device<span class="w"> </span><span class="c1">#0 of type GPU : NVIDIA GeForce GTX TITAN</span>
Device<span class="w"> </span><span class="c1">#1 of type GPU : Quadro K420</span>
GPU<span class="w"> </span>selected<span class="w"> </span>Quadro<span class="w"> </span>K420
Traceback<span class="w"> </span><span class="o">(</span>most<span class="w"> </span>recent<span class="w"> </span>call<span class="w"> </span>last<span class="o">)</span>:
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/equemene/bench4gpu/ETSN/./MyDFT_8.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">356</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>k_np,l_np<span class="o">=</span>CUDADFT<span class="o">(</span>a_np,b_np,Device<span class="o">)</span>
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/equemene/bench4gpu/ETSN/./MyDFT_8.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">162</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>CUDADFT
<span class="w">    </span><span class="nv">mod</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>SourceModule<span class="o">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">  File &quot;</span>/usr/lib/python3/dist-packages/pycuda/compiler.py<span class="s2">&quot;, line 290, in __init__</span>
<span class="s2">    cubin = compile(source, nvcc, options, keep, no_extern_c,</span>
<span class="s2">  File &quot;</span>/usr/lib/python3/dist-packages/pycuda/compiler.py<span class="s2">&quot;, line 254, in compile</span>
<span class="s2">    return compile_plain(source, options, keep, nvcc, cache_dir, target)</span>
<span class="s2">  File &quot;</span>/usr/lib/python3/dist-packages/pycuda/compiler.py<span class="s2">&quot;, line 135, in compile_plain</span>
<span class="s2">    raise CompileError(&quot;</span>nvcc<span class="w"> </span>compilation<span class="w"> </span>of<span class="w"> </span>%s<span class="w"> </span>failed<span class="s2">&quot; % cu_file_path,</span>
<span class="s2">pycuda.driver.CompileError: nvcc compilation of /tmp/tmpccm0243v/kernel.cu failed</span>
<span class="s2">[command: nvcc --cubin -arch sm_30 -I/usr/lib/python3/dist-packages/pycuda/cuda kernel.cu]</span>
<span class="s2">[stderr:</span>
<span class="s2">nvcc fatal   : Value &#39;sm_30&#39; is not defined for option &#39;gpu-architecture&#39;</span>
<span class="s2">]</span>

<span class="s2">-------------------------------------------------------------------</span>
<span class="s2">PyCUDA ERROR: The context stack was not empty upon module cleanup.</span>
<span class="s2">-------------------------------------------------------------------</span>
<span class="s2">A context was still active when the context stack was being</span>
<span class="s2">cleaned up. At this point in our execution, CUDA may already</span>
<span class="s2">have been deinitialized, so there is no way we can finish</span>
<span class="s2">cleanly. The program will be aborted now.</span>
<span class="s2">Use Context.pop() to avoid this problem.</span>
<span class="s2">-------------------------------------------------------------------</span>
<span class="s2">Aborted</span>
</pre></div>
</div>
<p>En lisant attentivement, nous découvrons que le compilateur <strong>nvcc</strong> embarqué ne supporte pas la GPU <strong>Quadro K420</strong> simplement parce qu’elle est trop vieille ! Ainsi, <strong>PyOpenCL</strong> montre là aussi sa supériorité : non seulement PyOpenCL permet une exécution sans modification sur CPU ou GPU, de manière plus efficace qu’avec Numpy ou Numba, mais en plus, sur GPU, elle offre moins de contraintes sur la distribution des tâches (pas de nécessité d”<em>hybrider</em> son programme en <em>Blocks</em> et <em>Threads</em>) et une pérennité dans le temps, que ce soit pour les GPU très anciennes ou très récentes !</p>
<p>Comme dernière modification sur notre , nous proposons de :</p>
<ul class="simple">
<li><p>lever l’inhibition des méthodes sous Python</p></li>
<li><p>supprimer l’option <code class="docutils literal notranslate"><span class="pre">-g</span></code></p></li>
<li><p>rajouter une option à l’activation de la naive : <code class="docutils literal notranslate"><span class="pre">-n</span></code> (défaut non)</p></li>
<li><p>rajouter une option à l’activation de la Numpy : <code class="docutils literal notranslate"><span class="pre">-y</span></code> (défaut oui)</p></li>
<li><p>rajouter une option à l’activation de la Numba : <code class="docutils literal notranslate"><span class="pre">-a</span></code> (défaut non)</p></li>
<li><p>rajouter une option à l’activation de la OpenCL : <code class="docutils literal notranslate"><span class="pre">-o</span></code> (défaut oui)</p></li>
<li><p>rajouter une option à l’activation de la CUDA : <code class="docutils literal notranslate"><span class="pre">-c</span></code> (défaut non)</p></li>
<li><p>rajouter une option au nombre de <em>threads</em> en CUDA : <code class="docutils literal notranslate"><span class="pre">-t</span></code> (défaut 1024)</p></li>
<li><p>rajouter un test sur l’appel du noyau CUDA (cas threads non multiple de taille)</p></li>
</ul>
<p>Nous trouverons ces modifications dans le programme <code class="docutils literal notranslate"><span class="pre">MyDFT_9.py</span></code>.</p>
</section>
<section id="exploration-avec-le-coeur-du-gpu-xgemm">
<h2>Exploration avec le « coeur » du GPU : xGEMM<a class="headerlink" href="#exploration-avec-le-coeur-du-gpu-xgemm" title="Lien vers cette rubrique">¶</a></h2>
<p>Dans l’introduction sur les GPU, il était présenté la GPU comme un « gros » multiplicateur de matrices.</p>
<p>En effet, la méthode par <em>shadering</em> exploitait de nombreuses multiplications matricielles pour générer une image numérique (CGI ou <em>Compute Generated Image</em>). Il n’est donc pas étonnant que les GPU soient, historiquement, plutôt « efficaces » pour ce type de tâches : nous allons l’évaluer.</p>
<section id="de-blas-aux-xgemm-les-differentes-implementations">
<h3>De BLAS aux xGEMM : les différentes implémentations<a class="headerlink" href="#de-blas-aux-xgemm-les-differentes-implementations" title="Lien vers cette rubrique">¶</a></h3>
<p>En calcul scientifique, l’objectif est de ne pas réinventer la roue à chaque modélisation numérique. Depuis presque 40 ans, la libraire d’algèbre linéaire la plus courante est la BLAS pour <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">Basic Linear Algebra Subprograms</a>.</p>
<p>Ces routines peuvent être considérées comme des <em>standards</em>. De nombreuses implémentations existent pour toutes les architectures. Sur GPU, Nvidia propose sa propre version avec <a class="reference external" href="http://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a> et AMD a placé en <em>Open Source</em> la sienne <a class="reference external" href="https://github.com/clMathLibraries/clBLAS">clBLAS</a>.</p>
<p>Sur les CPU, Intel propose son implémentation largement optimisée pour ses processeurs au sein des <a class="reference external" href="https://software.intel.com/en-us/mkl">librairies MKL</a> mais les versions Open Sourcen notamment <a class="reference external" href="http://www.openblas.net/">OpenBLAS</a>, n’ont rien à leur envier. D’autres implémentations sont installées au CBP : l”<a class="reference external" href="http://math-atlas.sourceforge.net/">ATLAS</a> et la <a class="reference external" href="https://www.gnu.org/software/gsl/">GSL</a>.</p>
<p>Les librairies BLAS sont dans 3 catégories : celles manipulant exclusivement les vecteurs (1 dimension), celles manipulant les matrices et les vecteurs (1 et 2 dimensions), enfin celles manipulant exclusivement les matrices (2 dimensions).</p>
<p>L’implémentation de la multiplication de matrices dans les libairies BLAS est la <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code>, avec <code class="docutils literal notranslate"><span class="pre">x</span></code> à remplacer par <code class="docutils literal notranslate"><span class="pre">S</span></code>, <code class="docutils literal notranslate"><span class="pre">D</span></code>, <code class="docutils literal notranslate"><span class="pre">C</span></code> et <code class="docutils literal notranslate"><span class="pre">Z</span></code> respectivement pour la <strong>S</strong> imple précision (32 bits), la <strong>D</strong> ouble précision (64 bits), la <strong>C</strong> omplexe &amp; simple précision et complexe &amp; double précision ( <strong>Z</strong> ).</p>
<p>L’objectif de cette première manipulation est de commencer à comparer les GPU et les CPU avec cette opération simple.</p>
</section>
<section id="exploitations-de-xgemm">
<h3>Exploitations de xGEMM<a class="headerlink" href="#exploitations-de-xgemm" title="Lien vers cette rubrique">¶</a></h3>
<p>Le dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu/BLAS/xGEMM</span></code> contient peu de fichiers dont les importants sont : un unique programme source, <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code>, et un fichier de construction, <code class="docutils literal notranslate"><span class="pre">Makefile</span></code>. C’est ce fichier qui va <code class="docutils literal notranslate"><span class="pre">construire</span></code> tous les exécutables d’un coup, à la fois pour les différentes implémentations de BLAS, mais aussi pour les deux précisions <strong>SP</strong> (simple précision sur 32 bits) et <strong>DP</strong> (double précision sur 64 bits).</p>
<section id="le-source">
<h4>Le source<a class="headerlink" href="#le-source" title="Lien vers cette rubrique">¶</a></h4>
<p>Le programme source <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code> a été conçu pour fonctionner avec n’importe quelle implémentation. Si vous l’éditez, vous réalisez qu’il n’est pas si simple d’avoir un programme qui s’exécute indifféremment quelle que soit la librairie. Même si les appels sont comparables (même nombre d’attributs dans les fonctions), leur nom change de librairie à librairie. Pour n’avoir qu’un seul source, les directives sont largement exploitées. C’est donc le <code class="docutils literal notranslate"><span class="pre">Makefile</span></code> qui va permettre de ne compiler que telle ou telle portion du programme source.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #6.1 : éditez le source du programme `xGEMM.c` et repérez les éléments suivants</strong></p>
<ul class="simple">
<li><p>Identifiez dans <code class="docutils literal notranslate"><span class="pre">Makefile</span></code> quelles directives (précédées par <code class="docutils literal notranslate"><span class="pre">-D</span></code>) sont associées aux différentes implémentations</p></li>
<li><p>Identifiez dans <code class="docutils literal notranslate"><span class="pre">xGEMM.c</span></code> les « directives » C à base de <code class="docutils literal notranslate"><span class="pre">#ifdef</span></code> utilisées pour séparer les différentes implémentations</p></li>
<li><p>Repérez les deux implémentations <strong>FBLAS</strong> et <strong>OpenBLAS</strong> dans le programme à partir de l’analyse du <code class="docutils literal notranslate"><span class="pre">Makefile</span></code></p></li>
<li><p>Quelle différence existe-t-il dans les appels de la fonction <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> ?</p></li>
<li><p>Repérez les deux implémentations pour GPU Nvidia, les <strong>cublas</strong> et <strong>thunking</strong></p></li>
<li><p>Par quoi se distinguent les versions <strong>cublas</strong> et <strong>thunking</strong> ?*</p></li>
</ul>
</div>
</section>
<section id="les-executables">
<h4>Les exécutables<a class="headerlink" href="#les-executables" title="Lien vers cette rubrique">¶</a></h4>
<p>C’est simplement en lançant la commande <code class="docutils literal notranslate"><span class="pre">make</span></code> dans le dossier que la compilation s’opère. Ainsi, tous les exécutables commencent par <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_</span></code> ou <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_</span></code>. Ils sont ensuite suffixés par l’implémentation BLAS :</p>
<p>Nous avons alors 12 exécutables de la forme <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_&lt;version&gt;</span></code> ou <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_&lt;version&gt;</span></code> :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">openblas</span></code> utilisant la librairie OpenBLAS, pour CPU</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gsl</span></code> utilisant la librairie GSL (pour <em>GNU Scientific Librairies</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fblas</span></code> utilisant la librairie OpenBLAS mais pour des appels fortran, pour CPU</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cublas</span></code> utilisant la librairie cuBLAS avec une gestion externe de la mémoire</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thunking</span></code> utilisant la librairie cuBLAS avec une gestion interne de la mémoire</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clblas</span></code> utilisant la librairie clBLAS et OpenCL</p></li>
</ul>
<p>Le programme appelé avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> donne quelques informations pour le lancement.</p>
<p>A l’exception de <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_clblas</span></code> et <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_clblas</span></code>, les paramètres d’entrée sont :</p>
<ul class="simple">
<li><p>la taille de la matrice</p></li>
<li><p>le nombre d’itérations</p></li>
</ul>
<p>Pour les programmes <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_clblas</span></code> et <code class="docutils literal notranslate"><span class="pre">xGEMM_DP_clblas</span></code>, les paramètres d’entrée sont :</p>
<ul class="simple">
<li><p>la taille de la matrice</p></li>
<li><p>le nombre d’itérations</p></li>
<li><p>l’ID de la plateforme</p></li>
<li><p>l’ID du périphérique</p></li>
</ul>
<p>En appelant ces deux exécutables avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code>, le programme détecte les plates-formes et périphériques.</p>
<p>La sortie offre comme informations :</p>
<ul class="simple">
<li><p>la durée moyenne d’exécution de chaque cycle</p></li>
<li><p>l’estimation du nombre de GFlops</p></li>
<li><p>l’erreur estimée par le calcul de la trace des matrices</p></li>
</ul>
<p>Voici quelques exemples de lancement de ces exécutables sur une même machine, pour les CPU exclusivement :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_fblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>FBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1597913000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">25</span>.020
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_gsl<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>GSL:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.4037233000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">2</span>.848
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_openblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0109249000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">365</span>.953
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Voici quelques exemples de lancement de ces exécutables sur une même machine, pour les GPU exclusivement :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3678790000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007630000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007413000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">5393</span>.228
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0447023000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">89</span>.436
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Nous constatons d’abord une grosse disparité de performance. En analysant la durée d’un cycle, nous découvrons qu’il est inférieur à la milliseconde. Nous portons donc le nombre d’itérations à 1000, nous obtenons alors :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3984100000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0006670000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005262330<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">7597</span>.395
Error<span class="w"> </span><span class="m">0</span>.0000000000

root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0073920040<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">540</span>.855
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Il faut donc prendre certaines précautions dans chaque évaluation de performances, notamment lorsque les durées d’exécution sont trop courtes.</p>
<p>Nous avons vu que plusieurs GPU peuvent coexister dans la machine. La question est de savoir lequel est sollicité lors d’un lancement de programme. Par défaut, avec les librairies CUDA, une seule GPU est sollicitée, souvent la première découverte. Pour savoir lequel a fait le travail, nous pouvons exploiter la commande <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> présentée ci-dessus pendant l’exécution du programme.</p>
<p>Dans le premier terminal qui nous sert à l’exécution des programmes, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">100000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">100000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3861840000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0007770000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005138863<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">7779</span>.931
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Dans le second terminal, dans lequel nous lançons des commandes de supervision, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:~#<span class="w"> </span>nvidia-smi
Sat<span class="w"> </span>Nov<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">12</span>:10:59<span class="w"> </span><span class="m">2018</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">384</span>.130<span class="w">                </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">384</span>.130<span class="w">                   </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:3B:00.0<span class="w">  </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">27</span>%<span class="w">   </span>52C<span class="w">    </span>P2<span class="w">   </span>254W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">    </span>248MiB<span class="w"> </span>/<span class="w"> </span>11171MiB<span class="w"> </span><span class="p">|</span><span class="w">     </span><span class="m">98</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w">   </span><span class="m">1</span><span class="w">  </span>Quadro<span class="w"> </span>K420<span class="w">         </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:A1:00.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">25</span>%<span class="w">   </span>49C<span class="w">    </span>P8<span class="w">    </span>N/A<span class="w"> </span>/<span class="w">  </span>N/A<span class="w"> </span><span class="p">|</span><span class="w">     </span>12MiB<span class="w"> </span>/<span class="w">  </span>1999MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">   </span>Type<span class="w">   </span>Process<span class="w"> </span>name<span class="w">                             </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6477</span><span class="w">      </span>C<span class="w">   </span>./xGEMM_SP_cublas<span class="w">                            </span>199MiB<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6681</span><span class="w">      </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                            </span>36MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Nous voyons que le GPU #0, identifié comme la GTX 1080 Ti, exécute 2 tâches : <code class="docutils literal notranslate"><span class="pre">/usr/lib/xorg/Xorg</span></code> et <code class="docutils literal notranslate"><span class="pre">./xGEMM_SP_cublas</span></code>. Nous avons également l’empreinte mémoire de chacun des processus : 36MiB pour le <code class="docutils literal notranslate"><span class="pre">Xorg</span></code> et 199MiB pour notre programme <code class="docutils literal notranslate"><span class="pre">xGEMM_SP_cublas</span></code>.</p>
<p>La question légitime est de se demander, dans le cas d’une machine multi-gpu, comment « contrôler » sur quele GPU est exécutée le programme. Il existe des méthodes assez comparables à celles de OpenCL pour la découverte des périphériques, mais elles sont généralement peu exploitées dans les programmes. La technique la plus classique reste l’utilisation d’une variable d’environnement, laquelle va « contraindre » l’exploitation d’un (ou plusieurs) GPU(s) : <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>.</p>
<p>Par exemple, si nous précisons que cette variable vaut <code class="docutils literal notranslate"><span class="pre">1</span></code>, le périphérique Nvidia <code class="docutils literal notranslate"><span class="pre">#1</span></code> sera le seul sollicité. Ainsi, en lançant la commande préfixée de cette variable valuée, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>./xGEMM_SP_cublas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1777080000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0005750000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0283741830<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">140</span>.903
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Et pendant l’exécution, dans la fenêtre de commandes de supervision :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@opencluster2:~#<span class="w"> </span>nvidia-smi
Sat<span class="w"> </span>Nov<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">12</span>:21:26<span class="w"> </span><span class="m">2018</span>
+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">384</span>.130<span class="w">                </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">384</span>.130<span class="w">                   </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">108</span>...<span class="w">  </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:3B:00.0<span class="w">  </span>On<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">24</span>%<span class="w">   </span>37C<span class="w">    </span>P8<span class="w">    </span>12W<span class="w"> </span>/<span class="w"> </span>250W<span class="w"> </span><span class="p">|</span><span class="w">     </span>39MiB<span class="w"> </span>/<span class="w"> </span>11171MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w">   </span><span class="m">1</span><span class="w">  </span>Quadro<span class="w"> </span>K420<span class="w">         </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:A1:00.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span><span class="m">30</span>%<span class="w">   </span>59C<span class="w">    </span>P0<span class="w">    </span>N/A<span class="w"> </span>/<span class="w">  </span>N/A<span class="w"> </span><span class="p">|</span><span class="w">     </span>51MiB<span class="w"> </span>/<span class="w">  </span>1999MiB<span class="w"> </span><span class="p">|</span><span class="w">    </span><span class="m">100</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                       </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">       </span>PID<span class="w">   </span>Type<span class="w">   </span>Process<span class="w"> </span>name<span class="w">                             </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">      </span><span class="m">6681</span><span class="w">      </span>G<span class="w">   </span>/usr/lib/xorg/Xorg<span class="w">                            </span>36MiB<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span><span class="m">1</span><span class="w">      </span><span class="m">8192</span><span class="w">      </span>C<span class="w">   </span>./xGEMM_SP_cublas<span class="w">                             </span>39MiB<span class="w"> </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>Nous pouvons évidemment appliquer la même approche du préfixe avec l’autre implémentation CUDA (le mode <em>Thunking</em>) :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>./xGEMM_SP_thunking<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span>
Using<span class="w"> </span>CuBLAS/Thunking:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix

Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0361565210<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">110</span>.575
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Avec les implémentations OpenCL, il est possible, sans variable, de s’adresser avec un unique exécutable, à chacun des périphériques (CPU ou GPU) quelle que soit leur implémentation :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2068470000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0105010000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.6236489000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">6</span>.411
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
<span class="m">1</span><span class="w"> </span>warning<span class="w"> </span>generated.
./xGEMM_SP_clblas:<span class="w"> </span>symbol<span class="w"> </span>lookup<span class="w"> </span>error:<span class="w"> </span>/root/.cache/pocl/kcache/DO/MOINFKPIFEHKLMFJBAMOHIHHPGDFMKFNMCFAG/sgemm_Col_NN_B0_MX032_NX032_KX08/16-16-1/sgemm_Col_NN_B0_MX032_NX032_KX08.so:<span class="w"> </span>undefined<span class="w"> </span>symbol:<span class="w"> </span>mem_fence
root@opencluster2:/local/tests/bench4gpu/BLAS/xGEMM#<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
./xGEMM_SP_clblas:<span class="w"> </span>symbol<span class="w"> </span>lookup<span class="w"> </span>error:<span class="w"> </span>/root/.cache/pocl/kcache/DO/MOINFKPIFEHKLMFJBAMOHIHHPGDFMKFNMCFAG/sgemm_Col_NN_B0_MX032_NX032_KX08/16-16-1/sgemm_Col_NN_B0_MX032_NX032_KX08.so:<span class="w"> </span>undefined<span class="w"> </span>symbol:<span class="w"> </span>mem_fence

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>:<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.3912880000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0025020000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0029808910<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">1341</span>.210
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">1</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">1000</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>:<span class="w"> </span>Quadro<span class="w"> </span>K420

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2507630000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0019840000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1263268040<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">31</span>.648
Error<span class="w"> </span><span class="m">0</span>.0000000000

$<span class="w"> </span>./xGEMM_SP_clblas<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">0</span>
Using<span class="w"> </span>CLBLAS:<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span><span class="k">for</span><span class="w"> </span>1000x1000<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz

Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.2919330000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>memory<span class="w"> </span>free<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.0030360000<span class="w"> </span>s
Duration<span class="w"> </span>of<span class="w"> </span>each<span class="w"> </span>cycle<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.1896384000<span class="w"> </span>s
Number<span class="w"> </span>of<span class="w"> </span>GFlops<span class="w"> </span>:<span class="w"> </span><span class="m">21</span>.082
Error<span class="w"> </span><span class="m">0</span>.0000000000
</pre></div>
</div>
<p>Nous pouvons également constater que certains périphériques ne « passent » pas en OpenCL et que les performances sont très variables.</p>
<p>Voici un synoptique des performances pour les différentes implémentations et les différents GPU en simple précision. Les performances ont été placées en log. Les GPU présentent des performances incroyablement supérieures au processeur (autour d’un facteur 20 pour la GTX 1080 Ti face à la meilleure des implémentations pour CPU).</p>
<img alt="Image xgemm_sp" class="img-fluid center" src="../../_images/xgemm_sp.png" />
<p>Lors du passage en double précision, les GPU se rapprochent des CPU en performance.</p>
<img alt="Image xgemm_dp" class="img-fluid center" src="../../_images/xgemm_dp.png" />
<p>Le ratio entre performances en simple sur double précision illustre la grosse différence entre CPU et GPU.</p>
<img alt="Image xgemm_ratio_spdp" class="img-fluid center" src="../../_images/xgemm_ratio_spdp.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #6.2 : lancez les `xGEMM_&lt;precision&gt;_&lt;implementation&gt;` avec une taille de 1000</strong></p>
<ul class="simple">
<li><p>Variez le nombre d’itérations pour obtenir une durée d’exécution d’une dizaine de secondes ?</p></li>
<li><p>Laquelle des implémentations CPU est la plus performante ?</p></li>
<li><p>Laquelle des implémentations GPU est la plus performante ?</p></li>
<li><p>Exécutez à nouveau la performance en passant la précision (de SP à DP) sur CPU</p></li>
<li><p>Evaluez le rapport de performances entre SP et DP sur CPU</p></li>
<li><p>Exécutez à nouveau la performance en passant la précision (de SP à DP) sur GPU</p></li>
<li><p>Evaluez le rapport de performances entre SP et DP sur GPU</p></li>
<li><p>Présentez les performances entre implémentations en simple précision</p></li>
<li><p>Présentez les performances entre implémentations en double précision</p></li>
</ul>
</div>
<p>Il est aussi intéressant de constater que la performance dépend non seulement de l’implémentation, du périphérique mais aussi de sa sollicitation. Voici la performance pour l’implémentation CPU avec OpenBLAS et les implémentations cuBLAS et <em>Thunking</em> sur la GTX 1080 Ti.</p>
<img alt="Image xgemm_sp_size" class="img-fluid center" src="../../_images/xgemm_sp_size.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #6.3 : lancez les programmes précédents pour différentes tailles</strong></p>
<ul class="simple">
<li><p>Diminuez la taille aux valeurs suivantes <code class="docutils literal notranslate"><span class="pre">125</span></code>, <code class="docutils literal notranslate"><span class="pre">250</span></code>, <code class="docutils literal notranslate"><span class="pre">500</span></code> et exécutez les programmes</p></li>
<li><p>Que constatez-vous pour les performances sur CPU ou GPU ?</p></li>
<li><p>Augmentez la taille à <code class="docutils literal notranslate"><span class="pre">2000</span></code>, <code class="docutils literal notranslate"><span class="pre">4000</span></code>, <code class="docutils literal notranslate"><span class="pre">8000</span></code>, <code class="docutils literal notranslate"><span class="pre">16000</span></code> et exécutez les programmes</p></li>
<li><p>Que constatez-vous pour les performances sur CPU ou GPU ?</p></li>
<li><p>Pendant une exécution, observez la consommation électrique instantanée : que constatez-vous ?</p></li>
<li><p>Présentez les performances en fonction des tailles explorées</p></li>
</ul>
</div>
</section>
</section>
</section>
<section id="exploration-de-codes-metiers">
<h2>Exploration de « codes métiers »<a class="headerlink" href="#exploration-de-codes-metiers" title="Lien vers cette rubrique">¶</a></h2>
<section id="introduction-a-l-integration-de-codes">
<h3>Introduction à l’intégration de codes<a class="headerlink" href="#introduction-a-l-integration-de-codes" title="Lien vers cette rubrique">¶</a></h3>
<p>Les « codes métiers » sont des programmes « de production scientifique ». Il n’est pas question, pour un utilisateur, de modifier le source du programme pour ses activités, notamment de recherche. Le programme est exploité « tel quel » et seuls les paramètres d’entrées changent.</p>
<p>Par contre l”<strong>intégration</strong> d’un code dans un <strong>environnement informatique</strong> (<em>tuple</em> matériel, système d’exploitation, librairies, logiciel, usage) peut s’avérer compliqué, voire complexe. Cette activité d’intégration forme une grande partie de l’activité des personnels des infrastructures de calcul scientifique.</p>
</section>
<section id="exploitation-en-deep-learning-avec-tensorflow">
<h3>Exploitation en Deep Learning avec TensorFlow<a class="headerlink" href="#exploitation-en-deep-learning-avec-tensorflow" title="Lien vers cette rubrique">¶</a></h3>
<p>Nous allons tenter d’exploiter un des exemples présentés dans les <a class="reference external" href="https://www.tensorflow.org/tutorials">tutoriels</a> de <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p>L’exploitation des GPU a littéralement « explosé » lorsque le <em>Machine Learning</em> ou le <em>Deep Learning</em> sont devenus des modes. En effet, la puissance « brute » des GPU peut enfin être exploitée sans trop de portage, notamment par l’exploitation des librairies BLAS ou cuDNN.</p>
<p>L’exemple sur lequel nous allons nous pencher est le <a class="reference external" href="https://www.tensorflow.org/tutorials/images/cnn">DeepCNN</a>.</p>
<p>L’intégration de TensorFlow avec une exploitation des GPU est plutôt ardue à partir des sources, étant donné le nombre de dépendances. L’approche <a class="reference external" href="https://docs.conda.io/en/latest/">Conda</a> permet d’installer un « environnement système » bâti essentiellement autour d’applications Python. Conda permet également à tout utilisateur de créer son propre environnement complet lui permettant un suivi personnel de ses outils.</p>
<p>Au CBP, un environnement Conda a été installé pour permettre l’exploitation de la majorité des outils construits autour de TensorFlow. Le chargement de l’environnement se réalise en « sourçant » l’environnement CONDA avec la commande suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module<span class="w"> </span>load<span class="w"> </span>conda3/4.9.2
</pre></div>
</div>
<p>La commande précédente « paramètre » les variables d’environnement nécessaires l’exploitation de l’environnement complet CONDA installé pour vous dans <code class="docutils literal notranslate"><span class="pre">/opt/conda3-4.9.2/</span></code></p>
<p>L’objectif est de « jouer » le <a class="reference external" href="https://www.tensorflow.org/tutorials/images/cnn">tutoriel</a> exploitant la base d’images CIFAR10 pour un apprentissage convolutif.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #7.1 :</strong></p>
<ul class="simple">
<li><p>chargez l’environnement conda</p></li>
<li><p>préparez la variable d’environnement <code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></li>
<li><p>ouvrez un terminal et tapez <code class="docutils literal notranslate"><span class="pre">dstat</span></code> pour monitorer le système</p></li>
<li><p>ouvrez un terminal et tapez <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">dmon</span></code> pour la GPU</p></li>
<li><p>lancez un <code class="docutils literal notranslate"><span class="pre">ipython</span></code> dans un terminal</p></li>
<li><p>appliquez ligne à ligne le tutoriel et regardez l’activité réseau</p></li>
<li><p>vérifiez que vous obtenez des résultats comparables</p></li>
<li><p>récupérez dans un fichier <code class="docutils literal notranslate"><span class="pre">CIFAR10.py</span></code> toutes les commandes du tutoriel</p></li>
<li><p>inhiber les lignes associées à un affichage (préfixées par <code class="docutils literal notranslate"><span class="pre">plt</span></code></p></li>
<li><p>lancez le fichier préfixé de <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">python</span></code></p></li>
<li><p>notez le temps écoulé (<code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">Elapsed</span></code>) pour cette première exécution</p></li>
<li><p>relancez le fichier préfixé de <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">python</span></code></p></li>
<li><p>notez le temps écoulé (<code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">Elapsed</span></code>) pour cette seconde exécution</p></li>
<li><p>inhibez les GPU Nvidia avec <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code></p></li>
<li><p>relancez le fichier préfixé de <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">python</span></code></p></li>
<li><p>vérifiez que la GPU est inutilisée</p></li>
<li><p>notez le temps écoulé (<code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">Elapsed</span></code>) pour cette troisième exécution</p></li>
<li><p>comparez les temps d’exécution et sur l’efficacité d’usage de la GPU</p></li>
</ul>
</div>
<p>En regardant l’activité du GPU, il apparaît que le gain est substanciel par rapport à une « petite » configuration GPU. Cependant, la nature du réseau créé n’exploitait pas de manière optimale la GPU par rapport à la CPU. Une petite modification de notre réseau va permettre de mettre cela en évidence, en modifiant le nombre de poids d’une des couches neuronales.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #7.2 :</strong></p>
<ul class="simple">
<li><p>changez <strong>64</strong> en <strong>65536</strong> dans <code class="docutils literal notranslate"><span class="pre">model.add(layers.Dense(64,</span> <span class="pre">activation='relu'))</span></code></p></li>
<li><p>supprimez la référence à <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code> avec <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">-n</span> <span class="pre">CUDA_VISIBLE_DEVICES</span></code></p></li>
<li><p>relancez l’apprentissage <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">python</span> <span class="pre">CIFAR10.py</span></code></p></li>
<li><p>notez dès le début d’un cycle l’ETA (Estimate Time of Arrival)</p></li>
<li><p>contrôlez l’activité de la GPU</p></li>
<li><p>arrêtez l’apprentissage avec un <strong>&lt;Ctrl&gt;&lt;C&gt;</strong></p></li>
<li><p>inhibez la GPU</p></li>
<li><p>relancez l’apprentissage <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">python</span> <span class="pre">CIFAR10.py</span></code></p></li>
<li><p>notez dès le début d’un cycle l’ETA</p></li>
<li><p>arrêtez l’apprentissage avec un <strong>&lt;Ctrl&gt;&lt;C&gt;</strong></p></li>
<li><p>effectuez le rapport entre les ETA</p></li>
</ul>
</div>
<p>Sur la machine <strong>k40</strong> équipée d’une GPU <strong>Tesla K40</strong> ancienne et de deux CPU E5-2609v2, le ratio est de 15. Le plus intéressant vient de la comparaison avec la machine au CBP disposant des processeurs les plus performants : 2 AMD Epyc 7742 avec chacun 64 coeurs. Ces derniers sont 3x moins rapides que la K40 sur cette opération. Ainsi, même de vieilles GPU (génération N-5) peuvent encore, dans des opérations de Machine Learning, s’avérer efficaces, dès lors que les problèmes sont correctement dimensionnés pour elles.</p>
</section>
<section id="integration-et-exploitation-du-code-genesis">
<h3>Intégration et exploitation du code GENESIS<a class="headerlink" href="#integration-et-exploitation-du-code-genesis" title="Lien vers cette rubrique">¶</a></h3>
<p>Le code <a class="reference external" href="https://www.r-ccs.riken.jp/labs/cbrt/">GENESIS</a> de l’institut <a class="reference external" href="https://www.r-ccs.riken.jp/en/">RIKEN Center for Computational Science</a> est un logiciel de <a class="reference external" href="https://fr.wikipedia.org/wiki/Dynamique_mol%C3%A9culaire">dynamique moléculaire</a>.
Présenté comme exploitant massivement les GPU, il est disponible sur <a class="reference external" href="https://bitbucket.org/dpotter/pkdgrav3/">bitbucket</a>.
C’est un programme <em>hybride</em> (exploitant 2 stratégies de parallélisation), et même <em>trhybride</em> dans la mesure où il exploite les GPU de type Nvidia avec CUDA, la distribution sur les coeurs via <a class="reference external" href="https://fr.wikipedia.org/wiki/OpenMP">OpenMP</a> et la distribution sur des noeuds différents via <a class="reference external" href="https://fr.wikipedia.org/wiki/Message_Passing_Interface">passage de messages MPI</a>.
Le code source est accessible à l’adresse : <a class="reference external" href="https://www.r-ccs.riken.jp/labs/cbrt/download/genesis-version-1-5/">https://www.r-ccs.riken.jp/labs/cbrt/download/genesis-version-1-5/</a></p>
<div class="note note-warning docutils container">
<p><strong>Exercice #8.1 : Récupérez et compilez le code suivant la documentation fournie</strong></p>
<ul class="simple">
<li><p>Lisez la <a class="reference external" href="https://www.r-ccs.riken.jp/labs/cbrt/installation/">documentation</a> d’installation</p></li>
<li><p>Placez les sources dans le dossier <code class="docutils literal notranslate"><span class="pre">/local/$USER/GENESIS</span></code> créé pour l’occasion</p></li>
<li><p>Préparez une compilation pour GPU en simple précision dans le dossier <code class="docutils literal notranslate"><span class="pre">/local/$USER/GENESIS/gpu-single</span></code></p></li>
<li><p>Compilez et installez le programme</p></li>
<li><p>Purgez la compilation précédente</p></li>
<li><p>Préparez une compilation pour CPU en simple précision dans le dossier <code class="docutils literal notranslate"><span class="pre">/local/$USER/GENESIS/cpu-single</span></code></p></li>
<li><p>Compilez et installez le programme</p></li>
</ul>
</div>
<p>L’exécution du programme est évaluée en comparant son exécution dans différentes configurations d’exploitation des CPU et des GPU.
Pour cela, l’exemple de la base de <a class="reference external" href="https://www.r-ccs.riken.jp/labs/cbrt/?smd_process_download=1&amp;download_id=14619">tests de régression</a>. Le test  <code class="docutils literal notranslate"><span class="pre">test_rpath_spdyn/alad_water</span></code> a été modifié pour durer un peu plus longtemps à l’exécution.</p>
<p>De plus, <strong>GENESIS</strong> étant <em>trhybride</em>, il est programmé pour se distribuer sur des machines indépendantes qui communiquent par <em>échanges de messages</em>. Le test  <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/alad_water.tgz">alad_water</a> exige, par construction de la simulation, quatre exécutions concurrentes lesquelles vont communiquer par MPI. Il faudra donc préfixer l’exécutable de <code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span></code> pour exécuter ces quatre tâches.</p>
<p>De plus, ce programme est aussi parallélisé avec OpenMP : il va donc « aussi » exploiter les coeurs disponibles. Le souci, c’est que, par défaut, il va lancer pour chaque tâche MPI autant de sous-tâches OpenMP que de coeurs (même « virtuels ») disponibles sur la machine. Ainsi, en exécutant l’exemple <code class="docutils literal notranslate"><span class="pre">alad_water</span></code> sur une machine disposant de 8 coeurs Hyperthreadés (donc disposant au total de 16 coeurs logiques), il va lancer 4*16 soit 64 tâches pour seulement 8 « vrais » coeurs : de quoi surcharger la machine.</p>
<p>Pour finir, dans comme ce programme est « aussi » <em>gépufié</em> (porté sur GPU), il risque d’y avoir un goulet d’étranglement pour l’accès au GPU pour les 64 tâches simultanées. Ainsi, les programmes « fortement » parallélisés exigent de choisir judicieusement les différents paramètres de parallélisation tout comme nous avons vue que, pour les GPU, il fallait découper la tâche en un nombre optimal de sous-tâches.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #8.2 : Exécutez l’exemple `alad_water`</strong></p>
<ul class="simple">
<li><p>Récupérez <a class="reference external" href="http://www.cbp.ens-lyon.fr/emmanuel.quemener/documents/alad_water.tgz">l’exemple d’exécution</a></p></li>
<li><p>Décompressez l’archive dans <code class="docutils literal notranslate"><span class="pre">/local/$USER/GENESIS</span></code></p></li>
<li><p>Exécutez le programme sur l’exemple avec la version CPU</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">/local/$USER/GENESIS/cpu-single/bin/spdyn</span> <span class="pre">inp</span></code></p></li>
</ul>
</li>
<li><p>Observez pendant l’exécution l’activité des coeurs</p></li>
<li><p>Notez le <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> et le <code class="docutils literal notranslate"><span class="pre">System</span> <span class="pre">Time</span></code></p></li>
<li><p>Effacez les résultats <code class="docutils literal notranslate"><span class="pre">test*</span></code> avec <code class="docutils literal notranslate"><span class="pre">rm</span> <span class="pre">test*</span></code></p></li>
<li><p>Exécutez le programme sur l’exemple avec la version GPU</p>
<ul>
<li><p>Exécutez la commande <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">/local/$USER/GENESIS/gpu-single/bin/spdyn</span> <span class="pre">inp</span></code></p></li>
</ul>
</li>
<li><p>Observez pendant l’exécution l’activité des coeurs et des GPU</p></li>
<li><p>Notez le <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> et le <code class="docutils literal notranslate"><span class="pre">System</span> <span class="pre">Time</span></code></p></li>
<li><p>Effacez les résultats <code class="docutils literal notranslate"><span class="pre">test*</span></code> avec <code class="docutils literal notranslate"><span class="pre">rm</span> <span class="pre">test*</span></code></p></li>
<li><p>Déterminez, sachant que 4 tâches MPI simultanément, combien de <em>threads</em> lancer</p></li>
<li><p>Définissez ce nombre pour le système avec la fonction suivante :</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPTIMAL_THREADS=&lt;MonCHoixJudicieux&gt;</span></code></p></li>
</ul>
</li>
<li><p>Exécutez la commande <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">-x</span> <span class="pre">OMP_NUM_THREADS=$OPTIMAL_THREADS</span> <span class="pre">/local/$USER/GENESIS/cpu-single/bin/spdyn</span> <span class="pre">inp</span></code></p></li>
<li><p>Notez le <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> et le <code class="docutils literal notranslate"><span class="pre">System</span> <span class="pre">Time</span></code></p></li>
<li><p>Effacez les résultats <code class="docutils literal notranslate"><span class="pre">test*</span></code> avec <code class="docutils literal notranslate"><span class="pre">rm</span> <span class="pre">test*</span></code></p></li>
<li><p>Exécutez la commande <code class="docutils literal notranslate"><span class="pre">/usr/bin/time</span> <span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">-x</span> <span class="pre">OMP_NUM_THREADS=$OPTIMAL_THREADS</span> <span class="pre">/local/$USER/GENESIS/gpu-single/bin/spdyn</span> <span class="pre">inp</span></code></p></li>
<li><p>Notez le <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> et le <code class="docutils literal notranslate"><span class="pre">System</span> <span class="pre">Time</span></code></p></li>
<li><p>Concluez sur la pertinence de l’utilisation de l’option <code class="docutils literal notranslate"><span class="pre">-x</span> <span class="pre">OMP_NUM_THREADS=$OPTIMAL_THREADS</span></code></p></li>
</ul>
</div>
</section>
<section id="integration-et-exploitation-du-code-gromacs">
<h3>Intégration et exploitation du code Gromacs<a class="headerlink" href="#integration-et-exploitation-du-code-gromacs" title="Lien vers cette rubrique">¶</a></h3>
<p>Nous allons tenter de reproduire une <a class="reference external" href="https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/gromacs/">expérience de Nvidia</a> vantant l’efficacité des GPGPU pour le logiciel de <a class="reference external" href="https://fr.wikipedia.org/wiki/Dynamique_mol%C3%A9culaire">dynamique moléculaire</a> <a class="reference external" href="http://www.gromacs.org/">Gromacs</a>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #9.1 : appliquez la « recette » de Nvidia</strong></p>
<ul class="simple">
<li><p>La documentation offre ceci :
- récupérez le source
- étendez l’archive
- créez un dossier pour la construction
- passez dans ce dossier
- préparez la compilation
- compilez le code
- installez les exécutables</p></li>
<li><p>A quelle étape est-ce que cela bloque ? Quel message avez-vous ?</p></li>
<li><p>Trouvez une méthode permettant de régler ce problème.</p></li>
</ul>
</div>
<p>En cas de difficultés, appliquez la <a class="reference internal" href="gromacsGPU.html#gromacsgpu"><span class="std std-ref">recette de Gromacs pour Debian Buster</span></a> ;-)</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #9.2 : Exécutez l’exemple `1536`</strong></p>
<ul class="simple">
<li><p>Quel <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> avez-vous pour l’exécution sur GPU (et CPU) ?</p></li>
<li><p>Quel <code class="docutils literal notranslate"><span class="pre">Elapsed</span> <span class="pre">Time</span></code> avez-vous pour l’exécution uniquement sur CPU ?</p></li>
<li><p>Quel ratio de performances existe entre les deux exécutions ?</p></li>
</ul>
</div>
</section>
</section>
<section id="exploration-des-gpu-avec-un-pi-monte-carlo">
<h2>Exploration des GPU avec un Pi Monte Carlo<a class="headerlink" href="#exploration-des-gpu-avec-un-pi-monte-carlo" title="Lien vers cette rubrique">¶</a></h2>
<section id="le-pi-monte-carlo-ou-pi-dart-dash-un-code-compute-bound">
<h3>Le « Pi Monte Carlo » ou « Pi Dart Dash »,un code « compute bound »<a class="headerlink" href="#le-pi-monte-carlo-ou-pi-dart-dash-un-code-compute-bound" title="Lien vers cette rubrique">¶</a></h3>
<p>Le calcul de Pi par la  <a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo">méthode de Monte Carlo</a> est exemplaire à plusieurs titres :</p>
<ul class="simple">
<li><p>elle est simple : un générateur de nombres aléatoires, un mécanisme de test et un compteur suffisent</p></li>
<li><p>elle est parallélisable : en distribuant le nombre d’itérations sur les unités de calcul</p></li>
<li><p>elle est <em>compute bound</em> : en n’ayant quasiment aucun accès mémoire (reste dans les registres de calcul)</p></li>
<li><p>elle est cependant notoirement inefficace pour calculer Pi ;-)</p></li>
</ul>
<p>Les versions que vous allez utiliser exploitent de 2 à 4 paramètres en entrée :</p>
<ul class="simple">
<li><p>le nombre total d’itérations</p></li>
<li><p>le régime de Parallélisme (PR) : le <strong>découpage</strong> du travail vers les unités de traitement</p></li>
<li><p>le type de variables : INT32, INT64, FP32, FP64</p></li>
<li><p>le type de <em>Random Number Generator</em> : MWC, CONG, SHR3, KISS</p></li>
</ul>
<p>Intuitivement, le <strong>régime de parallélisme</strong> à explorer est optimal lorsqu’il correspond au nombre d’unités de traitement (<em>Compute Units</em>). Nous verrons que c’est un peu plus compliqué que cela.</p>
<p>Le type de variable va permettre de juger de l’efficacité des <em>Compute Units</em> en fonction des données qu’elles manipulent, notamment lorsque nous passons de 32 à 64 bits.</p>
<p>Le type de <em>RNG</em> a aussi son importance. Les <em>RNG</em> utilisés ici sont ceux de <a class="reference external" href="https://en.wikipedia.org/wiki/George_Marsaglia">Georges Marsaglia</a>. Comme tous les <em>RNG</em> pseudo-aléatoires, ils nécessitent une « graine », laquelle permet une reproductibilité des tirages. Voici leur code source, d’une effroyable efficacité compte-tenu de leur compacité.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#define znew  ((z=36969*(z&amp;65535)+(z&gt;&gt;16))&lt;&lt;16)</span>
<span class="c1">#define wnew  ((w=18000*(w&amp;65535)+(w&gt;&gt;16))&amp;65535)</span>
<span class="c1">#define MWC   (znew+wnew)</span>
<span class="c1">#define SHR3  (jsr=(jsr=(jsr=jsr|(jsr&lt;&lt;17))|(jsr&gt;&gt;13))|(jsr&lt;&lt;5))</span>
<span class="c1">#define CONG  (jcong=69069*jcong+1234567)</span>
<span class="c1">#define KISS  ((MWC|CONG)+SHR3)</span>
</pre></div>
</div>
<p>Comme nous divisons un nombre d’itérations entier par un régime de parallélisme, nous approximons dans le code le nombre d’itérations de chaque calcul élémentaire à l’entier supérieur. Lorsque le nombre d’itérations dépasse le milliard, le nombre d’itérations supplémentaires ne dépasse pas 7%.</p>
<p>Comme résultat, nous avons deux observables simples :</p>
<ul class="simple">
<li><p>une estimation de Pi : juste indicative, Pi n’étant pas rationnel
* par l’addition de tous les résultats sur le nombre total d’itérations que multiplie 4</p></li>
<li><p>le temps écoulé</p></li>
</ul>
<p>Pour évaluer une performance, il est toujours intéressant de choisir une métrique maximaliste : nous définissons le <strong>itops</strong> soit le <em>ITerative Operations Per Second</em> comme le rapport entre ce nombre total d’itérations et le temps écoulé.</p>
</section>
<section id="les-programmes-utilises-opencl-cuda">
<h3>Les programmes utilisés : OpenCL, CUDA<a class="headerlink" href="#les-programmes-utilises-opencl-cuda" title="Lien vers cette rubrique">¶</a></h3>
<p>Le dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu</span></code> contient de nombreuses implémentations de ce calcul élémentaire. Nous nous focaliserons sur 2 d’entre eux :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/OpenCL/PiOpenCL.c</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/XPU/PiXPU.py</span></code></p></li>
</ul>
</section>
<section id="implementation-c-opencl">
<h3>Implémentation C/OpenCL<a class="headerlink" href="#implementation-c-opencl" title="Lien vers cette rubrique">¶</a></h3>
<p>Le programme <code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/C/OpenCL/PiOpenCL.c</span></code> est une implémentation en C « pur » : il permet de juger de la difficulté d’appropriation de OpenCL. En effet, une grande partie du code est destinée à définir quelle plateforme et quel périphérique utiliser, placer les données à traîter.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.1 : exploration du code OpenCL</strong></p>
<ul class="simple">
<li><p>Repérez dans le programme source le <strong>noyau</strong> OpenCL réalisant le calcul</p></li>
<li><p>Repérez dans le programme source les parties <strong>découverte</strong> des périphériques</p></li>
<li><p>Repérez quel <em>RNG</em> est utilisé dans ce programme</p></li>
</ul>
</div>
<p>Le code se compile très simplement uniquement en appliquant la commande <code class="docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">-o</span> <span class="pre">PiOpenCL</span> <span class="pre">PiOpenCL.c</span> <span class="pre">-lOpenCL</span> <span class="pre">-lm</span></code>. L’exécutable <code class="docutils literal notranslate"><span class="pre">PiOpenCL</span></code> est prêt à être utilisé.</p>
<p>Son exécution sans paramètre ne fait qu’une « découverte » des périphériques OpenCL disponibles et présente la documentation. Par exemple :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Performs<span class="w"> </span>a<span class="w"> </span>Pi<span class="w"> </span>estimation<span class="w"> </span>by<span class="w"> </span>Dart<span class="w"> </span>Dash:

<span class="w">  </span><span class="c1">#1 OpenCL Plateform ID (default 0)</span>
<span class="w">  </span><span class="c1">#2 OpenCL Device ID (default 0)</span>
<span class="w">  </span><span class="c1">#3 Minimal number of iterations (default 1000000)</span>
<span class="w">  </span><span class="c1">#4 Parallel Rate (default 1024)</span>
<span class="w">  </span><span class="c1">#5 Loops (default 1)</span>
<span class="w">  </span><span class="c1">#6 Type of variable: INT32, INT64, FP32, FP64 (default FP32)</span>

OpenCL<span class="w"> </span>statistics:<span class="w"> </span><span class="m">4</span><span class="w"> </span>platform<span class="o">(</span>s<span class="o">)</span><span class="w"> </span>detected

Device<span class="w"> </span><span class="o">(</span><span class="m">0</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">  </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU
<span class="w">  </span>Device<span class="w"> </span>vendor:<span class="w"> </span>GenuineIntel
<span class="w">  </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>AMD-APP<span class="w"> </span><span class="o">(</span><span class="m">1912</span>.5<span class="o">)</span>
<span class="w">  </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">1912</span>.5<span class="w"> </span><span class="o">(</span>sse2,avx<span class="o">)</span>
<span class="w">  </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">  </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">1</span>,0<span class="o">)</span>:<span class="w"> </span>pthread-Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">  </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU<span class="w"> </span>CL_DEVICE_TYPE_DEFAULT
<span class="w">  </span>Device<span class="w"> </span>vendor:<span class="w"> </span>GenuineIntel
<span class="w">  </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span>pocl
<span class="w">  </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">0</span>.13
<span class="w">  </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">2</span>.0
<span class="w">  </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,0<span class="o">)</span>:<span class="w"> </span>GeForce<span class="w"> </span>GTX<span class="w"> </span><span class="m">1080</span><span class="w"> </span>Ti
<span class="w">  </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_GPU
<span class="w">  </span>Device<span class="w"> </span>vendor:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation
<span class="w">  </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>CUDA
<span class="w">  </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">384</span>.130
<span class="w">  </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">  </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">28</span>
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>
Device<span class="w"> </span><span class="o">(</span><span class="m">2</span>,1<span class="o">)</span>:<span class="w"> </span>Quadro<span class="w"> </span>K420
<span class="w">  </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_GPU
<span class="w">  </span>Device<span class="w"> </span>vendor:<span class="w"> </span>NVIDIA<span class="w"> </span>Corporation
<span class="w">  </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span>CUDA
<span class="w">  </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">384</span>.130
<span class="w">  </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">1</span>.2
<span class="w">  </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">1</span>
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>

Device<span class="w"> </span><span class="o">(</span><span class="m">3</span>,0<span class="o">)</span>:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Xeon<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>CPU<span class="w"> </span>E5-2637<span class="w"> </span>v4<span class="w"> </span>@<span class="w"> </span><span class="m">3</span>.50GHz
<span class="w">  </span>Device<span class="w"> </span>Type:<span class="w"> </span>CL_DEVICE_TYPE_CPU
<span class="w">  </span>Device<span class="w"> </span>vendor:<span class="w"> </span>Intel<span class="o">(</span>R<span class="o">)</span><span class="w"> </span>Corporation
<span class="w">  </span>Hardware<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span><span class="o">(</span>Build<span class="w"> </span><span class="m">25</span><span class="o">)</span>
<span class="w">  </span>Software<span class="w"> </span>version:<span class="w"> </span><span class="m">1</span>.2.0.25
<span class="w">  </span>OpenCL<span class="w"> </span>C<span class="w"> </span>version:<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">2</span>.0
<span class="w">  </span>Parallel<span class="w"> </span>compute<span class="w"> </span>units:<span class="w"> </span><span class="m">16</span>
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Group<span class="w"> </span>Size:<span class="w"> </span>-697485824
<span class="w">  </span>Maximum<span class="w"> </span>Work<span class="w"> </span>Item<span class="w"> </span>Sizes:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<p>Nous découvrons que 4 plates-formes sont détectées, servant 5 périphériques.</p>
<ul class="simple">
<li><p>les 3 implémentations CPU de OpenCL : celles d’AMD, de PortableCL et d’Intel</p></li>
<li><p>les 2 GPU Nvidia <strong>GTX 1080 Ti</strong> et <strong>Quadro K420</strong></p></li>
</ul>
<p>Cette sortie montre également les options (au moins 2) à entrer pour exploiter le programme :</p>
<ul class="simple">
<li><p>#1 l’identifiant de la plateforme</p></li>
<li><p>#2 l’identifiant du périphérique pour cette plateforme</p></li>
<li><p>#3 le nombre minimum d’itérations (par défaut 1000000)</p></li>
<li><p>#4 le régime de parallélisme PR (par défault 1024)</p></li>
<li><p>#5 le nombre de boucles (par défault 1) : bien utile pour évaluer la reproductibilité temporelle</p></li>
<li><p>#6 le type de variable: INT32, INT64, FP32, FP64 (par défault FP32)</p></li>
</ul>
<p>Il est donc nécessaire de préciser uniquement le tuple <code class="docutils literal notranslate"><span class="pre">(plateforme,périphérique)</span></code> pour exécuter le programme.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.2 : compilation et première exécution</strong></p>
<ul class="simple">
<li><p>Compilez le programme avec la ligne de compilation précisée ci-dessus</p></li>
<li><p>Exécutez le programme « à vide » et identifiez les périphériques</p></li>
<li><p>Exécutez le programme sur la première GPU Nvidia que vous avez repérée</p></li>
</ul>
</div>
<p>Avec ce premier outil, il est possible de juger de la différence fondamentale de performances entre GPU et CPU, en fonction du régime de parallélisme.</p>
<p>Par exemple, sur les périphériques ci-dessus :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>3.98</p></td>
<td><p>251524870</p></td>
<td><p>785423827</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>4.77</p></td>
<td><p>209512671</p></td>
<td><p>785423827</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>26.11</p></td>
<td><p>38299749</p></td>
<td><p>785423825</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>108.52</p></td>
<td><p>9214573</p></td>
<td><p>785423825</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>3.90</p></td>
<td><p>256424327</p></td>
<td><p>785423825</p></td>
</tr>
</tbody>
</table>
<img alt="Image opencluster2_qpu1" class="img-fluid center" src="../../_images/opencluster2_qpu1.png" />
<p>Il est assez intéressant que les implémentations CPU offrent quasiment la même performance. Par contre les GPU offrent une performance bien moindre (6x moins pour la GTX 1080 Ti et presque 30x moins pour la Quadro K420).</p>
<p>Il est aussi intéressant qu’étrange que le nombre de « coups » à l’intérieur du quadrant d’exploration ne soit pas le même pour toutes les implémentations. C’est un artéfact lié à la multiplication du <em>RNG</em> par la constante pour le placer entre 0 et 1.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.3 : exécution sur tous les périphériques pour un PR=1</strong></p>
<ul class="simple">
<li><p>Exécutez le programme sur toutes (GPU &amp; CPU) avec un nombre d’itérations de 1 milliard</p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et le <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio existe entre le ou les GPU et les processeurs ?</p></li>
</ul>
</div>
<p>Nous pouvons maintenant explorer la réponse des périphériques, notamment pour des régimes de parallélisme bien plus élevés, par exemple la valeur par défaut de <code class="docutils literal notranslate"><span class="pre">1024</span></code>. Nous portons par contre le nombre d’itérations à 10000000000, soit 10x plus que précédemment.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>4.28</p></td>
<td><p>2338471813</p></td>
<td><p>7853958701</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>24.23</p></td>
<td><p>412737304</p></td>
<td><p>7853958701</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>0.37</p></td>
<td><p>26864605077</p></td>
<td><p>7853958630</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>3.04</p></td>
<td><p>3287218047</p></td>
<td><p>7853958630</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>1.25</p></td>
<td><p>7973063801</p></td>
<td><p>7853958630</p></td>
</tr>
</tbody>
</table>
<img alt="Image opencluster2_qpu1024" class="img-fluid center" src="../../_images/opencluster2_qpu1024.png" />
<p>Cette seconde expérience montre de manière assez spectaculaire que les GPU ne dévoilent leur puissance « que » pour des régimes de parallélisme élevé. Notons aussi que les implémentations sur CPU ont des performances très très disparates.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.4 : exécution sur tous les périphériques pour un PR=1024</strong></p>
<ul class="simple">
<li><p>Exécutez le programme sur toutes (GPU &amp; CPU) avec un nombre d’itérations de 10 milliards</p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio existe entre le ou les GPU et les processeurs ?</p></li>
</ul>
</div>
<p>Dans l’expérience précédente, nous avons exploité un régime de parallélisme sur les processeurs très supérieur au nombre de <em>Compute Units</em>, lesquelles sont identifiées comme les coeurs. Il y avait 8 coeurs physiques et nous avons « chargé » chaque coeur à 256 fois leur charge. Que se passe-t-il si nous effectuons la même chose avec les GPU ?</p>
<p>Dans notre exemple, la GTX 1080 Ti dispose de 3584 <em>cuda cores</em>. La Quadro K420 de 192 <em>cuda cores</em>. Explorons ces périphériques avec des  <strong>PR</strong> de 256x ces valeurs (nous sommes obligés de porter les itérations à 1000 milliards) :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Durée</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>3.77</p></td>
<td><p>265583420021</p></td>
<td><p>785397498152</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro K420</p></td>
<td><p>290.03</p></td>
<td><p>3447937882</p></td>
<td><p>785398065372</p></td>
</tr>
</tbody>
</table>
<img alt="Image opencluster2_epu" class="img-fluid center" src="../../_images/opencluster2_epu.png" />
<p>Ce graphique montre sans ambiguité la puissance « brute » qu’offre une GPU de gamer en comparaison de CPU traditionnelle (33x dans la meilleure implémentation CPU, celle d’Intel). Notons également que GPU n’est pas synonyme de puissance brute : la « petite » Quadro K420, bien que « professionnelle » présente des performances 77x inférieures.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.5 : exécution sur tous les périphériques pour un PR optimal</strong></p>
<ul class="simple">
<li><p>Reprenez les spécifications des GPU et isolez le nombre de <em>cuda cores</em></p></li>
<li><p>Exécutez le programme sur les GPU avec un nombre d’itérations de 100 milliards et un PR de 256x le nombre de <em>cuda cores</em></p></li>
<li><p>Repérez les éléments de <strong>durée</strong>, <strong>itops</strong> et <strong>inside</strong></p></li>
<li><p>Tracez l’histogramme correspondant aux performances sur le modèle ci-dessus</p></li>
<li><p>Quel ratio de performance existe entre la GPU la plus puissante et la meilleure implémentation des CPU ?</p></li>
</ul>
</div>
<p>Nous avons déjà noté, dans l’exploitation de <code class="docutils literal notranslate"><span class="pre">xGEMM</span></code> que les performances pour les GPU étaient largement influencées par la précision utilisée pour les calculs.</p>
<p>Pour les mêmes périphériques mais en passant en double précision, nous avons :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Elapsed</p></th>
<th class="head"><p>Itops</p></th>
<th class="head"><p>Inside</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>4.05</p></td>
<td><p>2472082769</p></td>
<td><p>7853958184</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>18.89</p></td>
<td><p>529471467</p></td>
<td><p>7853958184</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>3.34</p></td>
<td><p>29909278511</p></td>
<td><p>78540290903</p></td>
</tr>
<tr class="row-odd"><td><p>QuadroK420</p></td>
<td><p>12.52</p></td>
<td><p>798857983</p></td>
<td><p>7854068741</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>16.24</p></td>
<td><p>6156907937</p></td>
<td><p>78539995659</p></td>
</tr>
</tbody>
</table>
<img alt="Image piopencl_dp" class="img-fluid center" src="../../_images/piopencl_dp.png" />
<p>Nous avons présenté dans le cours qu’un mauvais choix de régime de parallélisme pouvait largement influencer la performance.</p>
<p>Par exemple, regardons pour la meilleure implémentation de CPU et pour la GPU la plus puissante, quelle influence a le choix du régime de parallélisme autour du régime de parallélisme optimal.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #10.6 : exécution sur tous les périphériques pour un PR optimal en double précision</strong></p>
<ul class="simple">
<li><p>Reprenez les expériences ci-dessus en précisant un calcul en double précision</p></li>
<li><p>Tracez l’histogramme avec tous les périphériques OpenCL</p></li>
<li><p>Quel ratio de performance existe entre la GPU la plus puissante et la meilleure implémentation des CPU ?</p></li>
</ul>
</div>
</section>
<section id="implementation-python-opencl-python-cuda">
<h3>Implémentation Python/OpenCL Python/CUDA<a class="headerlink" href="#implementation-python-opencl-python-cuda" title="Lien vers cette rubrique">¶</a></h3>
<p>Dans l’exemple précédent, nous avons exploité un programme en C « pur ». Nous avons vu comment s’intégrait la portion de code (le noyau ou le <em>kernel</em>) qui était exécutée, soit par les GPU, soit par différentes implémentations pour CPU de OpenCL. Nous avons aussi pu « juger » du côté assez « compliqué » de découvertes des périphériques et des mécanismes d’entrée/sortie.</p>
<p>Avec le programme <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code>, situé dans le dossier <code class="docutils literal notranslate"><span class="pre">bench4gpu/Pi/XPU</span></code> nous allons pouvoir exploiter les périphériques de calcul plus simplement, et bénéficier de toutes les facilités d’un langage évolué.</p>
<p>Regardons d’abord sa sortie lorsqu’il est sollicité avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>/bench4gpu/Pi/XPU
$<span class="w"> </span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-h
PiXPU.py<span class="w"> </span>-o<span class="w"> </span><span class="o">(</span>Out<span class="w"> </span>of<span class="w"> </span>Core<span class="w"> </span>Metrology<span class="o">)</span><span class="w"> </span>-c<span class="w"> </span><span class="o">(</span>Print<span class="w"> </span>Curves<span class="o">)</span><span class="w"> </span>-k<span class="w"> </span><span class="o">(</span>Case<span class="w"> </span>On<span class="w"> </span>IfThen<span class="o">)</span><span class="w"> </span>-d<span class="w"> </span>&lt;DeviceId&gt;<span class="w"> </span>-g<span class="w"> </span>&lt;CUDA/OpenCL&gt;<span class="w"> </span>-i<span class="w"> </span>&lt;Iterations&gt;<span class="w"> </span>-b<span class="w"> </span>&lt;BlocksBegin&gt;<span class="w"> </span>-e<span class="w"> </span>&lt;BlocksEnd&gt;<span class="w"> </span>-s<span class="w"> </span>&lt;BlocksStep&gt;<span class="w"> </span>-f<span class="w"> </span>&lt;ThreadsFirst&gt;<span class="w"> </span>-l<span class="w"> </span>&lt;ThreadsLast&gt;<span class="w"> </span>-t<span class="w"> </span>&lt;ThreadssTep&gt;<span class="w"> </span>-r<span class="w"> </span>&lt;RedoToImproveStats&gt;<span class="w"> </span>-m<span class="w"> </span>&lt;SHR3/CONG/MWC/KISS&gt;<span class="w"> </span>-v<span class="w"> </span>&lt;INT32/INT64/FP32/FP64&gt;

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>OpenCL<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>CUDA<span class="w"> </span>API:
Device<span class="w"> </span><span class="c1">#0 of type GPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#1 of type GPU : Quadro K420</span>
</pre></div>
</div>
<p>Nous disposons de plus d’options pour le lancement. Ce programme étant un programme de test de performances, il permet une exploration de régimes de parallélisme. Dans les approches de programmation CUDA ou OpenCL, il y a deux étages de parallélisme :</p>
<ul class="simple">
<li><p>le premier pour des tâches indépendantes : <em>Blocks</em> et <em>Work items</em> en sont les éléments</p></li>
<li><p>le second pour des tâches nécessitant une synchronisation : ce sont les <em>Threads</em></p></li>
</ul>
<p>Il y a donc, pour explorer ces deux régimes de parallélisme, 6 options différentes :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">&lt;BlocksBegin&gt;</span></code>  : le premier nombre de <em>Work items</em> ou de <em>Blocks</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">&lt;BlocksEnd&gt;</span></code>    : le dernier nombre de <em>Work items</em> ou de <em>Blocks</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">&lt;BlocksStep&gt;</span></code>   : le pas entre deux <em>Work items</em> ou de <em>Blocks</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">&lt;ThreadsFirst&gt;</span></code> : le premier nombre de <em>Threads</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-l</span> <span class="pre">&lt;ThreadsLast&gt;</span></code>  : le dernier nombre de <em>Threads</em> à explorer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">&lt;ThreadssTep&gt;</span></code>  : le pas entre deux <em>Threads</em> à explorer</p></li>
</ul>
<p>Il est aussi possible de coupler les deux régimes de parallélisme en appelant 16 <em>work items</em> avec 16 <em>threads</em>.</p>
<p>Par exemple, pour explorer des régimes de parallélisme de 16 à 128 avec des pas de 16 en <em>Work items</em> et 4 à 8 en <em>Threads</em> avec des pas unitaires, nous aurons <code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">16</span> <span class="pre">-e</span> <span class="pre">128</span> <span class="pre">-s</span> <span class="pre">16</span> <span class="pre">-f</span> <span class="pre">4</span> <span class="pre">-l</span> <span class="pre">8</span> <span class="pre">-t</span> <span class="pre">1</span> <span class="pre">-p</span> <span class="pre">2</span></code>.</p>
<p>D’autres options :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">&lt;CUDA/OpenCL&gt;</span></code> : pour sélectionner l’utilisation de CUDA ou OpenCL</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span> <span class="pre">&lt;Iterations&gt;</span></code> : pour le nombre total d’itérations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-r</span> <span class="pre">&lt;RedoToImproveStats&gt;</span></code> : pour refaire plusieurs expériences en série</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-m</span> <span class="pre">&lt;SHR3/CONG/MWC/KISS&gt;</span></code> : pour sélectionner le type de <em>Random Number Generator</em> de Marsaglia</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">&lt;INT32/INT64/FP32/FP64&gt;</span></code> : pour sélectionner le type de variable à exploiter</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-k</span> <span class="pre">(Case</span> <span class="pre">On</span> <span class="pre">IfThen)</span></code> : pour forcer l’exploitation du test avec un mécanisme en <code class="docutils literal notranslate"><span class="pre">IfThen</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">&lt;DeviceId&gt;</span></code> : pour sélectionner le périphérique en utilisant l’ID fourni avec le <code class="docutils literal notranslate"><span class="pre">-h</span></code></p></li>
</ul>
<p>L’appel du programme ci-dessus nous montre qu’il y a le même nombre de périphériques OpenCL visibles (les 3 implémentations OpenCL pour CPU et les 2 GPU Nvidia), la nouveauté est que nous voyons également deux périphériques CUDA.</p>
<p>En sortie, lors d’un appel simple ne précisant que le périphérique, ici le premier, <code class="docutils literal notranslate"><span class="pre">#0</span></code>, nous avons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span>
Devices<span class="w"> </span>Identification<span class="w"> </span>:<span class="w"> </span><span class="o">[</span><span class="m">0</span><span class="o">]</span>
GpuStyle<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>OpenCL
Iterations<span class="w"> </span>:<span class="w"> </span><span class="m">10000000</span>
Number<span class="w"> </span>of<span class="w"> </span>Blocks<span class="w"> </span>on<span class="w"> </span>begin<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Blocks<span class="w"> </span>on<span class="w"> </span>end<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Step<span class="w"> </span>on<span class="w"> </span>Blocks<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Threads<span class="w"> </span>on<span class="w"> </span>begin<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>Threads<span class="w"> </span>on<span class="w"> </span>end<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Step<span class="w"> </span>on<span class="w"> </span>Threads<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Number<span class="w"> </span>of<span class="w"> </span>redo<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>
Metrology<span class="w"> </span><span class="k">done</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span>XPU<span class="w"> </span>:<span class="w"> </span>False
Type<span class="w"> </span>of<span class="w"> </span>Marsaglia<span class="w"> </span>RNG<span class="w"> </span>used<span class="w"> </span>:<span class="w"> </span>MWC
Type<span class="w"> </span>of<span class="w"> </span>variable<span class="w"> </span>:<span class="w"> </span>FP32
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
<span class="o">([</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span><span class="o">{</span><span class="m">0</span>:<span class="w"> </span><span class="s1">&#39;xPU&#39;</span><span class="o">})</span>
<span class="o">(</span><span class="s1">&#39;Inside &#39;</span>,<span class="w"> </span><span class="o">{</span><span class="s1">&#39;Blocks&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;ValueType&#39;</span>:<span class="w"> </span><span class="s1">&#39;FP32&#39;</span>,<span class="w"> </span><span class="s1">&#39;RNG&#39;</span>:<span class="w"> </span><span class="s1">&#39;MWC&#39;</span>,<span class="w"> </span><span class="s1">&#39;Threads&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;Iterations&#39;</span>:<span class="w"> </span><span class="m">10000000</span>,<span class="w"> </span><span class="s1">&#39;Device&#39;</span>:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="s1">&#39;Steps&#39;</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">&#39;IfThen&#39;</span>:<span class="w"> </span>False<span class="o">})</span>
<span class="o">(</span><span class="s1">&#39;CPU/GPU selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz&#39;</span><span class="o">)</span>
<span class="o">(</span>Blocks/Threads<span class="o">)=(</span><span class="m">1</span>,1<span class="o">)</span><span class="w"> </span>method<span class="w"> </span><span class="k">done</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.06<span class="w"> </span>s...
<span class="o">{</span><span class="s1">&#39;Duration&#39;</span>:<span class="w"> </span>array<span class="o">([</span><span class="m">0</span>.06270599<span class="o">])</span>,<span class="w"> </span><span class="s1">&#39;Inside&#39;</span>:<span class="w"> </span><span class="m">7852019</span>.0,<span class="w"> </span><span class="s1">&#39;NewIterations&#39;</span>:<span class="w"> </span><span class="m">10000000</span><span class="o">}</span>
Pi<span class="w"> </span>estimation<span class="w"> </span><span class="m">3</span>.14080760
<span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">0</span>.06<span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">159474388</span><span class="w"> </span><span class="m">159474388</span>
</pre></div>
</div>
<p>Deux fichiers de sortie sont créés et reprennent dans leur titre les paramètres d’entrée :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_1_1_1_10000000_Device0_InMetro_opencluster2</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_1_1_1_10000000_Device0_InMetro_opencluster2.npz</span></code></p></li>
</ul>
<p>Le premier est uniquement lisible avec Python, le second est utilisable directement, pas exemple avec GNUplot.</p>
<section id="examen-du-code-source">
<h4>Examen du code source<a class="headerlink" href="#examen-du-code-source" title="Lien vers cette rubrique">¶</a></h4>
<div class="note note-warning docutils container">
<p><strong>Exercice #11.1 : récupération des éléments dans le code source</strong></p>
<ul class="simple">
<li><p>Editez le code source avec l’outil <code class="docutils literal notranslate"><span class="pre">gedit</span></code></p></li>
<li><p>Identifiez l’appel de la procédure principale OpenCL : ligne</p></li>
<li><p>Identifiez la zone de code de cette procédure OpenCL : lignes</p></li>
<li><p>Examinez dans cette procédure la <strong>construction</strong> du noyau OpenCL : ligne</p></li>
<li><p>Examinez dans cette procédure l”<strong>appel</strong> du noyau OpenCL : ligne</p></li>
<li><p>Identifiez le noyau OpenCL appelé par cette procédure : lignes</p></li>
<li><p>Identifiez l’appel de la procédure principale CUDA : ligne</p></li>
<li><p>Identifiez la zone de code de cette procédure CUDA : lignes</p></li>
<li><p>Identifiez le noyau CUDA appelé par cette procédure : lignes</p></li>
<li><p>Examinez dans cette procédure la <strong>construction</strong> du noyau CUDA : ligne</p></li>
<li><p>Examinez dans cette procédure l”<strong>appel</strong> du noyau CUDA : ligne</p></li>
<li><p>Quelles similarités distinguez-vous entre les noyaux OpenCL et CUDA ?</p></li>
</ul>
</div>
</section>
</section>
<section id="exploitation-du-programme">
<h3>Exploitation du programme<a class="headerlink" href="#exploitation-du-programme" title="Lien vers cette rubrique">¶</a></h3>
<p>Ainsi, si nous voulons étudier la scalabilité du CPU en <em>Work items</em> de 1 à 16x le nombre de coeurs (ici 8 physiques) en exploitant l’implémentation AMD de OpenCL, nous appelons la commande :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="m">1</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">8</span><span class="o">*</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">10</span><span class="w"> </span>-i<span class="w"> </span><span class="m">1000000000</span>
</pre></div>
</div>
<p>Dans notre cas, nous avons les deux fichiers suivants à exploiter :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2.npz</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2</span></code></p></li>
</ul>
<p>Nous pouvons ensuite exploiter l’outil simple <code class="docutils literal notranslate"><span class="pre">gnuplot</span></code> pour afficher nos résultats :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>gnuplot
<span class="nb">set</span><span class="w"> </span>xlabel<span class="w"> </span><span class="s1">&#39;Parallel Rate&#39;</span>
<span class="nb">set</span><span class="w"> </span>ylabel<span class="w"> </span><span class="s1">&#39;Itops&#39;</span>
<span class="nb">set</span><span class="w"> </span>yrange<span class="w"> </span><span class="o">[</span><span class="m">0</span>:*<span class="o">]</span>
plot<span class="w"> </span><span class="s1">&#39;Pi_FP32_MWC_xPU_OpenCL_1_128_1_1_1000000000_Device0_InMetro_opencluster2&#39;</span><span class="w"> </span>using<span class="w"> </span><span class="m">1</span>:9<span class="w"> </span>title<span class="w"> </span><span class="s1">&#39;OpenCL AMD&#39;</span>
</pre></div>
</div>
<p>Il existe un bouton d’export du graphique en image au format PNG ou SVG. Nous obtenons le suivant :</p>
<img alt="Image amd_opencluster2_insa" class="img-fluid center" src="../../_images/amd_opencluster2_insa.png" />
<p>Nous observons que la scalabilité pour un code aussi simple n’est pas si triviale que cela à analyser. Il n’y a pas continuité en fonction de PR croissant. Notons une pseudo-période correspondant au nombre de coeurs physiques, avec des maximums locaux pour les multiples de cette valeur (le <em>handsaw curve effect</em>).</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #11.2 : étude de la scalabilité d’une implémentation CPU</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> un périphérique CPU</p></li>
<li><p>Exécutez le d’un PR=1 à un PR égal à 8x le nombre de coeurs physiques</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
</ul>
</div>
<p>Nous pouvons également « explorer » la scalabilité des GPU forts de notre expérience de <code class="docutils literal notranslate"><span class="pre">PiOpenCL</span></code>. Par exemple, du nombre de <em>cuda cores</em> à ce nombre multiplié par 16, par pas de 128. La commande appelée est la suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">2</span><span class="w"> </span>-b<span class="w"> </span><span class="m">3584</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">8</span><span class="k">))</span><span class="w"> </span>-s<span class="w"> </span><span class="m">128</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">100000000000</span>
</pre></div>
</div>
<p>Nous obtenons pour notre GTX 1080 Ti les résultats suivants :</p>
<img alt="Image gtx1080ti_opencluster2_insa" class="img-fluid center" src="../../_images/gtx1080ti_opencluster2_insa.png" />
<p>Nous pouvons constater que la scalabilité est très peu continue, encore moins que pour la scalabilité étudiée des CPU. Nous constatons également que des pseudo-lignes se chevauchent. Le PR optimal était autour de 4x le nombre de <em>cuda cores</em> et offrait une performance de <strong>268 Gitops</strong>.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #11.3 : étude de la scalabilité d’une GPU</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> un périphérique GPU</p></li>
<li><p>Exécutez-le d’un PR=&lt;NbCudaCores&gt; à un PR égal à 8x&lt;NbCudaCores&gt; par pas de 128 en OpenCL</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
<li><p>Identifiez pour quel PR la performance est maximale</p></li>
</ul>
</div>
<p>Comme nous avons également la même implémentation en CUDA, lançons l’exploration avec CUDA pour le PR optimal, ici identifié à 4x le nombre de <em>cuda cores</em> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-g<span class="w"> </span>CUDA<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">10000000000</span>
</pre></div>
</div>
<p>Comme résultat de cette implémentation CUDA, nous n’obtenons pas <strong>268 Gitops</strong>, mais seulement <strong>6 Gitops</strong> !</p>
<p>La seule manière de retrouver une performance comparable en CUDA est de solliciter le second étage de parallélisme des GPU, les <em>Threads</em>. Avec la commande suivante, avec 1024 Threads, nous plafonnons à <strong>198 Gitops</strong> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-g<span class="w"> </span>CUDA<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="k">))</span><span class="w"> </span>-f<span class="w"> </span><span class="m">1024</span><span class="w"> </span>-l<span class="w"> </span><span class="m">1024</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">1000000000000</span>
</pre></div>
</div>
<p>En relançant le calcul précédent, nous parvenons à <strong>271 Gitops</strong> soit plus que l’implémentation OpenCL.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #11.4 : étude de l’implémentation CUDA autour du PR optimal</strong></p>
<ul class="simple">
<li><p>Identifiez avec <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">PiXPU.py</span> <span class="pre">-h</span></code> le périphérique GPU déjà utilisé en CUDA</p></li>
<li><p>Exécutez le avec le PR optimal des <em>Blocks</em> en CUDA</p></li>
<li><p>Quel ratio de performance avez-vous entre CUDA et OpenCL ?</p></li>
<li><p>Exécutez le avec le PR optimal des <em>Blocks</em> et 1024 <em>Threads</em></p></li>
<li><p>Quel ratio de performance avez-vous entre CUDA et OpenCL ?</p></li>
</ul>
</div>
<p>Il existe aussi des artéfacts sur des régimes de parallélisme spéciaux en OpenCL sur les GPU Nvidia : en explorant autour du PR optimal, quelles sont les PR qu’il ne faut surtout pas exploiter et quel est leur point commun ?</p>
<p>En lançant cette exploration suivante, nous obtenons :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>PiXPU.py<span class="w"> </span>-d<span class="w"> </span><span class="m">2</span><span class="w"> </span>-b<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="o">-</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-e<span class="w"> </span><span class="k">$((</span><span class="m">3584</span><span class="o">*</span><span class="m">4</span><span class="o">+</span><span class="m">16</span><span class="k">))</span><span class="w"> </span>-r<span class="w"> </span><span class="m">3</span><span class="w"> </span>-i<span class="w"> </span><span class="m">100000000000</span>
</pre></div>
</div>
<img alt="Image gtx1080ti_aroundepu_opencluster2_insa" class="img-fluid center" src="../../_images/gtx1080ti_aroundepu_opencluster2_insa.png" />
<p>Alors que l’optimum de performance est atteint autour d’un PR de 14336 avec <strong>258 Gitops</strong>, nous n’obtenons un Itops que de <strong>8.5 Gitops</strong> (soit 30x moins) sur 5 valeurs particulières : 14321, 14323, 14327, 14341, 14347. Le point commun entre ces valeurs de PR est à rechercher sur le site <a class="reference external" href="http://www.math.com/students/calculators/source/prime-number.htm">de mathématiques</a></p>
<div class="note note-warning docutils container">
<p><strong>Exercice #11.4 : étude de valeurs particulières de PR</strong></p>
<ul class="simple">
<li><p>Exécutez <code class="docutils literal notranslate"><span class="pre">PiXPU.py</span></code> autour du PR égal à 4x le nombre de <em>cuda cores</em> (16 avant et 16 après)</p></li>
<li><p>Tracez les résultats avec GNUplot</p></li>
<li><p>Quels sont les PR avec les performances les plus faibles ?</p></li>
</ul>
</div>
</section>
</section>
<section id="exploration-par-un-corps-n-corps-a-grain-fin">
<h2>Exploration par un corps N-Corps à « grain fin »<a class="headerlink" href="#exploration-par-un-corps-n-corps-a-grain-fin" title="Lien vers cette rubrique">¶</a></h2>
<p>Le code de test <strong>Pi Monte Carlo</strong> avait pour avantage de ne solliciter que très peu la mémoire. La seule mémoire sollicitée sur les périphériques se résumait au nombre de tirages dans le quadrant de cercle. De plus, l’opération de parallélisation divisait un nombre total d’itérations en un nombre équivalent pour chaque <em>work item</em>, chaque <em>block</em> ou chaque <em>thread</em>. Chaque calcul était indépendant des autres : nous avions non seulement un <strong>code ALU</strong> (ne sollicitant que les unités de traitement) mais aussi un <strong>code gros grain</strong> (indépendance des calculs).</p>
<p>Dans le code <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code>, situé dans <code class="docutils literal notranslate"><span class="pre">bench4gpu/NBody</span></code>, le principe est de déterminer dans un modèle newtonien la position et la vitesse de chaque particule en intéraction avec toutes les autres. A chaque itération, chaque position et chaque vitesse de chaque particule vont être modifiées par la proximité de toutes les autres : nous disposons d’un <strong>code grain fin</strong>. De plus, la détermination de la vitesse et la position de chaque particule à chaque instant nécessite un accès à la position de chacune des autres : un accès permanent à la mémoire est donc indispensable.</p>
<p>Le programme <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code> n’est disponible qu’en OpenCL. Son invocation avec l’option <code class="docutils literal notranslate"><span class="pre">-h</span></code> offre la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>/bench4gpu/NBody
$<span class="w"> </span>python3<span class="w"> </span>NBody.py<span class="w"> </span>-h
NBody.py<span class="w"> </span>-h<span class="w"> </span><span class="o">[</span>Help<span class="o">]</span><span class="w"> </span>-r<span class="w"> </span><span class="o">[</span>InitialRandom<span class="o">]</span><span class="w"> </span>-g<span class="w"> </span><span class="o">[</span>OpenGL<span class="o">]</span><span class="w"> </span>-e<span class="w"> </span><span class="o">[</span>VirielStress<span class="o">]</span><span class="w"> </span>-o<span class="w"> </span><span class="o">[</span>Verbose<span class="o">]</span><span class="w"> </span>-p<span class="w"> </span><span class="o">[</span>Potential<span class="o">]</span><span class="w"> </span>-x<span class="w"> </span>&lt;None<span class="p">|</span>NegExp<span class="p">|</span>CorRad&gt;<span class="w"> </span>-d<span class="w"> </span>&lt;DeviceId&gt;<span class="w"> </span>-n<span class="w"> </span>&lt;NumberOfParticules&gt;<span class="w"> </span>-i<span class="w"> </span>&lt;Iterations&gt;<span class="w"> </span>-z<span class="w"> </span>&lt;SizeOfBoxOrBall&gt;<span class="w"> </span>-v<span class="w"> </span>&lt;Velocity&gt;<span class="w"> </span>-s<span class="w"> </span>&lt;Step&gt;<span class="w"> </span>-b<span class="w"> </span>&lt;Ball<span class="p">|</span>Box&gt;<span class="w"> </span>-m<span class="w"> </span>&lt;ImplicitEuler<span class="p">|</span>RungeKutta<span class="p">|</span>ExplicitEuler<span class="p">|</span>Heun&gt;<span class="w"> </span>-t<span class="w"> </span>&lt;FP32<span class="p">|</span>FP64&gt;

Informations<span class="w"> </span>about<span class="w"> </span>devices<span class="w"> </span>detected<span class="w"> </span>under<span class="w"> </span>OpenCL:
Device<span class="w"> </span><span class="c1">#0 from Advanced Micro Devices, Inc. of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#1 from The pocl project of type xPU : pthread-Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
Device<span class="w"> </span><span class="c1">#2 from NVIDIA Corporation of type xPU : GeForce GTX 1080 Ti</span>
Device<span class="w"> </span><span class="c1">#3 from NVIDIA Corporation of type xPU : Quadro K420</span>
Device<span class="w"> </span><span class="c1">#4 from Intel(R) Corporation of type xPU : Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz</span>
</pre></div>
</div>
<p>Un certain nombre des paramètres sont à définir avec une valeur :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">&lt;DeviceId&gt;</span></code> : sélection du périphérique (défaut <strong>0</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-n</span> <span class="pre">&lt;NumberOfParticules&gt;</span></code> : nombre de particules du système (défaut <strong>2</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">&lt;Step&gt;</span></code> : pas d’intégration (défaut <strong>1/32</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-m</span> <span class="pre">&lt;ImplicitEuler|RungeKutta|ExplicitEuler|Heun&gt;</span></code> : type d’intégration différentielle (défaut <strong>ImplicitEuler</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">&lt;FP32|FP64&gt;</span></code> : précision de calcul (défaut <strong>FP32</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span> <span class="pre">&lt;Iterations&gt;</span></code> : nombre d’itérations (défaut <strong>10</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-x</span> <span class="pre">&lt;None|NegExp|CorRad&gt;</span></code> : introduction d’un « rayon de coeur » pour éviter les divergences (défaut <strong>None</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-z</span> <span class="pre">&lt;SizeOfBoxOrBall&gt;</span></code> : taille de la boîte ou de la boule (défaut <strong>sqrt(2)</strong>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">&lt;Velocity&gt;</span></code> : vitesse initiale des particules (défaut définie par le Viriel)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">&lt;Ball|Box&gt;</span></code> : type de distribution aléatoire (défaut <strong>Ball</strong>)</p></li>
</ul>
<p>D’autres sont des booléens :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h</span> <span class="pre">[Help]</span></code> : la sortie précédente</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-r</span> <span class="pre">[InitialRandom]</span></code> : défaut</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">[OpenGL]</span></code> : pour une sortie graphique</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">[VirielStress]</span></code> : par défaut</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">[Verbose]</span></code> : impression position et vitesse des particules</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">[Potential]</span></code> : exploitation du potentiel à la place de la force</p></li>
</ul>
<p>Par défaut, une invocation sans option offre la sortie suivante :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>NBody.py
<span class="w"> </span>Device<span class="w"> </span>choosed<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>
<span class="w"> </span>Number<span class="w"> </span>of<span class="w"> </span>particules<span class="w"> </span>:<span class="w"> </span><span class="m">2</span>
<span class="w"> </span>Size<span class="w"> </span>of<span class="w"> </span>Shape<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.4142135
<span class="w"> </span>Initial<span class="w"> </span>velocity<span class="w"> </span>:<span class="w"> </span><span class="m">1</span>.0
<span class="w"> </span>Step<span class="w"> </span>of<span class="w"> </span>iteration<span class="w"> </span>:<span class="w"> </span><span class="m">0</span>.03125
<span class="w"> </span>Number<span class="w"> </span>of<span class="w"> </span>iterations<span class="w"> </span>:<span class="w"> </span><span class="m">10</span>
<span class="w"> </span>Method<span class="w"> </span>of<span class="w"> </span>resolution<span class="w"> </span>:<span class="w"> </span>ImplicitEuler
<span class="w"> </span>Initial<span class="w"> </span>Random<span class="w"> </span><span class="k">for</span><span class="w"> </span>RNG<span class="w"> </span>Seed<span class="w"> </span>:<span class="w"> </span>False
<span class="w"> </span>ValueType<span class="w"> </span>is<span class="w"> </span>:<span class="w"> </span>FP32
<span class="w"> </span>Viriel<span class="w"> </span>distribution<span class="w"> </span>of<span class="w"> </span>stress<span class="w"> </span>:<span class="w"> </span>True
<span class="w"> </span>OpenGL<span class="w"> </span>real<span class="w"> </span><span class="nb">time</span><span class="w"> </span>rendering<span class="w"> </span>:<span class="w"> </span>False
<span class="w"> </span>Speed<span class="w"> </span>rendering<span class="w"> </span>:<span class="w"> </span>False
<span class="w"> </span>Interaction<span class="w"> </span><span class="nb">type</span><span class="w"> </span>:<span class="w"> </span>Force
<span class="w"> </span>Counter<span class="w"> </span>Artevasion<span class="w"> </span><span class="nb">type</span><span class="w"> </span>:<span class="w"> </span>None
<span class="w"> </span><span class="o">(</span><span class="s1">&#39;CPU/GPU selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;Intel(R) Xeon(R) CPU E5-2637 v4 @ 3.50GHz&#39;</span><span class="o">)</span>
<span class="w"> </span><span class="o">(</span><span class="s1">&#39;Platform selected: &#39;</span>,<span class="w"> </span><span class="s1">&#39;AMD Accelerated Parallel Processing&#39;</span><span class="o">)</span>
<span class="w"> </span>/usr/lib/python2.7/dist-packages/pyopencl/cffi_cl.py:1470:<span class="w"> </span>CompilerWarning:<span class="w"> </span>Non-empty<span class="w"> </span>compiler<span class="w"> </span>output<span class="w"> </span>encountered.<span class="w"> </span>Set<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">PYOPENCL_COMPILER_OUTPUT</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>to<span class="w"> </span>see<span class="w"> </span>more.
<span class="w">   </span><span class="s2">&quot;to see more.&quot;</span>,<span class="w"> </span>CompilerWarning<span class="o">)</span>
<span class="w"> </span>All<span class="w"> </span>particles<span class="w"> </span>superimposed.
<span class="w"> </span>All<span class="w"> </span>particules<span class="w"> </span>distributed
<span class="w"> </span>Center<span class="w"> </span>Of<span class="w"> </span>Mass<span class="w"> </span>estimated:<span class="w"> </span><span class="o">(</span>-0.05390843,0.25029457,-0.0005747825<span class="o">)</span>
<span class="w"> </span>All<span class="w"> </span>particules<span class="w"> </span>stressed
<span class="w"> </span>Energy<span class="w"> </span>estimated:<span class="w"> </span><span class="nv">Viriel</span><span class="o">=</span>-5.960464477539063e-08<span class="w"> </span><span class="nv">Potential</span><span class="o">=</span>-0.94194394<span class="w"> </span><span class="nv">Kinetic</span><span class="o">=</span><span class="m">0</span>.47097194

<span class="w"> </span>Starting!
<span class="w"> </span>..........
<span class="w"> </span>Ending!

<span class="w"> </span>Center<span class="w"> </span>Of<span class="w"> </span>Mass<span class="w"> </span>estimated:<span class="w"> </span><span class="o">(</span>-0.05390393,0.25027496,-0.00055484474<span class="o">)</span>
<span class="w"> </span>Energy<span class="w"> </span>estimated:<span class="w"> </span><span class="nv">Viriel</span><span class="o">=</span>-2.7835369110107422e-05<span class="w"> </span><span class="nv">Potential</span><span class="o">=</span>-0.94973665<span class="w"> </span><span class="nv">Kinetic</span><span class="o">=</span><span class="m">0</span>.4748544

<span class="w"> </span>Duration<span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">   </span>Mean:<span class="w">       </span><span class="m">0</span>.0017527103424072265
<span class="w">   </span>Median:<span class="w">     </span><span class="m">0</span>.00153350830078125
<span class="w">   </span>Stddev:<span class="w">     </span><span class="m">0</span>.0007242915279449818
<span class="w">   </span>Min:<span class="w">        </span><span class="m">0</span>.0013959407806396484
<span class="w">   </span>Max:<span class="w">        </span><span class="m">0</span>.0039031505584716797

<span class="w">   </span>Variability:<span class="w">        </span><span class="m">0</span>.4723101450288789

<span class="w"> </span>FPS<span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">   </span>Mean:<span class="w">       </span><span class="m">623</span>.2326583734787
<span class="w">   </span>Median:<span class="w">     </span><span class="m">653</span>.6473926380554
<span class="w">   </span>Stddev:<span class="w">     </span><span class="m">130</span>.28936462458745
<span class="w">   </span>Min:<span class="w">        </span><span class="m">256</span>.2032862989432
<span class="w">   </span>Max:<span class="w">        </span><span class="m">716</span>.3627668659266

<span class="w"> </span>Squertz<span class="w"> </span><span class="k">in</span><span class="w"> </span>log10<span class="w"> </span><span class="p">&amp;</span><span class="w"> </span><span class="nb">complete</span><span class="w"> </span>stats<span class="w"> </span>on<span class="w"> </span>device<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span><span class="m">10</span><span class="w"> </span>iterations<span class="w"> </span>:
<span class="w">   </span>Mean:<span class="w">       </span><span class="m">3</span>.396710194304037<span class="w">       </span><span class="m">2492</span>.9306334939147
<span class="w">   </span>Median:<span class="w">     </span><span class="m">3</span>.417403524471372<span class="w">       </span><span class="m">2614</span>.5895705522216
<span class="w">   </span>Stddev:<span class="w">     </span><span class="m">2</span>.716968957513558<span class="w">       </span><span class="m">521</span>.1574584983498
<span class="w">   </span>Min:<span class="w">        </span><span class="m">3</span>.01064468743274<span class="w">        </span><span class="m">1024</span>.813145195773
<span class="w">   </span>Max:<span class="w">        </span><span class="m">3</span>.4571929965271666<span class="w">      </span><span class="m">2865</span>.4510674637063
</pre></div>
</div>
<p>Les éléments de sortie sont les statistiques de chaque itération, exprimées en <strong>squertz</strong>, contraction de <strong>square</strong> (pour « carré ») avec <strong>Hertz</strong>. En effet, le nombre de calculs élémentaires évolue suivant une loi en <strong>N(N-1)</strong> (chaque particule parmi <strong>N</strong> intéragit avec les <strong>N-1</strong> autres particules).</p>
<section id="analyse-du-programme">
<h3>Analyse du programme<a class="headerlink" href="#analyse-du-programme" title="Lien vers cette rubrique">¶</a></h3>
<p>Lors de l’initialisation du « système N-Corps », plusieurs opérations sont effectuées :</p>
<ul class="simple">
<li><p>l’initialisation de la position des particules</p></li>
<li><p>la distribution aléatoire des particules dans le volume (boule ou cube)</p></li>
<li><p>la détermination du centre de gravité</p></li>
<li><p>la distribution semi-aléatoire des vitesses en fonction du Viriel</p></li>
<li><p>l’évolution du système</p></li>
</ul>
<div class="note note-warning docutils container">
<p><strong>Exercice #12.1 : étude du source de `NBody.py`</strong></p>
<ul class="simple">
<li><p>Editez le programme avec gedit</p></li>
<li><p>Identifiez le bloc de noyaux OpenCL : lignes</p></li>
<li><p>Identifiez les appels des noyaux OpenCL : lignes</p></li>
<li><p>Identifiez les récupérations de positions et vitesses des particules</p></li>
<li><p>Identifiez la portion de code OpenGL</p></li>
</ul>
</div>
<p>Pour un lancement sur 32768 particules et les différents périphériques (3 CPU et 2 GPU), pour des calculs en 32 et 64 bits en flottants, nous avons les résultats suivants :</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Périphérique</p></th>
<th class="head"><p>Squertz SP</p></th>
<th class="head"><p>Squertz DP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AMD</p></td>
<td><p>2583647198</p></td>
<td><p>1141839568</p></td>
</tr>
<tr class="row-odd"><td><p>PortableCL</p></td>
<td><p>1277518016</p></td>
<td><p>782950973</p></td>
</tr>
<tr class="row-even"><td><p>GTX 1080 Ti</p></td>
<td><p>104176444905</p></td>
<td><p>2853097176</p></td>
</tr>
<tr class="row-odd"><td><p>QuadroK420</p></td>
<td><p>3242286836</p></td>
<td><p>116285732</p></td>
</tr>
<tr class="row-even"><td><p>Intel</p></td>
<td><p>4728894103</p></td>
<td><p>1444506859</p></td>
</tr>
</tbody>
</table>
<img alt="Image nbody_opencluster2" class="img-fluid center" src="../../_images/nbody_opencluster2.png" />
<p>La figure ci-dessus illustre l’écrasante performance de la GTX 1080 Ti en comparaison de toutes les autres implémentations : plus d’un facteur 22 en simple précision et presque un facteur 2 en double précision pour la meilleure des implémentations CPU.</p>
<img alt="Image nbody_log_opencluster2" class="img-fluid center" src="../../_images/nbody_log_opencluster2.png" />
<p>Seule une représentation en log permet de ne pas trop écraser les performances des implémentations CPU.</p>
<div class="note note-warning docutils container">
<p><strong>Exercice #12.2 : lancement de `NBody.py` pour 32768 particules</strong></p>
<ul class="simple">
<li><p>Exécutez le programme pour tous les périphériques détectés</p></li>
<li><p>Ajoutez l’option pour un calcul en 64 bits et réexécutez</p></li>
<li><p>Tracez les histogrammes de performances</p></li>
<li><p>Quel est le ratio entre la meilleure GPU et la meilleure en CPU en 32 bits</p></li>
<li><p>Quel est le ratio entre la meilleure GPU et la meilleure en CPU en 64 bits</p></li>
<li><p>Quel est le ratio pour un même périphérique entre 32 et 64 bits ?</p></li>
</ul>
</div>
<p>Vous pouvez également exécuter <code class="docutils literal notranslate"><span class="pre">NBody.py</span></code> avec l’option <code class="docutils literal notranslate"><span class="pre">-g</span></code> pour disposer d’une animation en temps réel du calcul.</p>
<img alt="Image nbody_005" class="img-fluid center" src="../../_images/nbody_005.png" />
<p>La fenêtre de rendu offre la vision suivante :</p>
<img alt="Image nbodygl_004" class="img-fluid center" src="../../_images/nbodygl_004.png" />
<p>La pression sur la touche <code class="docutils literal notranslate"><span class="pre">&lt;Esc&gt;</span></code> permet de sortir du programme pour afficher les statistiques de la simulation.</p>
<img alt="Image nbody_006" class="img-fluid center" src="../../_images/nbody_006.png" />
<p>Si nous changeons de manière insignifiante le nombre de particules (de 8192 à 8191), nous obtenons des performances très différentes :</p>
<img alt="Image nbody_007" class="img-fluid center" src="../../_images/nbody_007.png" />
<div class="note note-warning docutils container">
<p><strong>Exercice #12.3 : lancement de `NBody.py` en mode `-g`</strong></p>
<ul class="simple">
<li><p>Exécutez le programme pour la meilleure implémentation sur CPU sur 8192 particules</p></li>
<li><p>Appuyez sur <code class="docutils literal notranslate"><span class="pre">s</span></code> pour passer des positions aux vitesses</p></li>
<li><p>Utilisez les flèches pour les opérations de rotations</p></li>
<li><p>Utilisez les &lt;+&gt; ou &lt;-&gt; pour les opérations de zoom ou dézoom</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez finalement la performance médiane en Squertz</p></li>
<li><p>Exécutez le programme sur la GPU la plus puissante avec 8192 particules</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez la performance médiane en Squertz</p></li>
<li><p>Exécutez le programme sur la GPU la plus puissante avec 8191 particules</p></li>
<li><p>Sortez avec &lt;Esc&gt; et notez la performance médiane en Squertz</p></li>
<li><p>Quel ratio entre Squertz existe entre 8192 et 8191 particules ?</p></li>
<li><p>Pourquoi un tel ratio ?</p></li>
</ul>
</div>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Lien vers cette rubrique">¶</a></h2>
<p>Comme vous l’aurez remarqué au cours de ces Travaux Pratiques, l’exploitation peut être pleine de surprises : une métrologie pertinente ne peut se passer de la connaissance du matériel exploité.</p>
<p>L’exploitation de « codes métier » vous aura aussi permis d’entrevoir la difficulté d’intégrer et d’exécuter des programmes dans des environnements pourtant bien homogènes : toutes les stations exploitées ont exactement le même système d’exploitation, <a class="reference internal" href="../../Science/Publications/Sidus/SidusDoc.html#sidusdoc"><span class="std std-ref">SIDUS</span></a>. Les « astuces » permettant de simplement pouvoir exécuter les programmes illustraient aussi que, sans expérience, difficile de s’en sortir.</p>
<p>— <a class="reference external" href="mailto:emmanuel&#46;quemener&#37;&#52;&#48;ens-lyon&#46;fr">Emmanuel Quemener</a> 2022/07/20 15:13</p>
</section>
</section>


              </div>
              <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper mt-4 d-flex justify-content-between">
  <div role="note" aria-label="source link">
    <ul class="this-page-menu">
      <li><a href="../../_sources/Plateformes/Autres/ETSN2022.rst.txt"
            rel="nofollow">Montrer le code source</a></li>
    </ul>
   </div>

        </div>
      </div>-->
            </div>
            <div class="clearer"></div>
          </div>
        </div>
      </div>

  
      <div class="clearer"></div>
    </div>
<div class="orange-border right"></div>
  <footer class="text-white bg-dark mt-5 mx-auto">
    <p class="fs-11 mt-1">
    Centre Blaise Pascal et Pôle Scientifique de Modélisation Numérique, ENS de Lyon - 46, allée d'Italie - 69364 Lyon cedex 07 - France <br>
    Téléphone : +33 (0)4 72 72 86 37 - Email : cbp@ens-lyon.fr 
</p>
      <p class="fs-13">
    &#169; Copyright 2024, PSMN&#39;s Staff.
          Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
      </p>
  </footer>
  <script src="../../_static/main.js"></script>
  <script src="../../_static/jquery.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_bundle.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_popper.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap_cdn.min.js"></script>
  <script src="../../_static/Bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>